{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c29eca9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tsa.deterministic import (CalendarFourier,\n",
    "                                           CalendarSeasonality,\n",
    "                                           CalendarTimeTrend,\n",
    "                                           DeterministicProcess)\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize()\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import ctypes as ct\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import statistics as st\n",
    "import lightgbm as lgbm\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "909879c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c34085",
   "metadata": {},
   "source": [
    "## Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bedd4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NUM = 95\n",
    "NFOLDS = 5\n",
    "SEED = 42\n",
    "TRAIN_DATE = 'date < 20210601'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0eaba37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(seed: int = 42):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)  # type: ignore\n",
    "#     torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "#     torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "# set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c34d5f",
   "metadata": {},
   "source": [
    "## Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "196b4321",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/MLB-Player-Digital-Engagement-Forecasting/data/\")\n",
    "MAIN_DATA_DIR = DATA_DIR / 'mlb-player-digital-engagement-forecasting-update'\n",
    "TRAIN_DIR = MAIN_DATA_DIR / 'train'\n",
    "OUTPUT_DIR = Path('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5193baf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(MAIN_DATA_DIR / 'players.csv')\n",
    "seasons = pd.read_csv(MAIN_DATA_DIR / 'seasons.csv')\n",
    "teams = pd.read_csv(MAIN_DATA_DIR / 'teams.csv')\n",
    "\n",
    "rosters = pd.read_csv(TRAIN_DIR / 'rosters_train.csv').query(TRAIN_DATE)\n",
    "targets = pd.read_csv(TRAIN_DIR / 'nextDayPlayerEngagement_train.csv').query(TRAIN_DATE)\n",
    "scores = pd.read_csv(TRAIN_DIR / 'playerBoxScores_train.csv').query(TRAIN_DATE)\n",
    "scores = scores.groupby(['playerId', 'date']).sum().reset_index()\n",
    "standings = pd.read_csv(TRAIN_DIR / 'standings_train.csv').query(TRAIN_DATE)\n",
    "playerTwitterFollowers = pd.read_csv(TRAIN_DIR / 'playerTwitterFollowers_train.csv').query(TRAIN_DATE)\n",
    "awards = pd.read_csv(TRAIN_DIR / 'awards_train.csv').query(TRAIN_DATE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d9361f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elements_dict = {\"players\":players, \n",
    "                       \"rosters\":rosters, \n",
    "                       \"targets\":targets, \n",
    "                       \"scores\":scores, \n",
    "                       \"seasons\":seasons, \n",
    "                       \"teams\":teams, \n",
    "                       \"standings\":standings,\n",
    "                       'awards':awards}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65201799",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_team_name(name):\n",
    "    names = name.split('-')\n",
    "    result = ''\n",
    "    for n in names:\n",
    "        if n == 'st':\n",
    "            n = 'st.'\n",
    "        result += f' {n.capitalize()}'\n",
    "\n",
    "    return result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc9c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corr(df):\n",
    "    # 相関係数行列を作成\n",
    "    corr_mat = df.corr(method='pearson')\n",
    "\n",
    "    # 行（列）サイズを取得\n",
    "    n = corr_mat.shape[0]\n",
    "    corr_ary = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if i == j:\n",
    "                continue\n",
    "            corr_ary.append(corr_mat.iloc[i,j])\n",
    "\n",
    "    return corr_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5836a22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probs(pid,df,temp):\n",
    "    to_append=[pid,'','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','']\n",
    "    targets=['target1','target2','target3','target4']\n",
    "    z=1\n",
    "    for target in targets:\n",
    "        target_prob = temp[target].tolist()\n",
    "        mean = np.mean(target_prob)\n",
    "        std = np.std(target_prob)\n",
    "        median = st.median(target_prob)\n",
    "        distribution = norm(mean, std)\n",
    "        min_weight = min(target_prob)\n",
    "        max_weight = max(target_prob)\n",
    "        values = list(np.linspace(min_weight, max_weight))\n",
    "        probabilities = [distribution.pdf(v) for v in values]\n",
    "        max_value = max(probabilities)\n",
    "        max_index = probabilities.index(max_value)\n",
    "        to_append[z]=mean\n",
    "        to_append[z+1]=median\n",
    "        to_append[z+2]=std\n",
    "        to_append[z+3]=min_weight\n",
    "        to_append[z+4]=max_weight\n",
    "        to_append[z+5]=temp[target].skew()\n",
    "        to_append[z+6]=temp[target].kurt()\n",
    "\n",
    "        z=z+7\n",
    "    corr_ = calc_corr(temp[['target1', 'target2', 'target3', 'target4']])\n",
    "    to_append[z:] = corr_  \n",
    "    df_length = len(df)\n",
    "    df.loc[df_length] = to_append\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51e261e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_consecutive_items_n_cols(df, col_name_list, output_col):\n",
    "    cum_sum_list = [\n",
    "        (df[col_name] != df[col_name].shift(1)).cumsum().tolist() for col_name in col_name_list\n",
    "    ]\n",
    "    df[output_col] = df.groupby(\n",
    "        [\"_\".join(map(str, x)) for x in zip(*cum_sum_list)]\n",
    "    ).cumcount() + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c5c3a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_season(date_raw, season_start_end):\n",
    "    idxes = 0\n",
    "    for raw in season_start_end.iloc():\n",
    "        idx_ = ((date_raw >= raw.iloc[0]) & (date_raw <= raw.iloc[1])) * 1\n",
    "        idxes += idx_\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "06ba8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n",
    "    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n",
    "    model = lgbm.LGBMRegressor(**params)\n",
    "    model.fit(x_train, y_train, \n",
    "        eval_set=[(x_valid, y_valid)],  \n",
    "        early_stopping_rounds=verbose, \n",
    "        verbose=verbose)\n",
    "    oof_pred = model.predict(x_valid)\n",
    "    oof_pred = np.clip(oof_pred, 0, 100)\n",
    "    score = mean_absolute_error(oof_pred, y_valid)\n",
    "    print('mae:', score)\n",
    "    return oof_pred, model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "42d9811a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_timeseries_fold(train):\n",
    "    \n",
    "    tr_idxs = []\n",
    "    val_idxs = []\n",
    "    \n",
    "    tr_idx = (train['date'].astype(int) < 20200701)\n",
    "    val_idx = (train['date'].astype(int) >= 20200701) & (train['date'].astype(int) < 20200801)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "        \n",
    "    tr_idx = (train['date'].astype(int) < 20200801)\n",
    "    val_idx = (train['date'].astype(int) >= 20200801) & (train['date'].astype(int) < 20200901)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "\n",
    "    tr_idx = (train['date'].astype(int) < 20200901)\n",
    "    val_idx = (train['date'].astype(int) >= 20200901) & (train['date'].astype(int) < 20201001)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "    \n",
    "    tr_idx = (train['date'].astype(int) < 20210401)\n",
    "    val_idx = (train['date'].astype(int) >= 20210401) & (train['date'].astype(int) < 20210501)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "\n",
    "    tr_idx = (train['date'].astype(int) < 20210501)\n",
    "    val_idx = (train['date'].astype(int) >= 20210501) & (train['date'].astype(int) < 20210601)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "    \n",
    "    \n",
    "    return tr_idxs, val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c98781c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rt4kaidoTrain:\n",
    "    def __init__(self, usetimelinefeature=False):\n",
    "        \n",
    "        self.usetimelinefeature = usetimelinefeature\n",
    "        self.targets_cols = ['playerId', 'target1', 'target2', 'target3', 'target4', 'date']\n",
    "        self.players_cols = ['playerId', 'primaryPositionName', 'birthCity', 'DOY', 'mlbDebutYear', 'mlbDebutDate', 'DebutAge', 'heightInches', 'weight', 'playerForTestSetAndFuturePreds']\n",
    "        self.rosters_cols = ['playerId', 'teamId', 'status', 'date']\n",
    "        self.salaries_cols = ['teamId', 'salary', 'year']\n",
    "        self.standings_cols = ['teamId', 'wildCardRank', 'sportGamesBack', 'date']\n",
    "        self.transactions_cols = ['playerId', 'transaction_flag', 'date']\n",
    "        self.stat_cols = [\"playerId\", \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_skew\",\"target1_kurt\",\n",
    "                        \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_skew\",\"target2_kurt\",\n",
    "                        \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_skew\",\"target3_kurt\",\n",
    "                        \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_skew\",\"target4_kurt\",\n",
    "                        'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr']\n",
    "\n",
    "        self.scores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances', 'date']\n",
    "\n",
    "        self.feature_cols1 = ['week_day','label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank', 'award_flag'] \n",
    "\n",
    "        self.feature_cols2 = ['label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank', 'award_flag'] \n",
    "\n",
    "        self.feature_cols3 = ['week_day','label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank', 'diffmlbDebutDateflag', 'sincemlbDebutDateflag', 'award_flag'] \n",
    "\n",
    "        self.feature_cols4 = ['week_day', 'annual_day', 'month', 'label_playerId', 'label_primaryPositionName', 'label_teamId', 'label_birthCity',\n",
    "                        'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank', 'diffmlbDebutDateflag', 'sincemlbDebutDateflag', 'award_flag'] \n",
    "        \n",
    "        # lightgbm\n",
    "        self.params1 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 15,\n",
    "            'min_child_weight': 13,\n",
    "            'subsample': 0.6,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'reg_lambda': 30.9319329450672,\n",
    "            'reg_alpha': 0.7515114958383698,\n",
    "            'feature_fraction': 0.9190642982206391,\n",
    "            'bagging_fraction': 0.8602941852412167,\n",
    "            'bagging_freq': 18,\n",
    "            'num_leaves': 841,\n",
    "            'min_child_samples': 39\n",
    "        }\n",
    "\n",
    "\n",
    "        self.params2 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 15,\n",
    "            'min_child_weight': 10,\n",
    "            'subsample': 0.7,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'reg_lambda': 0.024881742520683536,\n",
    "            'reg_alpha': 0.017345922288425283,\n",
    "            'feature_fraction': 0.9367028357310329,\n",
    "            'bagging_fraction': 0.4918512249239658,\n",
    "            'bagging_freq': 14,\n",
    "            'num_leaves': 778,\n",
    "            'min_child_samples': 93\n",
    "        }\n",
    "\n",
    "\n",
    "        self.params3 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 12,\n",
    "            'min_child_weight': 7,\n",
    "            'subsample': 0.6,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_lambda': 0.01788396916254518,\n",
    "            'reg_alpha': 0.03371095673858391,\n",
    "            'feature_fraction': 0.999031125349641,\n",
    "            'bagging_fraction': 0.7149807933910547,\n",
    "            'bagging_freq': 10,\n",
    "            'num_leaves': 725,\n",
    "            'min_child_samples': 91\n",
    "        }\n",
    "\n",
    "\n",
    "        self.params4 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 6,\n",
    "            'min_child_weight': 4,\n",
    "            'subsample': 0.9,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_lambda': 0.00848895237283686,\n",
    "            'reg_alpha': 50.46708556901996,\n",
    "            'feature_fraction': 0.9003128313130303,\n",
    "            'bagging_fraction': 0.8113363312593455,\n",
    "            'bagging_freq': 17,\n",
    "            'num_leaves': 888,\n",
    "            'min_child_samples': 75\n",
    "        }\n",
    "        \n",
    "        # lightgbm\n",
    "        self.gameday_params1 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 15,\n",
    "            'min_child_weight': 11,\n",
    "            'subsample': 0.5,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_lambda': 0.003032755323920707,\n",
    "            'reg_alpha': 0.366363643519398,\n",
    "            'feature_fraction': 0.7371239177317086,\n",
    "            'bagging_fraction': 0.7812193424369623,\n",
    "            'bagging_freq': 2,\n",
    "            'num_leaves': 85,\n",
    "            'min_child_samples': 5\n",
    "        }\n",
    "\n",
    "\n",
    "        self.gameday_params2 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 1,\n",
    "            'min_child_weight': 15,\n",
    "            'subsample': 0.9,\n",
    "            'colsample_bytree': 0.8,\n",
    "            'reg_lambda': 0.03384271181171102,\n",
    "            'reg_alpha': 0.0029030113032933614,\n",
    "            'feature_fraction': 0.689102086803655,\n",
    "            'bagging_fraction': 0.5529672595341992,\n",
    "            'bagging_freq': 7,\n",
    "            'num_leaves': 354,\n",
    "            'min_child_samples': 43\n",
    "        }\n",
    "\n",
    "\n",
    "        self.gameday_params3 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 7,\n",
    "            'min_child_weight': 17,\n",
    "            'subsample': 0.9,\n",
    "            'colsample_bytree': 0.5,\n",
    "            'reg_lambda': 0.013206410340812798,\n",
    "            'reg_alpha': 0.38462102899359113,\n",
    "            'feature_fraction': 0.865874475429003,\n",
    "            'bagging_fraction': 0.9975448137502082,\n",
    "            'bagging_freq': 1,\n",
    "            'num_leaves': 683,\n",
    "            'min_child_samples': 30\n",
    "        }\n",
    "\n",
    "\n",
    "        self.gameday_params4 = {            \n",
    "            'random_state': SEED,\n",
    "            'objective':'mae',\n",
    "            'n_estimators': 10000,\n",
    "            'learning_rate': 0.1,\n",
    "            'max_depth': 8,\n",
    "            'min_child_weight': 5,\n",
    "            'subsample': 0.5,\n",
    "            'colsample_bytree': 0.7,\n",
    "            'reg_lambda': 0.5078328819318434,\n",
    "            'reg_alpha': 0.3444492532547177,\n",
    "            'feature_fraction': 0.5100430719886615,\n",
    "            'bagging_fraction': 0.9444400283463885,\n",
    "            'bagging_freq': 8,\n",
    "            'num_leaves': 11,\n",
    "            'min_child_samples': 44\n",
    "        }\n",
    "        \n",
    "\n",
    "    def make_feature(self, train_elements_dict):\n",
    "\n",
    "        players = train_elements_dict['players']\n",
    "        rosters = train_elements_dict['rosters']\n",
    "        targets = train_elements_dict['targets']\n",
    "        scores = train_elements_dict['scores']\n",
    "        seasons = train_elements_dict['seasons']\n",
    "        teams = train_elements_dict['teams']\n",
    "        standings = train_elements_dict['standings']\n",
    "\n",
    "        print('calc target stat ... ', end=\"\")\n",
    "\n",
    "        ## target stats\n",
    "        targets_train = targets.merge(rosters[self.rosters_cols], on=['playerId', 'date'], how='left')\n",
    "        targets_train = targets_train[(targets_train['date'] >= 20210501) & (targets_train['date'] < 20210601)]\n",
    "        \n",
    "        playerId_list = targets_train['playerId'].unique()\n",
    "        player_target_probs = pd.DataFrame(columns = self.stat_cols)  \n",
    "        for pid in tqdm(playerId_list):\n",
    "            temp = targets_train[targets_train['playerId'] == pid]\n",
    "            player_target_stats=calc_probs(pid,player_target_probs,temp)\n",
    "\n",
    "        teamId_list = targets_train['teamId'].dropna().unique()\n",
    "        team_target_probs = pd.DataFrame(columns = self.stat_cols)\n",
    "        for pid in tqdm(teamId_list):\n",
    "            temp = targets_train[targets_train['teamId'] == pid]\n",
    "            team_target_stats=calc_probs(pid,team_target_probs,temp)\n",
    "\n",
    "        team_stat_cols = self.stat_cols\n",
    "        team_stat_cols = team_stat_cols[:1] + [\"team_\" + word for word in team_stat_cols[1:]]\n",
    "        team_target_stats.columns = team_stat_cols\n",
    "\n",
    "        self.feature_cols1 += self.stat_cols[1:-6]\n",
    "        self.feature_cols2 += self.stat_cols[1:-6]\n",
    "        self.feature_cols3 += self.stat_cols[1:-6]\n",
    "        self.feature_cols4 += self.stat_cols[1:-6]\n",
    "\n",
    "        self.feature_cols1 += team_stat_cols[1:]\n",
    "        self.feature_cols2 += team_stat_cols[1:]\n",
    "        self.feature_cols3 += team_stat_cols[1:]\n",
    "        self.feature_cols4 += team_stat_cols[1:]\n",
    "\n",
    "        print('done.')\n",
    "\n",
    "        print('preprocess ... ', end=\"\")\n",
    "        ## salaries\n",
    "        # salaries = salaries.groupby(['year', 'team']).sum()['salary'].reset_index()\n",
    "        # salaries['team'] = salaries['team'].apply(map_team_name)\n",
    "        # salaries = salaries.merge(teams, left_on='team', right_on='name', how='inner')\n",
    "        # salaries = salaries.rename(columns={'id': 'teamId'})\n",
    "\n",
    "        ## seasons\n",
    "        seasons = seasons.fillna('0000-00-00')\n",
    "        for c_ in seasons.columns[1:]:\n",
    "            seasons[c_] = seasons[c_].str.replace('-', '').astype(int)\n",
    "\n",
    "        ## players\n",
    "        players['DOY'] = pd.to_datetime(players['DOB'], format=\"%Y-%m-%d\").dt.year\n",
    "        players['mlbDebutYear'] = pd.to_datetime(players['mlbDebutDate'], format=\"%Y-%m-%d\").dt.year\n",
    "        players['DebutAge'] = players['mlbDebutYear'] - players['DOY']\n",
    "        players['mlbDebutDate'] = pd.to_numeric(players['mlbDebutDate'].str.replace('-', ''), errors=\"coerce\")\n",
    "\n",
    "        print('done.')\n",
    "\n",
    "        print('creat feature ... ', end=\"\")\n",
    "        # creat feature\n",
    "        train = targets[self.targets_cols].merge(players[self.players_cols], on=['playerId'], how='left')\n",
    "        train = train.merge(rosters[self.rosters_cols], on=['playerId', 'date'], how='left')\n",
    "        train = train.merge(scores[self.scores_cols], on=['playerId', 'date'], how='left')\n",
    "        train = train.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n",
    "        train = train.merge(standings[self.standings_cols], on=['teamId', 'date'], how='left')\n",
    "        train = train.merge(team_target_stats, how='left', left_on=[\"teamId\"],right_on=[\"playerId\"], suffixes=('', 'team_'))\n",
    "        train = train.merge(awards, on=['playerId', 'date'], how='left')\n",
    "\n",
    "        \n",
    "        date_ = pd.to_datetime(train['date'], format=\"%Y%m%d\")\n",
    "        train['annual_day'] = (date_ - pd.to_datetime(date_.dt.year, format=\"%Y\")) /  timedelta(days=1)\n",
    "        train['week_day'] = date_.dt.weekday\n",
    "        train['month'] = date_.dt.month\n",
    "        train['year'] = date_.dt.year\n",
    "        train['mlbDebutDateflag'] = (train['mlbDebutDate'] == train['date']) * 1\n",
    "        train['sincemlbDebutDateflag'] = (train['date'] >= train['mlbDebutDate']) * 1\n",
    "        train['diffmlbDebutDateflag'] = (train['date'] - train['mlbDebutDate'])\n",
    "\n",
    "        # label encoding\n",
    "        player2num = {c: i for i, c in enumerate(train['playerId'].unique())}\n",
    "        position2num = {c: i for i, c in enumerate(train['primaryPositionName'].unique())}\n",
    "        birthCityn2num = {c: i for i, c in enumerate(train['birthCity'].unique())}\n",
    "        teamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\n",
    "        status2num = {c: i for i, c in enumerate(train['status'].unique())}\n",
    "        awardName2num = {c: i for i, c in enumerate(train['awardName'].unique())}\n",
    "        train['label_playerId'] = train['playerId'].map(player2num)\n",
    "        train['label_primaryPositionName'] = train['primaryPositionName'].map(position2num)\n",
    "        train['label_birthCity'] = train['birthCity'].map(birthCityn2num)\n",
    "        train['label_teamId'] = train['teamId'].map(teamid2num)\n",
    "        train['label_status'] = train['status'].map(status2num)\n",
    "        train['award_flag'] = train['awardSeason'].isna()*1\n",
    "\n",
    "\n",
    "        ## season_info\n",
    "        on_preseason_idxes = extract_season(train['date'], seasons[['preSeasonStartDate', 'preSeasonEndDate']])\n",
    "        on_season_idxes = extract_season(train['date'], seasons[['regularSeasonStartDate', 'regularSeasonEndDate']]) * 2\n",
    "        on_postseason_idxes = extract_season(train['date'], seasons[['postSeasonStartDate', 'postSeasonEndDate']]) * 3\n",
    "\n",
    "        special_days = seasons['lastDate1stHalf'].to_list() + seasons['allStarDate'].to_list() + seasons['firstDate2ndHalf'].to_list()\n",
    "        special_idxes = 0\n",
    "        for day in special_days:\n",
    "            special_idxes += (train['date'] == day) * 4\n",
    "\n",
    "        on_total_season_idxes = on_preseason_idxes\n",
    "        on_total_season_idxes[on_season_idxes==2] = 2\n",
    "        on_total_season_idxes[on_postseason_idxes==3] = 3\n",
    "        on_total_season_idxes[special_idxes==4] = 4\n",
    "\n",
    "        train['season_info'] = on_total_season_idxes\n",
    "\n",
    "        ## only on season\n",
    "        on_whole_idxes = extract_season(train['date'], seasons[['seasonStartDate', 'seasonEndDate']])\n",
    "        train = train[on_whole_idxes == 1].reset_index(drop=True)\n",
    "\n",
    "        # train = train.merge(playerTwitterFollowers, how='left', on=[\"playerId\", 'date'])\n",
    "\n",
    "\n",
    "        print('done.')\n",
    "        \n",
    "        train_features_dict = {'players': players,\n",
    "                               'seasons': seasons,\n",
    "                                'player_target_stats': player_target_stats,\n",
    "                                'team_target_stats': team_target_stats,\n",
    "                                'player2num': player2num, \n",
    "                                'position2num': position2num, \n",
    "                                'birthCityn2num': birthCityn2num,\n",
    "                                'teamid2num': teamid2num,\n",
    "                                'status2num': status2num,\n",
    "                                'feature_cols1': self.feature_cols1,\n",
    "                                'feature_cols2': self.feature_cols2,\n",
    "                                'feature_cols3': self.feature_cols3,\n",
    "                                'feature_cols4': self.feature_cols4,\n",
    "                                'rosters_cols_all': list(rosters.columns),\n",
    "                                'scores_cols_all': list(scores.columns),\n",
    "                                'standings_cols_all': list(standings.columns),\n",
    "                                'awards_cols_all': list(awards.columns)\n",
    "                              }\n",
    "        \n",
    "        if self.usetimelinefeature:\n",
    "            ## game_info\n",
    "            train['gameday'] = ~train['battingOrder'].isna()*1\n",
    "            train.sort_values(by=['playerId','date'],inplace=True,ascending=True)\n",
    "\n",
    "            train=count_consecutive_items_n_cols(train,['playerId','gameday'],'daysSinceLastGame')\n",
    "            train.loc[train['gameday']==1,'daysSinceLastGame'] = 0\n",
    "\n",
    "            train_game = train[train['gameday']==1]\n",
    "            train_last_game = train_game[~train_game.duplicated(subset='playerId', keep='last')][['playerId', 'date']]\n",
    "            train_last_game.columns = ['playerId', 'lastdate']\n",
    "            train_player_unique = pd.DataFrame(train['playerId'].unique(), columns=['playerId'])\n",
    "            train_last_game = pd.merge(train_player_unique, train_last_game, on=['playerId'], how='left' )\n",
    "            train_last_game = train_last_game.fillna(20171231)\n",
    "            \n",
    "            train_features_dict['train_last_game'] = train_last_game\n",
    "            self.feature_cols1 += ['daysSinceLastGame']\n",
    "            self.feature_cols2 += ['daysSinceLastGame']\n",
    "            self.feature_cols3 += ['daysSinceLastGame']\n",
    "            self.feature_cols4 += ['daysSinceLastGame']\n",
    "            \n",
    "            \n",
    "            ## rosters_info\n",
    "            train['rosterday'] = ~train['status'].isna()*1\n",
    "            train.sort_values(by=['playerId','date'],inplace=True,ascending=True)\n",
    "\n",
    "            train=count_consecutive_items_n_cols(train,['playerId','rosterday'],'daysSinceLastRoster')\n",
    "            train.loc[train['rosterday']==1,'daysSinceLastRoster'] = 0\n",
    "\n",
    "            train_roster= train[train['rosterday']==1]\n",
    "            train_last_roster = train_roster[~train_roster.duplicated(subset='playerId', keep='last')][['playerId', 'date']]\n",
    "            train_last_roster.columns = ['playerId', 'lastroster']\n",
    "            train_player_unique = pd.DataFrame(train['playerId'].unique(), columns=['playerId'])\n",
    "            train_last_roster = pd.merge(train_player_unique, train_last_roster, on=['playerId'], how='left' )\n",
    "            train_last_roster = train_last_roster.fillna(20171231)\n",
    "            \n",
    "            train_features_dict['train_last_roster'] = train_last_roster\n",
    "            self.feature_cols1 += ['daysSinceLastRoster']\n",
    "            self.feature_cols2 += ['daysSinceLastRoster']\n",
    "            self.feature_cols3 += ['daysSinceLastRoster']\n",
    "            self.feature_cols4 += ['daysSinceLastRoster']\n",
    "\n",
    "\n",
    "        return train, train_features_dict\n",
    "    \n",
    "    def train_and_evaluate(self, train, isgamedayonly=False):\n",
    "        \n",
    "        if isgamedayonly:\n",
    "            train = train[train['gameday'] == 1].reset_index(drop=True)\n",
    "        else: \n",
    "            ## only test_player\n",
    "            train = train[train['playerForTestSetAndFuturePreds'] == True].reset_index(drop=True)\n",
    "            \n",
    "        train_X = train\n",
    "        train_y = train[['target1', 'target2', 'target3', 'target4']]\n",
    "\n",
    "        oof = np.zeros(train_y.shape) - 1.0\n",
    "        y_valids = np.zeros(train_y.shape) - 1.0\n",
    "        \n",
    "        tr_idxs, val_idxs = my_timeseries_fold(train)\n",
    "        \n",
    "        \n",
    "        model1s = []\n",
    "        model2s = []\n",
    "        model3s = []\n",
    "        model4s = []\n",
    "        scores = []\n",
    "        oof = np.zeros(train_y.shape) - 1.0\n",
    "        y_valids = np.zeros(train_y.shape) - 1.0\n",
    "\n",
    "        for idx in range(NFOLDS):\n",
    "            \n",
    "            tr_idx = tr_idxs[idx]\n",
    "            val_idx = val_idxs[idx]\n",
    "\n",
    "            x_train = train_X.loc[tr_idx].reset_index(drop=True)\n",
    "            y_train = train_y.loc[tr_idx].reset_index(drop=True)\n",
    "            x_valid = train_X.loc[val_idx].reset_index(drop=True)\n",
    "            y_valid = train_y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "\n",
    "            oof1, model1, score1 = fit_lgbm(\n",
    "                x_train[self.feature_cols1], y_train['target1'],\n",
    "                x_valid[self.feature_cols1], y_valid['target1'],\n",
    "                self.gameday_params1 if isgamedayonly else self.params1\n",
    "            )\n",
    "            oof2, model2, score2 = fit_lgbm(\n",
    "                x_train[self.feature_cols2], y_train['target2'],\n",
    "                x_valid[self.feature_cols2], y_valid['target2'],\n",
    "                self.gameday_params2 if isgamedayonly else self.params2\n",
    "            )\n",
    "            oof3, model3, score3 = fit_lgbm(\n",
    "                x_train[self.feature_cols3], y_train['target3'],\n",
    "                x_valid[self.feature_cols3], y_valid['target3'],\n",
    "                self.gameday_params3 if isgamedayonly else self.params3\n",
    "            )\n",
    "            oof4, model4, score4 = fit_lgbm(\n",
    "                x_train[self.feature_cols4], y_train['target4'],\n",
    "                x_valid[self.feature_cols4], y_valid['target4'],\n",
    "                self.gameday_params4 if isgamedayonly else self.params4\n",
    "            )\n",
    "\n",
    "\n",
    "            score = (score1+score2+score3+score4) / 4\n",
    "            scores.append(score)\n",
    "            print(f'score: {score}')\n",
    "\n",
    "            model1s.append(model1)\n",
    "            model2s.append(model2)\n",
    "            model3s.append(model3)\n",
    "            model4s.append(model4)\n",
    "            oof[val_idx, 0] = oof1\n",
    "            oof[val_idx, 1] = oof2\n",
    "            oof[val_idx, 2] = oof3\n",
    "            oof[val_idx, 3] = oof4\n",
    "            y_valids[val_idx, 0] = y_valid['target1'].values\n",
    "            y_valids[val_idx, 1] = y_valid['target2'].values\n",
    "            y_valids[val_idx, 2] = y_valid['target3'].values\n",
    "            y_valids[val_idx, 3] = y_valid['target4'].values\n",
    "\n",
    "\n",
    "        oof_indexes = []\n",
    "        for i in range(NFOLDS):\n",
    "            oof_indexes.extend(val_idxs[i][val_idxs[i]==True].index.to_list())\n",
    "            \n",
    "        print(\"\\n--------------------------------------------\")\n",
    "        for i in range(NFOLDS):\n",
    "            print(f'{i}fold mae: {scores[i]}')\n",
    "        mae = mean_absolute_error(y_valids[oof_indexes, :], oof[oof_indexes, :])\n",
    "        print(\"oof mae:\", mae)\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "        oof_df = train[self.targets_cols]\n",
    "        oof_df.iloc[oof_indexes, 1:5] = oof[oof_indexes, :]\n",
    "\n",
    "        models = np.array([model1s, model2s, model3s, model4s])\n",
    "        \n",
    "        print(\"---------------April evaluate-------------------\")\n",
    "        weights = [0.05, 0.1, 0.15, 0.2, 0.5]\n",
    "        pred1s = 0\n",
    "        pred2s = 0\n",
    "        pred3s = 0\n",
    "        pred4s = 0\n",
    "        for i in range(NFOLDS):\n",
    "            pred1 = models[0][i].predict(x_valid[self.feature_cols1])\n",
    "            pred2 = models[1][i].predict(x_valid[self.feature_cols2])\n",
    "            pred3 = models[2][i].predict(x_valid[self.feature_cols3])\n",
    "            pred4 = models[3][i].predict(x_valid[self.feature_cols4])\n",
    "            oof_valid_april = np.clip(np.array([pred1, pred2, pred3, pred4]).T, 0, 100)\n",
    "            mae = mean_absolute_error(y_valid, oof_valid_april)\n",
    "            print(f'{i}fold mae: {mae}')\n",
    "            pred1s += pred1 * weights[i]\n",
    "            pred2s += pred2 * weights[i]\n",
    "            pred3s += pred3 * weights[i]\n",
    "            pred4s += pred4 * weights[i]\n",
    "            \n",
    "        oof_valid_april = np.clip(np.array([pred1s, pred2s, pred3s, pred4s]).T, 0, 100)\n",
    "        mae = mean_absolute_error(y_valid, oof_valid_april)\n",
    "        print(\"oof mae:\", mae)\n",
    "        print(\"--------------------------------------------\")\n",
    "\n",
    "        return oof_df.iloc[oof_indexes], models\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4b5412c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rt4kaidoTest:\n",
    "    def __init__(self, train_features_dict, models_notgameday, models_gameday, usetimelinefeature=False):\n",
    "        \n",
    "        self.usetimelinefeature = usetimelinefeature\n",
    "        self.train_features_dict = train_features_dict\n",
    "        self.feature_cols1 = train_features_dict['feature_cols1']\n",
    "        self.feature_cols2 = train_features_dict['feature_cols2']\n",
    "        self.feature_cols3 = train_features_dict['feature_cols3']\n",
    "        self.feature_cols4 = train_features_dict['feature_cols4']\n",
    "        self.models_notgameday = models_notgameday\n",
    "        self.models_gameday = models_gameday\n",
    "\n",
    "\n",
    "        self.test_players_cols = ['playerId', 'primaryPositionName', 'birthCity', 'DOY', 'mlbDebutYear', 'mlbDebutDate', 'DebutAge', 'heightInches', 'weight']\n",
    "        self.test_rosters_cols = ['date', 'playerId', 'teamId', 'status']\n",
    "        self.test_standings_cols = ['date','teamId', 'wildCardRank', 'sportGamesBack']\n",
    "        self.test_scores_cols = ['date','playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances', 'gamePk']\n",
    "        \n",
    "\n",
    "    def test_oneline(self, test_df, sample_prediction_df):\n",
    "        \n",
    "        null = np.nan\n",
    "        true = True\n",
    "        false = False\n",
    "        \n",
    "        sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n",
    "        test_date = test_df.index[0]\n",
    "\n",
    "        # creat dataset\n",
    "        date_and_playerId = sample_prediction_df['date_playerId'].str.split('_', expand=True)\n",
    "        sample_prediction_df['playerId'] = date_and_playerId[1].astype(int)\n",
    "        sample_prediction_df['date'] = test_date\n",
    "        \n",
    "        # Dealing with missing values\n",
    "        if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n",
    "            test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n",
    "        else:\n",
    "            test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "            for col in self.train_features_dict['rosters_cols_all']:\n",
    "                if col == 'playerId': continue\n",
    "                test_rosters[col] = np.nan\n",
    "        test_rosters['date'] = test_date\n",
    "\n",
    "        if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n",
    "            test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n",
    "            test_scores = test_scores.groupby('playerId').sum().reset_index()\n",
    "        else:\n",
    "            test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "            for col in self.train_features_dict['scores_cols_all']:\n",
    "                if col == 'playerId': continue\n",
    "                test_scores[col] = np.nan\n",
    "        test_scores['date'] = test_date\n",
    "        \n",
    "        if test_df['awards'].iloc[0] == test_df['awards'].iloc[0]:\n",
    "            test_awards = pd.DataFrame(eval(test_df['awards'].iloc[0]))\n",
    "            test_awards = test_awards.groupby('playerId').sum().reset_index()\n",
    "        else:\n",
    "            test_awards = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "            for col in self.train_features_dict['awards_cols_all']:\n",
    "                if col == 'playerId': continue\n",
    "                test_awards[col] = np.nan\n",
    "        test_awards['date'] = test_date\n",
    "              \n",
    "\n",
    "        test = sample_prediction_df[['playerId', 'date']].copy()\n",
    "        test = test.merge(self.train_features_dict['players'][self.test_players_cols], on='playerId', how='left')\n",
    "        test = test.merge(test_rosters[self.test_rosters_cols], on=['playerId', 'date'], how='left')\n",
    "        test = test.merge(test_scores[self.test_scores_cols], on=['playerId', 'date'], how='left')\n",
    "        test = test.merge(test_awards, on=['playerId', 'date'], how='left')\n",
    "        test = test.merge(self.train_features_dict['player_target_stats'], how='left', left_on=[\"playerId\"],right_on=[\"playerId\"])\n",
    "\n",
    "        if test_df['standings'].iloc[0] == test_df['standings'].iloc[0]:\n",
    "            test_standings = pd.DataFrame(eval(test_df['standings'].iloc[0]))\n",
    "        else:\n",
    "            test_standings = pd.DataFrame({'teamId': test['teamId'].unique()})\n",
    "            for col in self.train_features_dict['standings_cols_all']:\n",
    "                if col == 'teamId': continue\n",
    "                test_standings[col] = np.nan   \n",
    "        test_standings['date'] = test_date\n",
    "\n",
    "        self.test = test\n",
    "        self.awards = test_awards\n",
    "\n",
    "        \n",
    "        test = test.merge(test_standings[self.test_standings_cols], on=['teamId', 'date'], how='left')\n",
    "        test = test.merge(self.train_features_dict['team_target_stats'], how='left', left_on=[\"teamId\"],right_on=[\"playerId\"], suffixes=('', 'team_'))\n",
    "        test['wildCardRank'] = test['wildCardRank'].astype(float)\n",
    "\n",
    "\n",
    "        test['label_playerId'] = test['playerId'].map(self.train_features_dict['player2num'])\n",
    "        test['label_primaryPositionName'] = test['primaryPositionName'].map(self.train_features_dict['position2num'])\n",
    "        test['label_teamId'] = test['teamId'].map(self.train_features_dict['teamid2num'])\n",
    "        test['label_status'] = test['status'].map(self.train_features_dict['status2num'])\n",
    "        test['label_birthCity'] = test['birthCity'].map(self.train_features_dict['birthCityn2num'])\n",
    "        test['award_flag'] = test['awardSeason'].isna()*1\n",
    "        test['mlbDebutDateflag'] = (test['mlbDebutDate'] == test['date']) * 1\n",
    "        test['sincemlbDebutDateflag'] = (test['date'] >= test['mlbDebutDate']) * 1\n",
    "        test['diffmlbDebutDateflag'] = (test['date'] - test['mlbDebutDate'])\n",
    "\n",
    "        date_ = pd.to_datetime(test_df.index[0], format=\"%Y%m%d\")\n",
    "        test['annual_day'] = (date_ - pd.to_datetime(date_.year, format=\"%Y\")) /  timedelta(days=1)\n",
    "        test['week_day'] = date_.weekday()\n",
    "        test['month'] = date_.month\n",
    "        \n",
    "        \n",
    "        ## season_info\n",
    "        on_preseason_idxes = extract_season(test['date'], self.train_features_dict['seasons'][['preSeasonStartDate', 'preSeasonEndDate']])\n",
    "        on_season_idxes = extract_season(test['date'], self.train_features_dict['seasons'][['regularSeasonStartDate', 'regularSeasonEndDate']]) * 2\n",
    "        on_postseason_idxes = extract_season(test['date'], self.train_features_dict['seasons'][['postSeasonStartDate', 'postSeasonEndDate']]) * 3\n",
    "\n",
    "        special_days = self.train_features_dict['seasons']['lastDate1stHalf'].to_list() + self.train_features_dict['seasons']['allStarDate'].to_list() + self.train_features_dict['seasons']['firstDate2ndHalf'].to_list()\n",
    "        special_idxes = 0\n",
    "        for day in special_days:\n",
    "            special_idxes += (test['date'] == day) * 4\n",
    "\n",
    "        on_total_season_idxes = on_preseason_idxes\n",
    "        on_total_season_idxes[on_season_idxes==2] = 2\n",
    "        on_total_season_idxes[on_postseason_idxes==3] = 3\n",
    "        on_total_season_idxes[special_idxes==4] = 4\n",
    "\n",
    "        test['season_info'] = on_total_season_idxes\n",
    "             \n",
    "        \n",
    "#         test['season_info'] = 2\n",
    "        \n",
    "        if self.usetimelinefeature:\n",
    "            \n",
    "            test['gameday'] = ~test['battingOrder'].isna()*1\n",
    "            test = pd.merge(test, self.train_features_dict['train_last_game'], on=['playerId'], how='left')\n",
    "            test['daysSinceLastGame'] = (pd.to_datetime(test['date'], format=\"%Y%m%d\") - pd.to_datetime(test['lastdate'], format=\"%Y%m%d\")).dt.days\n",
    "            test.loc[test['gameday']==1,'daysSinceLastGame']=0\n",
    "            \n",
    "            self.train_features_dict['train_last_game'] = pd.merge(self.train_features_dict['train_last_game'], test[test['gameday']==1][['playerId','date']], on=['playerId'], how='left')\n",
    "            self.train_features_dict['train_last_game']['lastdate'].update(self.train_features_dict['train_last_game']['date'])\n",
    "            self.train_features_dict['train_last_game'] = self.train_features_dict['train_last_game'][['playerId', 'lastdate']]\n",
    "                        \n",
    "            test['rosterday'] = ~test['status'].isna()*1\n",
    "            test = pd.merge(test, self.train_features_dict['train_last_roster'], on=['playerId'], how='left')\n",
    "            test['daysSinceLastRoster'] = (pd.to_datetime(test['date'], format=\"%Y%m%d\") - pd.to_datetime(test['lastroster'], format=\"%Y%m%d\")).dt.days\n",
    "            test.loc[test['rosterday']==1,'daysSinceLastRoster']=0\n",
    "            \n",
    "            self.train_features_dict['train_last_roster'] = pd.merge(self.train_features_dict['train_last_roster'], test[test['rosterday']==1][['playerId','date']], on=['playerId'], how='left')\n",
    "            self.train_features_dict['train_last_roster']['lastroster'].update(self.train_features_dict['train_last_roster']['date'])\n",
    "            self.train_features_dict['train_last_roster'] = self.train_features_dict['train_last_roster'][['playerId', 'lastroster']]\n",
    "            \n",
    "        test_gameday = test[test['gameday']==1]\n",
    "        \n",
    "        if len(test_gameday) != 0:\n",
    "            gameday_index = list(test_gameday.index)\n",
    "\n",
    "            test_X = test.iloc[gameday_index]\n",
    "            \n",
    "\n",
    "            pred1 = self.models_gameday[0][4].predict(test_X[self.feature_cols1])\n",
    "            pred2 = self.models_gameday[1][4].predict(test_X[self.feature_cols2])\n",
    "            pred3 = self.models_gameday[2][4].predict(test_X[self.feature_cols3])\n",
    "            pred4 = self.models_gameday[3][4].predict(test_X[self.feature_cols4])\n",
    "\n",
    "            # merge submission\n",
    "            sample_prediction_df['target1'].iloc[gameday_index] = pred1\n",
    "            sample_prediction_df['target2'].iloc[gameday_index] = pred2\n",
    "            sample_prediction_df['target3'].iloc[gameday_index] = pred3\n",
    "            sample_prediction_df['target4'].iloc[gameday_index] = pred4\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        test_notgameday = test[test['gameday']==0]\n",
    "        if len(test_notgameday) != 0:\n",
    "            notgameday_index = list(test_notgameday.index)\n",
    "\n",
    "            test_X = test.iloc[notgameday_index]\n",
    "\n",
    "            pred1 = self.models_notgameday[0][4].predict(test_X[self.feature_cols1])\n",
    "            pred2 = self.models_notgameday[1][4].predict(test_X[self.feature_cols2])\n",
    "            pred3 = self.models_notgameday[2][4].predict(test_X[self.feature_cols3])\n",
    "            pred4 = self.models_notgameday[3][4].predict(test_X[self.feature_cols4])\n",
    "\n",
    "            # merge submission\n",
    "            sample_prediction_df['target1'].iloc[notgameday_index] = pred1\n",
    "            sample_prediction_df['target2'].iloc[notgameday_index] = pred2\n",
    "            sample_prediction_df['target3'].iloc[notgameday_index] = pred3\n",
    "            sample_prediction_df['target4'].iloc[notgameday_index] = pred4\n",
    "\n",
    "        sample_prediction_df = sample_prediction_df.fillna(0.)\n",
    "        \n",
    "        sample_prediction_df['target1'] = np.clip(sample_prediction_df['target1'], 0, 100)\n",
    "        sample_prediction_df['target2'] = np.clip(sample_prediction_df['target2'], 0, 100)\n",
    "        sample_prediction_df['target3'] = np.clip(sample_prediction_df['target3'], 0, 100)\n",
    "        sample_prediction_df['target4'] = np.clip(sample_prediction_df['target4'], 0, 100)\n",
    "\n",
    "        del sample_prediction_df['playerId']\n",
    "        del sample_prediction_df['date']\n",
    "        \n",
    "        return sample_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b381a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc target stat ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2061/2061 [00:46<00:00, 44.40it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 41.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "preprocess ... done.\n",
      "creat feature ... done.\n"
     ]
    }
   ],
   "source": [
    "rt4kaido_train = Rt4kaidoTrain(usetimelinefeature=True)\n",
    "train, train_features_dict = rt4kaido_train.make_feature(train_elements_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d5b4e2be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9190642982206391, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9190642982206391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8602941852412167, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8602941852412167\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.693631\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's l1: 0.691598\n",
      "mae: 0.6915866085254493\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9367028357310329, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9367028357310329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4918512249239658, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4918512249239658\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.67639\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's l1: 2.58003\n",
      "mae: 2.580033758090487\n",
      "[LightGBM] [Warning] feature_fraction is set=0.999031125349641, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.999031125349641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149807933910547, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7149807933910547\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.87757\n",
      "Early stopping, best iteration is:\n",
      "[12]\tvalid_0's l1: 0.863006\n",
      "mae: 0.8630062488162205\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9003128313130303, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.9003128313130303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8113363312593455, subsample=0.9 will be ignored. Current value: bagging_fraction=0.8113363312593455\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.35595\n",
      "[200]\tvalid_0's l1: 1.35504\n",
      "[300]\tvalid_0's l1: 1.3546\n",
      "[400]\tvalid_0's l1: 1.35364\n",
      "[500]\tvalid_0's l1: 1.3481\n",
      "[600]\tvalid_0's l1: 1.34509\n",
      "[700]\tvalid_0's l1: 1.34002\n",
      "[800]\tvalid_0's l1: 1.33411\n",
      "[900]\tvalid_0's l1: 1.32928\n",
      "[1000]\tvalid_0's l1: 1.32308\n",
      "[1100]\tvalid_0's l1: 1.32091\n",
      "[1200]\tvalid_0's l1: 1.31463\n",
      "[1300]\tvalid_0's l1: 1.30807\n",
      "[1400]\tvalid_0's l1: 1.3072\n",
      "Early stopping, best iteration is:\n",
      "[1388]\tvalid_0's l1: 1.3063\n",
      "mae: 1.3053179700562043\n",
      "score: 1.3599861463720901\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9190642982206391, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9190642982206391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8602941852412167, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8602941852412167\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.864486\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's l1: 0.848959\n",
      "mae: 0.8489453217064908\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9367028357310329, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9367028357310329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4918512249239658, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4918512249239658\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.42565\n",
      "Early stopping, best iteration is:\n",
      "[30]\tvalid_0's l1: 2.40105\n",
      "mae: 2.401048390063975\n",
      "[LightGBM] [Warning] feature_fraction is set=0.999031125349641, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.999031125349641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149807933910547, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7149807933910547\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.919469\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 0.909756\n",
      "mae: 0.9097556061241735\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9003128313130303, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.9003128313130303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8113363312593455, subsample=0.9 will be ignored. Current value: bagging_fraction=0.8113363312593455\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.30969\n",
      "[200]\tvalid_0's l1: 1.30874\n",
      "[300]\tvalid_0's l1: 1.30852\n",
      "[400]\tvalid_0's l1: 1.3038\n",
      "[500]\tvalid_0's l1: 1.30204\n",
      "[600]\tvalid_0's l1: 1.29587\n",
      "[700]\tvalid_0's l1: 1.30226\n",
      "Early stopping, best iteration is:\n",
      "[627]\tvalid_0's l1: 1.29426\n",
      "mae: 1.293878354393076\n",
      "score: 1.3634069180719288\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9190642982206391, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9190642982206391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8602941852412167, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8602941852412167\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.811857\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's l1: 0.792495\n",
      "mae: 0.7924896307491222\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9367028357310329, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9367028357310329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4918512249239658, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4918512249239658\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.27715\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's l1: 2.25848\n",
      "mae: 2.258477321829415\n",
      "[LightGBM] [Warning] feature_fraction is set=0.999031125349641, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.999031125349641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149807933910547, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7149807933910547\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.10726\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's l1: 1.10582\n",
      "mae: 1.105815157059218\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9003128313130303, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.9003128313130303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8113363312593455, subsample=0.9 will be ignored. Current value: bagging_fraction=0.8113363312593455\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.31885\n",
      "[200]\tvalid_0's l1: 1.31633\n",
      "[300]\tvalid_0's l1: 1.31609\n",
      "[400]\tvalid_0's l1: 1.31355\n",
      "[500]\tvalid_0's l1: 1.30913\n",
      "[600]\tvalid_0's l1: 1.30166\n",
      "[700]\tvalid_0's l1: 1.29874\n",
      "[800]\tvalid_0's l1: 1.29535\n",
      "[900]\tvalid_0's l1: 1.29607\n",
      "Early stopping, best iteration is:\n",
      "[831]\tvalid_0's l1: 1.2949\n",
      "mae: 1.293711647666286\n",
      "score: 1.3626234393260104\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9190642982206391, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9190642982206391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8602941852412167, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8602941852412167\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.1501\n",
      "[200]\tvalid_0's l1: 1.14539\n",
      "Early stopping, best iteration is:\n",
      "[180]\tvalid_0's l1: 1.1452\n",
      "mae: 1.1449684342542863\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9367028357310329, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9367028357310329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4918512249239658, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4918512249239658\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.28421\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's l1: 2.21454\n",
      "mae: 2.2145412298656657\n",
      "[LightGBM] [Warning] feature_fraction is set=0.999031125349641, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.999031125349641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149807933910547, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7149807933910547\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.929048\n",
      "Early stopping, best iteration is:\n",
      "[38]\tvalid_0's l1: 0.927619\n",
      "mae: 0.9276157508208426\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9003128313130303, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.9003128313130303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8113363312593455, subsample=0.9 will be ignored. Current value: bagging_fraction=0.8113363312593455\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.58249\n",
      "[200]\tvalid_0's l1: 1.57894\n",
      "[300]\tvalid_0's l1: 1.57701\n",
      "[400]\tvalid_0's l1: 1.57411\n",
      "[500]\tvalid_0's l1: 1.57146\n",
      "[600]\tvalid_0's l1: 1.5708\n",
      "[700]\tvalid_0's l1: 1.56849\n",
      "[800]\tvalid_0's l1: 1.56349\n",
      "[900]\tvalid_0's l1: 1.56744\n",
      "Early stopping, best iteration is:\n",
      "[826]\tvalid_0's l1: 1.56093\n",
      "mae: 1.5601907438294513\n",
      "score: 1.4618290396925615\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9190642982206391, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9190642982206391\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8602941852412167, subsample=0.6 will be ignored. Current value: bagging_fraction=0.8602941852412167\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.07209\n",
      "[200]\tvalid_0's l1: 1.07094\n",
      "Early stopping, best iteration is:\n",
      "[186]\tvalid_0's l1: 1.07018\n",
      "mae: 1.0699630183348348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9367028357310329, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9367028357310329\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4918512249239658, subsample=0.7 will be ignored. Current value: bagging_fraction=0.4918512249239658\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.07593\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's l1: 2.0261\n",
      "mae: 2.0260989674901775\n",
      "[LightGBM] [Warning] feature_fraction is set=0.999031125349641, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.999031125349641\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7149807933910547, subsample=0.6 will be ignored. Current value: bagging_fraction=0.7149807933910547\n",
      "[LightGBM] [Warning] bagging_freq is set=10, subsample_freq=0 will be ignored. Current value: bagging_freq=10\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 0.861545\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's l1: 0.855131\n",
      "mae: 0.8551313584809834\n",
      "[LightGBM] [Warning] feature_fraction is set=0.9003128313130303, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.9003128313130303\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.8113363312593455, subsample=0.9 will be ignored. Current value: bagging_fraction=0.8113363312593455\n",
      "[LightGBM] [Warning] bagging_freq is set=17, subsample_freq=0 will be ignored. Current value: bagging_freq=17\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.1773\n",
      "[200]\tvalid_0's l1: 1.17685\n",
      "[300]\tvalid_0's l1: 1.17706\n",
      "Early stopping, best iteration is:\n",
      "[249]\tvalid_0's l1: 1.17618\n",
      "mae: 1.1761599686093234\n",
      "score: 1.28183832822883\n",
      "\n",
      "--------------------------------------------\n",
      "0fold mae: 1.3599861463720901\n",
      "1fold mae: 1.3634069180719288\n",
      "2fold mae: 1.3626234393260104\n",
      "3fold mae: 1.4618290396925615\n",
      "4fold mae: 1.28183832822883\n",
      "oof mae: 1.366229407047539\n",
      "--------------------------------------------\n",
      "---------------April evaluate-------------------\n",
      "0fold mae: 1.3125206976849355\n",
      "1fold mae: 1.3157036002259959\n",
      "2fold mae: 1.309478590824023\n",
      "3fold mae: 1.2948195937836742\n",
      "4fold mae: 1.28183832822883\n",
      "oof mae: 1.2845259971832983\n",
      "--------------------------------------------\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7371239177317086, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.7371239177317086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7812193424369623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7812193424369623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.8814\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's l1: 1.87776\n",
      "mae: 1.877606029433604\n",
      "[LightGBM] [Warning] feature_fraction is set=0.689102086803655, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.689102086803655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529672595341992, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5529672595341992\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 3.12915\n",
      "[200]\tvalid_0's l1: 3.14271\n",
      "Early stopping, best iteration is:\n",
      "[123]\tvalid_0's l1: 3.12231\n",
      "mae: 3.12231367749805\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865874475429003, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.865874475429003\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9975448137502082, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9975448137502082\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.83799\n",
      "Early stopping, best iteration is:\n",
      "[13]\tvalid_0's l1: 1.81325\n",
      "mae: 1.8132518264738067\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5100430719886615, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5100430719886615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9444400283463885, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9444400283463885\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.31221\n",
      "[200]\tvalid_0's l1: 2.299\n",
      "[300]\tvalid_0's l1: 2.26131\n",
      "[400]\tvalid_0's l1: 2.22147\n",
      "[500]\tvalid_0's l1: 2.20867\n",
      "[600]\tvalid_0's l1: 2.19096\n",
      "[700]\tvalid_0's l1: 2.16106\n",
      "[800]\tvalid_0's l1: 2.15337\n",
      "[900]\tvalid_0's l1: 2.1528\n",
      "[1000]\tvalid_0's l1: 2.14426\n",
      "[1100]\tvalid_0's l1: 2.14589\n",
      "Early stopping, best iteration is:\n",
      "[1003]\tvalid_0's l1: 2.14425\n",
      "mae: 2.1414340725464966\n",
      "score: 2.2386514014879895\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7371239177317086, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.7371239177317086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7812193424369623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7812193424369623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.22119\n",
      "Early stopping, best iteration is:\n",
      "[29]\tvalid_0's l1: 2.19232\n",
      "mae: 2.1923144109767865\n",
      "[LightGBM] [Warning] feature_fraction is set=0.689102086803655, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.689102086803655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529672595341992, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5529672595341992\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 3.17146\n",
      "[200]\tvalid_0's l1: 3.13747\n",
      "[300]\tvalid_0's l1: 3.12274\n",
      "[400]\tvalid_0's l1: 3.11486\n",
      "[500]\tvalid_0's l1: 3.11212\n",
      "[600]\tvalid_0's l1: 3.10677\n",
      "[700]\tvalid_0's l1: 3.09983\n",
      "[800]\tvalid_0's l1: 3.09411\n",
      "[900]\tvalid_0's l1: 3.09218\n",
      "[1000]\tvalid_0's l1: 3.08966\n",
      "Early stopping, best iteration is:\n",
      "[917]\tvalid_0's l1: 3.08861\n",
      "mae: 3.083762565456949\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865874475429003, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.865874475429003\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9975448137502082, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9975448137502082\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.82535\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's l1: 1.81483\n",
      "mae: 1.814831130658126\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5100430719886615, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5100430719886615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9444400283463885, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9444400283463885\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.15995\n",
      "[200]\tvalid_0's l1: 2.15289\n",
      "Early stopping, best iteration is:\n",
      "[183]\tvalid_0's l1: 2.14597\n",
      "mae: 2.1454804129920717\n",
      "score: 2.3090971300209833\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7371239177317086, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.7371239177317086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7812193424369623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7812193424369623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.07855\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's l1: 2.0629\n",
      "mae: 2.062903508507463\n",
      "[LightGBM] [Warning] feature_fraction is set=0.689102086803655, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.689102086803655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529672595341992, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5529672595341992\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 3.12485\n",
      "[200]\tvalid_0's l1: 3.09872\n",
      "[300]\tvalid_0's l1: 3.08593\n",
      "[400]\tvalid_0's l1: 3.07756\n",
      "[500]\tvalid_0's l1: 3.07128\n",
      "[600]\tvalid_0's l1: 3.06352\n",
      "[700]\tvalid_0's l1: 3.06061\n",
      "[800]\tvalid_0's l1: 3.05125\n",
      "[900]\tvalid_0's l1: 3.0456\n",
      "[1000]\tvalid_0's l1: 3.04608\n",
      "[1100]\tvalid_0's l1: 3.04312\n",
      "[1200]\tvalid_0's l1: 3.04262\n",
      "[1300]\tvalid_0's l1: 3.042\n",
      "[1400]\tvalid_0's l1: 3.03644\n",
      "Early stopping, best iteration is:\n",
      "[1372]\tvalid_0's l1: 3.03549\n",
      "mae: 3.035491577495091\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865874475429003, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.865874475429003\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9975448137502082, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9975448137502082\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.28804\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's l1: 2.28378\n",
      "mae: 2.283757747550689\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5100430719886615, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5100430719886615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9444400283463885, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9444400283463885\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.03393\n",
      "[200]\tvalid_0's l1: 2.03577\n",
      "Early stopping, best iteration is:\n",
      "[138]\tvalid_0's l1: 2.02862\n",
      "mae: 2.0275082402775393\n",
      "score: 2.3524152684576958\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7371239177317086, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.7371239177317086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7812193424369623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7812193424369623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.71328\n",
      "[200]\tvalid_0's l1: 2.69405\n",
      "[300]\tvalid_0's l1: 2.68509\n",
      "[400]\tvalid_0's l1: 2.6867\n",
      "Early stopping, best iteration is:\n",
      "[302]\tvalid_0's l1: 2.68477\n",
      "mae: 2.683884263770348\n",
      "[LightGBM] [Warning] feature_fraction is set=0.689102086803655, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.689102086803655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529672595341992, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5529672595341992\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.8849\n",
      "[200]\tvalid_0's l1: 2.8635\n",
      "[300]\tvalid_0's l1: 2.8533\n",
      "[400]\tvalid_0's l1: 2.84035\n",
      "[500]\tvalid_0's l1: 2.84125\n",
      "[600]\tvalid_0's l1: 2.84475\n",
      "Early stopping, best iteration is:\n",
      "[567]\tvalid_0's l1: 2.83908\n",
      "mae: 2.8390807280867847\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865874475429003, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.865874475429003\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9975448137502082, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9975448137502082\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.90055\n",
      "Early stopping, best iteration is:\n",
      "[39]\tvalid_0's l1: 1.89183\n",
      "mae: 1.8918185842524267\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5100430719886615, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5100430719886615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9444400283463885, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9444400283463885\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.3866\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's l1: 2.37358\n",
      "mae: 2.3735693767240935\n",
      "score: 2.4470882382084134\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7371239177317086, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.7371239177317086\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7812193424369623, subsample=0.5 will be ignored. Current value: bagging_fraction=0.7812193424369623\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.4957\n",
      "[200]\tvalid_0's l1: 2.47886\n",
      "[300]\tvalid_0's l1: 2.48231\n",
      "Early stopping, best iteration is:\n",
      "[204]\tvalid_0's l1: 2.47783\n",
      "mae: 2.4770965669051948\n",
      "[LightGBM] [Warning] feature_fraction is set=0.689102086803655, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.689102086803655\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5529672595341992, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5529672595341992\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 2.7798\n",
      "[200]\tvalid_0's l1: 2.75529\n",
      "[300]\tvalid_0's l1: 2.74558\n",
      "[400]\tvalid_0's l1: 2.74274\n",
      "[500]\tvalid_0's l1: 2.73567\n",
      "[600]\tvalid_0's l1: 2.73631\n",
      "Early stopping, best iteration is:\n",
      "[506]\tvalid_0's l1: 2.7337\n",
      "mae: 2.733696155965609\n",
      "[LightGBM] [Warning] feature_fraction is set=0.865874475429003, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.865874475429003\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9975448137502082, subsample=0.9 will be ignored. Current value: bagging_fraction=0.9975448137502082\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.58765\n",
      "Early stopping, best iteration is:\n",
      "[61]\tvalid_0's l1: 1.57907\n",
      "mae: 1.5790274044971944\n",
      "[LightGBM] [Warning] feature_fraction is set=0.5100430719886615, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.5100430719886615\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9444400283463885, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9444400283463885\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\tvalid_0's l1: 1.73447\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's l1: 1.73007\n",
      "mae: 1.730066881866133\n",
      "score: 2.1299717523085326\n",
      "\n",
      "--------------------------------------------\n",
      "0fold mae: 2.2386514014879895\n",
      "1fold mae: 2.3090971300209833\n",
      "2fold mae: 2.3524152684576958\n",
      "3fold mae: 2.4470882382084134\n",
      "4fold mae: 2.1299717523085326\n",
      "oof mae: 2.301657671280608\n",
      "--------------------------------------------\n",
      "---------------April evaluate-------------------\n",
      "0fold mae: 2.2317964951699425\n",
      "1fold mae: 2.1960998863521337\n",
      "2fold mae: 2.205144776420367\n",
      "3fold mae: 2.1393821008118543\n",
      "4fold mae: 2.1299717523085326\n",
      "oof mae: 2.1429354242527174\n",
      "--------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "oof_df, models = rt4kaido_train.train_and_evaluate(train, isgamedayonly=False)\n",
    "oof_df.to_csv(OUTPUT_DIR / f'oof{EXP_NUM}.csv')\n",
    "with open(OUTPUT_DIR / f\"models{EXP_NUM}.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(models, f)\n",
    "    \n",
    "oof_df_gameday, models_gameday = rt4kaido_train.train_and_evaluate(train, isgamedayonly=True)\n",
    "oof_df_gameday.to_csv(OUTPUT_DIR / f'oof{EXP_NUM}_gameday.csv')\n",
    "with open(OUTPUT_DIR / f\"models{EXP_NUM}_gameday.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(models_gameday, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "020819b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "del train, rt4kaido_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab9fe7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR / f\"train_features_dict{EXP_NUM}.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(train_features_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214309b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77ad8406",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(OUTPUT_DIR / f\"train_features_dict{EXP_NUM}.pickle\", mode=\"rb\") as f:\n",
    "    train_features_dict = pickle.load(f)\n",
    "    \n",
    "with open(OUTPUT_DIR / f\"models{EXP_NUM}.pickle\", mode=\"rb\") as f:\n",
    "    models = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "61d41e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt4kaido_test = Rt4kaidoTest(train_features_dict, models, models, usetimelinefeature=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b522bcb",
   "metadata": {},
   "source": [
    "## テストで取ってこれる一行はこんな感じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85406486",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ここはまあよしなに読み込む\n",
    "example_sample_submission = pd.read_csv(MAIN_DATA_DIR / \"example_sample_submission.csv\")\n",
    "example_test = pd.read_csv(MAIN_DATA_DIR / \"example_test.csv\")\n",
    "\n",
    "## nanを想定していくつかいじる\n",
    "example_test['rosters'][1] = np.nan\n",
    "example_test['playerBoxScores'][2] = np.nan\n",
    "example_test['games'][3] = np.nan\n",
    "\n",
    "## 一日ごと読み込んで，すべての日にちでうまく行くか．\n",
    "for i in range(len(example_test)):\n",
    "    test_df = example_test.set_index('date').iloc[i:i+1]\n",
    "    sample_prediction_df = example_sample_submission[example_sample_submission['date']==test_df.index[0]].set_index('date')\n",
    "    \n",
    "    ## ここで処理\n",
    "    sample_prediction_df = rt4kaido_test.test_oneline(test_df, sample_prediction_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a9b95727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_playerId</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210501_488726</td>\n",
       "      <td>3.429360</td>\n",
       "      <td>7.367882</td>\n",
       "      <td>0.199744</td>\n",
       "      <td>2.421429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210501_605218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.592663</td>\n",
       "      <td>0.100263</td>\n",
       "      <td>0.895448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210501_621563</td>\n",
       "      <td>0.174415</td>\n",
       "      <td>2.080586</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.922595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210501_670084</td>\n",
       "      <td>0.013371</td>\n",
       "      <td>0.652414</td>\n",
       "      <td>0.002285</td>\n",
       "      <td>0.366897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210501_670970</td>\n",
       "      <td>0.004776</td>\n",
       "      <td>0.168093</td>\n",
       "      <td>0.014122</td>\n",
       "      <td>0.120934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>20210501_596049</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.057808</td>\n",
       "      <td>0.001750</td>\n",
       "      <td>0.073785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>20210501_642851</td>\n",
       "      <td>0.001665</td>\n",
       "      <td>1.020548</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.103017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>20210501_596071</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.226332</td>\n",
       "      <td>0.000891</td>\n",
       "      <td>0.095052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>20210501_664901</td>\n",
       "      <td>0.010235</td>\n",
       "      <td>0.575453</td>\n",
       "      <td>0.006161</td>\n",
       "      <td>0.158663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>20210501_605525</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.601320</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.247286</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_playerId   target1   target2   target3   target4\n",
       "0     20210501_488726  3.429360  7.367882  0.199744  2.421429\n",
       "1     20210501_605218  0.000000  0.592663  0.100263  0.895448\n",
       "2     20210501_621563  0.174415  2.080586  0.010562  0.922595\n",
       "3     20210501_670084  0.013371  0.652414  0.002285  0.366897\n",
       "4     20210501_670970  0.004776  0.168093  0.014122  0.120934\n",
       "...               ...       ...       ...       ...       ...\n",
       "1182  20210501_596049  0.000229  0.057808  0.001750  0.073785\n",
       "1183  20210501_642851  0.001665  1.020548  0.000471  0.103017\n",
       "1184  20210501_596071  0.000008  0.226332  0.000891  0.095052\n",
       "1185  20210501_664901  0.010235  0.575453  0.006161  0.158663\n",
       "1186  20210501_605525  0.000578  0.601320  0.000775  0.247286\n",
       "\n",
       "[1187 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f908f24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
