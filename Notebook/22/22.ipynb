{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc49ebb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tsa.deterministic import (CalendarFourier,\n",
    "                                           CalendarSeasonality,\n",
    "                                           CalendarTimeTrend,\n",
    "                                           DeterministicProcess)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize()\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import ctypes as ct\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import statistics as st\n",
    "# import lightgbm as lgbm\n",
    "import optuna.integration.lightgbm as lgbm\n",
    "\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c0ba5af",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ef1c93",
   "metadata": {},
   "source": [
    "## Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3218ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_cols = ['playerId', 'target1', 'target2', 'target3', 'target4', 'date']\n",
    "players_cols = ['playerId', 'primaryPositionName', 'birthCity', 'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight']\n",
    "rosters_cols = ['playerId', 'teamId', 'status', 'date']\n",
    "transactions_cols = ['playerId', 'transaction_flag', 'date']\n",
    "scores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "       'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "       'assists', 'putOuts', 'errors', 'chances', 'date']\n",
    "\n",
    "feature_cols1 = ['week_day','label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "       'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "       'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "       'assists', 'putOuts', 'errors', 'chances',\n",
    "        \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_skew\",\"target1_kurt\",\n",
    "         \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_skew\",\"target2_kurt\",\n",
    "        \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_skew\",\"target3_kurt\",\n",
    "        \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_skew\",\"target4_kurt\", \n",
    "        'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr', 'daysSinceLastGame'] \n",
    "\n",
    "feature_cols2 = ['label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "       'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "       'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "       'assists', 'putOuts', 'errors', 'chances',\n",
    "        \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_skew\",\"target1_kurt\",\n",
    "         \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_skew\",\"target2_kurt\",\n",
    "        \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_skew\",\"target3_kurt\",\n",
    "        \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_skew\",\"target4_kurt\", \n",
    "        'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr', 'daysSinceLastGame'] \n",
    "\n",
    "feature_cols3 = ['week_day','label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "       'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "       'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "       'assists', 'putOuts', 'errors', 'chances',\n",
    "        \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_skew\",\"target1_kurt\",\n",
    "         \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_skew\",\"target2_kurt\",\n",
    "        \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_skew\",\"target3_kurt\",\n",
    "        \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_skew\",\"target4_kurt\", \n",
    "        'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr', 'daysSinceLastGame'] \n",
    "\n",
    "feature_cols4 = ['week_day', 'annual_day', 'month', 'label_playerId', 'label_primaryPositionName', 'label_teamId', 'label_birthCity',\n",
    "                'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight',\n",
    "       'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "       'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "       'assists', 'putOuts', 'errors', 'chances',\n",
    "        \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_skew\",\"target1_kurt\",\n",
    "         \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_skew\",\"target2_kurt\",\n",
    "        \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_skew\",\"target3_kurt\",\n",
    "        \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_skew\",\"target4_kurt\", \n",
    "        'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr', 'daysSinceLastGame'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4879aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training lightgbm\n",
    "params1 = {'objective':'mae',\n",
    "           'reg_alpha': 0.14947461820098767, \n",
    "           'reg_lambda': 0.10185644384043743, \n",
    "           'n_estimators': 3633, \n",
    "           'learning_rate': 0.08046301304430488, \n",
    "           'num_leaves': 674, \n",
    "           'feature_fraction': 0.9101240539122566, \n",
    "           'bagging_fraction': 0.9884451442950513, \n",
    "           'bagging_freq': 8, \n",
    "           'min_child_samples': 51}\n",
    "\n",
    "params2 = {'objective':'mae',\n",
    "           'reg_alpha': 0.1,\n",
    "           'reg_lambda': 0.1, \n",
    "           'n_estimators': 80,\n",
    "           'learning_rate': 0.1,\n",
    "           'random_state': 42,\n",
    "           \"num_leaves\": 22}\n",
    "\n",
    "params3 = {'objective':'mae',\n",
    "           'reg_alpha': 0.1,\n",
    "           'reg_lambda': 0.1, \n",
    "           'n_estimators': 10000,\n",
    "           'learning_rate': 0.1,\n",
    "           'random_state': 42,\n",
    "           \"num_leaves\": 100}\n",
    "\n",
    "params4 = {'objective':'mae',\n",
    "           'reg_alpha': 0.016468100279441976, \n",
    "           'reg_lambda': 0.09128335764019105, \n",
    "           'n_estimators': 9868, \n",
    "           'learning_rate': 0.10528150510326864, \n",
    "           'num_leaves': 157, \n",
    "           'feature_fraction': 0.5419185713426886, \n",
    "           'bagging_fraction': 0.2637405128936662, \n",
    "           'bagging_freq': 19, \n",
    "           'min_child_samples': 71}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25466b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NUM = 22\n",
    "NFOLDS = 5\n",
    "SEED = 777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b90fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1bd17f9",
   "metadata": {},
   "source": [
    "## Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6d6736e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/MLB-Player-Digital-Engagement-Forecasting/data/\")\n",
    "MAIN_DATA_DIR = DATA_DIR / 'mlb-player-digital-engagement-forecasting'\n",
    "TRAIN_DIR = MAIN_DATA_DIR / 'train'\n",
    "OUTPUT_DIR = Path('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84143565",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(MAIN_DATA_DIR / 'players.csv')\n",
    "\n",
    "rosters = pd.read_csv(TRAIN_DIR / 'rosters_train.csv')\n",
    "targets = pd.read_csv(TRAIN_DIR / 'nextDayPlayerEngagement_train.csv')\n",
    "scores = pd.read_csv(TRAIN_DIR / 'playerBoxScores_train.csv')\n",
    "scores = scores.groupby(['playerId', 'date']).sum().reset_index()\n",
    "seasons = pd.read_csv(MAIN_DATA_DIR / 'seasons.csv')\n",
    "\n",
    "# events = pd.read_csv(TRAIN_DIR / 'events_train.csv')\n",
    "# events = events.groupby(['gameDate']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af963dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>date</th>\n",
       "      <th>home</th>\n",
       "      <th>gamePk</th>\n",
       "      <th>teamId</th>\n",
       "      <th>jerseyNum</th>\n",
       "      <th>positionCode</th>\n",
       "      <th>battingOrder</th>\n",
       "      <th>gamesPlayedBatting</th>\n",
       "      <th>flyOuts</th>\n",
       "      <th>...</th>\n",
       "      <th>sacBuntsPitching</th>\n",
       "      <th>sacFliesPitching</th>\n",
       "      <th>saves</th>\n",
       "      <th>holds</th>\n",
       "      <th>blownSaves</th>\n",
       "      <th>assists</th>\n",
       "      <th>putOuts</th>\n",
       "      <th>errors</th>\n",
       "      <th>chances</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112526</td>\n",
       "      <td>20180402</td>\n",
       "      <td>0</td>\n",
       "      <td>529469</td>\n",
       "      <td>140</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112526</td>\n",
       "      <td>20180408</td>\n",
       "      <td>1</td>\n",
       "      <td>529546</td>\n",
       "      <td>140</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112526</td>\n",
       "      <td>20180410</td>\n",
       "      <td>1</td>\n",
       "      <td>529565</td>\n",
       "      <td>140</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112526</td>\n",
       "      <td>20180415</td>\n",
       "      <td>0</td>\n",
       "      <td>529640</td>\n",
       "      <td>140</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112526</td>\n",
       "      <td>20180421</td>\n",
       "      <td>1</td>\n",
       "      <td>529718</td>\n",
       "      <td>140</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182945</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210409</td>\n",
       "      <td>1</td>\n",
       "      <td>634478</td>\n",
       "      <td>140</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182946</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210414</td>\n",
       "      <td>0</td>\n",
       "      <td>634496</td>\n",
       "      <td>140</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182947</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210419</td>\n",
       "      <td>0</td>\n",
       "      <td>634536</td>\n",
       "      <td>140</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182948</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210425</td>\n",
       "      <td>0</td>\n",
       "      <td>634393</td>\n",
       "      <td>140</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182949</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210430</td>\n",
       "      <td>1</td>\n",
       "      <td>634337</td>\n",
       "      <td>140</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182950 rows × 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        playerId      date  home  gamePk  teamId  jerseyNum  positionCode  \\\n",
       "0         112526  20180402     0  529469     140       40.0             1   \n",
       "1         112526  20180408     1  529546     140       40.0             1   \n",
       "2         112526  20180410     1  529565     140       40.0             1   \n",
       "3         112526  20180415     0  529640     140       40.0             1   \n",
       "4         112526  20180421     1  529718     140       40.0             1   \n",
       "...          ...       ...   ...     ...     ...        ...           ...   \n",
       "182945    685503  20210409     1  634478     140       35.0             1   \n",
       "182946    685503  20210414     0  634496     140       35.0             1   \n",
       "182947    685503  20210419     0  634536     140       35.0             1   \n",
       "182948    685503  20210425     0  634393     140       35.0             1   \n",
       "182949    685503  20210430     1  634337     140       35.0             1   \n",
       "\n",
       "        battingOrder  gamesPlayedBatting  flyOuts  ...  sacBuntsPitching  \\\n",
       "0                0.0                 0.0      0.0  ...               0.0   \n",
       "1                0.0                 0.0      0.0  ...               0.0   \n",
       "2                0.0                 0.0      0.0  ...               0.0   \n",
       "3                0.0                 0.0      0.0  ...               0.0   \n",
       "4                0.0                 0.0      0.0  ...               0.0   \n",
       "...              ...                 ...      ...  ...               ...   \n",
       "182945           0.0                 0.0      0.0  ...               0.0   \n",
       "182946           0.0                 0.0      0.0  ...               0.0   \n",
       "182947           0.0                 0.0      0.0  ...               0.0   \n",
       "182948           0.0                 0.0      0.0  ...               0.0   \n",
       "182949           0.0                 0.0      0.0  ...               0.0   \n",
       "\n",
       "        sacFliesPitching  saves  holds  blownSaves  assists  putOuts  errors  \\\n",
       "0                    0.0    0.0    0.0         0.0      1.0      0.0     0.0   \n",
       "1                    0.0    0.0    0.0         0.0      0.0      1.0     0.0   \n",
       "2                    1.0    0.0    0.0         0.0      2.0      0.0     0.0   \n",
       "3                    1.0    0.0    0.0         0.0      1.0      0.0     0.0   \n",
       "4                    1.0    0.0    0.0         0.0      0.0      2.0     0.0   \n",
       "...                  ...    ...    ...         ...      ...      ...     ...   \n",
       "182945               0.0    0.0    0.0         0.0      0.0      1.0     0.0   \n",
       "182946               0.0    0.0    0.0         0.0      1.0      0.0     0.0   \n",
       "182947               0.0    0.0    0.0         0.0      0.0      0.0     0.0   \n",
       "182948               1.0    0.0    0.0         0.0      0.0      0.0     0.0   \n",
       "182949               0.0    0.0    0.0         0.0      0.0      0.0     0.0   \n",
       "\n",
       "        chances  index  \n",
       "0           1.0     91  \n",
       "1           1.0     97  \n",
       "2           2.0     99  \n",
       "3           1.0    104  \n",
       "4           2.0    110  \n",
       "...         ...    ...  \n",
       "182945      1.0   1194  \n",
       "182946      1.0   1199  \n",
       "182947      0.0   1204  \n",
       "182948      0.0   1210  \n",
       "182949      0.0   1215  \n",
       "\n",
       "[182950 rows x 81 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d353e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seasonId</th>\n",
       "      <th>seasonStartDate</th>\n",
       "      <th>seasonEndDate</th>\n",
       "      <th>preSeasonStartDate</th>\n",
       "      <th>preSeasonEndDate</th>\n",
       "      <th>regularSeasonStartDate</th>\n",
       "      <th>regularSeasonEndDate</th>\n",
       "      <th>lastDate1stHalf</th>\n",
       "      <th>allStarDate</th>\n",
       "      <th>firstDate2ndHalf</th>\n",
       "      <th>postSeasonStartDate</th>\n",
       "      <th>postSeasonEndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-11-01</td>\n",
       "      <td>2017-02-22</td>\n",
       "      <td>2017-04-01</td>\n",
       "      <td>2017-04-02</td>\n",
       "      <td>2017-10-01</td>\n",
       "      <td>2017-07-09</td>\n",
       "      <td>2017-07-11</td>\n",
       "      <td>2017-07-14</td>\n",
       "      <td>2017-10-03</td>\n",
       "      <td>2017-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>2018-10-28</td>\n",
       "      <td>2018-02-21</td>\n",
       "      <td>2018-03-27</td>\n",
       "      <td>2018-03-29</td>\n",
       "      <td>2018-10-01</td>\n",
       "      <td>2018-07-15</td>\n",
       "      <td>2018-07-17</td>\n",
       "      <td>2018-07-19</td>\n",
       "      <td>2018-10-02</td>\n",
       "      <td>2018-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-10-30</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>2019-03-20</td>\n",
       "      <td>2019-09-29</td>\n",
       "      <td>2019-07-07</td>\n",
       "      <td>2019-07-09</td>\n",
       "      <td>2019-07-11</td>\n",
       "      <td>2019-10-01</td>\n",
       "      <td>2019-10-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020-10-28</td>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2020-07-22</td>\n",
       "      <td>2020-07-23</td>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>2020-08-25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-26</td>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-10-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-10-31</td>\n",
       "      <td>2021-02-28</td>\n",
       "      <td>2021-03-30</td>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>2021-07-11</td>\n",
       "      <td>2021-07-13</td>\n",
       "      <td>2021-07-15</td>\n",
       "      <td>2021-10-04</td>\n",
       "      <td>2021-10-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seasonId seasonStartDate seasonEndDate preSeasonStartDate preSeasonEndDate  \\\n",
       "0      2017      2017-04-02    2017-11-01         2017-02-22       2017-04-01   \n",
       "1      2018      2018-03-29    2018-10-28         2018-02-21       2018-03-27   \n",
       "2      2019      2019-03-20    2019-10-30         2019-02-21       2019-03-26   \n",
       "3      2020      2020-07-23    2020-10-28         2020-02-21       2020-07-22   \n",
       "4      2021      2021-02-28    2021-10-31         2021-02-28       2021-03-30   \n",
       "\n",
       "  regularSeasonStartDate regularSeasonEndDate lastDate1stHalf allStarDate  \\\n",
       "0             2017-04-02           2017-10-01      2017-07-09  2017-07-11   \n",
       "1             2018-03-29           2018-10-01      2018-07-15  2018-07-17   \n",
       "2             2019-03-20           2019-09-29      2019-07-07  2019-07-09   \n",
       "3             2020-07-23           2020-09-27      2020-08-25         NaN   \n",
       "4             2021-04-01           2021-10-03      2021-07-11  2021-07-13   \n",
       "\n",
       "  firstDate2ndHalf postSeasonStartDate postSeasonEndDate  \n",
       "0       2017-07-14          2017-10-03        2017-11-01  \n",
       "1       2018-07-19          2018-10-02        2018-10-28  \n",
       "2       2019-07-11          2019-10-01        2019-10-30  \n",
       "3       2020-08-26          2020-09-29        2020-10-28  \n",
       "4       2021-07-15          2021-10-04        2021-10-31  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8fd2411",
   "metadata": {},
   "outputs": [],
   "source": [
    "seasons_startend = seasons\n",
    "seasons_startend['seasonStartDate'] = seasons_startend['seasonStartDate'].str.replace('-', '').astype(int)\n",
    "seasons_startend['seasonEndDate'] = seasons_startend['seasonEndDate'].str.replace('-', '').astype(int)\n",
    "seasons_startend = seasons_startend[['seasonStartDate', 'seasonEndDate']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15ca5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = targets[(targets['date'] >= 20210331)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "675ce6b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>engagementMetricsDate</th>\n",
       "      <th>playerId</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>index</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2442285</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>502210</td>\n",
       "      <td>0.017134</td>\n",
       "      <td>3.877565</td>\n",
       "      <td>0.003982</td>\n",
       "      <td>14.986099</td>\n",
       "      <td>1185</td>\n",
       "      <td>20210331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442286</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>630105</td>\n",
       "      <td>0.090707</td>\n",
       "      <td>15.558301</td>\n",
       "      <td>0.014335</td>\n",
       "      <td>1.734738</td>\n",
       "      <td>1185</td>\n",
       "      <td>20210331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442287</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>621532</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.288244</td>\n",
       "      <td>0.000398</td>\n",
       "      <td>0.129224</td>\n",
       "      <td>1185</td>\n",
       "      <td>20210331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442288</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>468504</td>\n",
       "      <td>0.008391</td>\n",
       "      <td>5.922723</td>\n",
       "      <td>0.986705</td>\n",
       "      <td>2.365196</td>\n",
       "      <td>1185</td>\n",
       "      <td>20210331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2442289</th>\n",
       "      <td>2021-04-01</td>\n",
       "      <td>657108</td>\n",
       "      <td>1.105526</td>\n",
       "      <td>10.486583</td>\n",
       "      <td>0.070877</td>\n",
       "      <td>1.585934</td>\n",
       "      <td>1185</td>\n",
       "      <td>20210331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506171</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>451661</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.625925</td>\n",
       "      <td>1215</td>\n",
       "      <td>20210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506172</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>519301</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.003329</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.216229</td>\n",
       "      <td>1215</td>\n",
       "      <td>20210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506173</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>527055</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.273131</td>\n",
       "      <td>1215</td>\n",
       "      <td>20210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506174</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>543484</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.056586</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.024240</td>\n",
       "      <td>1215</td>\n",
       "      <td>20210430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2506175</th>\n",
       "      <td>2021-05-01</td>\n",
       "      <td>605525</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.499284</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.386935</td>\n",
       "      <td>1215</td>\n",
       "      <td>20210430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        engagementMetricsDate  playerId   target1    target2   target3  \\\n",
       "2442285            2021-04-01    502210  0.017134   3.877565  0.003982   \n",
       "2442286            2021-04-01    630105  0.090707  15.558301  0.014335   \n",
       "2442287            2021-04-01    621532  0.000353   0.288244  0.000398   \n",
       "2442288            2021-04-01    468504  0.008391   5.922723  0.986705   \n",
       "2442289            2021-04-01    657108  1.105526  10.486583  0.070877   \n",
       "...                       ...       ...       ...        ...       ...   \n",
       "2506171            2021-05-01    451661  0.000000   0.013314  0.000000   \n",
       "2506172            2021-05-01    519301  0.000131   0.003329  0.000000   \n",
       "2506173            2021-05-01    527055  0.000000   0.019971  0.000000   \n",
       "2506174            2021-05-01    543484  0.000131   0.056586  0.000000   \n",
       "2506175            2021-05-01    605525  0.000131   0.499284  0.000000   \n",
       "\n",
       "           target4  index      date  \n",
       "2442285  14.986099   1185  20210331  \n",
       "2442286   1.734738   1185  20210331  \n",
       "2442287   0.129224   1185  20210331  \n",
       "2442288   2.365196   1185  20210331  \n",
       "2442289   1.585934   1185  20210331  \n",
       "...            ...    ...       ...  \n",
       "2506171   0.625925   1215  20210430  \n",
       "2506172   0.216229   1215  20210430  \n",
       "2506173   0.273131   1215  20210430  \n",
       "2506174   1.024240   1215  20210430  \n",
       "2506175   0.386935   1215  20210430  \n",
       "\n",
       "[63891 rows x 8 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b348761e",
   "metadata": {},
   "outputs": [],
   "source": [
    "playerId_list = targets_train['playerId'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3bf58f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corr(df):\n",
    "    # 相関係数行列を作成\n",
    "    corr_mat = df.corr(method='pearson')\n",
    "\n",
    "    # 行（列）サイズを取得\n",
    "    n = corr_mat.shape[0]\n",
    "    corr_ary = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if i == j:\n",
    "                continue\n",
    "            corr_ary.append(corr_mat.iloc[i,j])\n",
    "\n",
    "    return corr_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64c7503a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2061/2061 [00:45<00:00, 45.10it/s]\n"
     ]
    }
   ],
   "source": [
    "def calc_probs(pid,df,temp):\n",
    "    to_append=[pid,'','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','']\n",
    "    targets=['target1','target2','target3','target4']\n",
    "    z=1\n",
    "    for target in targets:\n",
    "        target_prob = temp[target].tolist()\n",
    "        mean = np.mean(target_prob)\n",
    "        std = np.std(target_prob)\n",
    "        median = st.median(target_prob)\n",
    "        distribution = norm(mean, std)\n",
    "        min_weight = min(target_prob)\n",
    "        max_weight = max(target_prob)\n",
    "        values = list(np.linspace(min_weight, max_weight))\n",
    "        probabilities = [distribution.pdf(v) for v in values]\n",
    "        max_value = max(probabilities)\n",
    "        max_index = probabilities.index(max_value)\n",
    "        to_append[z]=mean\n",
    "        to_append[z+1]=median\n",
    "        to_append[z+2]=std\n",
    "        to_append[z+3]=min_weight\n",
    "        to_append[z+4]=max_weight\n",
    "        to_append[z+5]=target_prob[max_index]\n",
    "        to_append[z+6]=temp[target].skew()\n",
    "        to_append[z+7]=temp[target].kurt()\n",
    "\n",
    "        z=z+8\n",
    "    corr_ = calc_corr(temp[['target1', 'target2', 'target3', 'target4']])\n",
    "    to_append[z:] = corr_  \n",
    "    df_length = len(df)\n",
    "    df.loc[df_length] = to_append\n",
    "    return df\n",
    "    \n",
    "\n",
    "### CREATE DATAFRAME to store probabilities\n",
    "column_names = [\"playerId\", \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_prob\",\"target1_skew\",\"target1_kurt\",\n",
    "                \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_prob\",\"target2_skew\",\"target2_kurt\",\n",
    "                \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_prob\",\"target3_skew\",\"target3_kurt\",\n",
    "                \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_prob\",\"target4_skew\",\"target4_kurt\",\n",
    "                'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr']\n",
    "player_target_probs = pd.DataFrame(columns = column_names)\n",
    "    \n",
    "for pid in tqdm(playerId_list):\n",
    "    temp = targets_train[targets_train['playerId'] == pid]\n",
    "    player_target_stats=calc_probs(pid,player_target_probs,temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "460de793",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>target1_mean</th>\n",
       "      <th>target1_median</th>\n",
       "      <th>target1_std</th>\n",
       "      <th>target1_min</th>\n",
       "      <th>target1_max</th>\n",
       "      <th>target1_prob</th>\n",
       "      <th>target1_skew</th>\n",
       "      <th>target1_kurt</th>\n",
       "      <th>target2_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>target4_max</th>\n",
       "      <th>target4_prob</th>\n",
       "      <th>target4_skew</th>\n",
       "      <th>target4_kurt</th>\n",
       "      <th>tgt1_2_corr</th>\n",
       "      <th>tgt1_3_corr</th>\n",
       "      <th>tgt2_3_corr</th>\n",
       "      <th>tgt1_4_corr</th>\n",
       "      <th>tgt2_4_corr</th>\n",
       "      <th>tgt3_4_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>502210.0</td>\n",
       "      <td>0.035258</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>0.098358</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.526284</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>4.499717</td>\n",
       "      <td>21.054009</td>\n",
       "      <td>0.919837</td>\n",
       "      <td>...</td>\n",
       "      <td>26.192647</td>\n",
       "      <td>1.347459</td>\n",
       "      <td>1.787924</td>\n",
       "      <td>2.122248</td>\n",
       "      <td>0.365838</td>\n",
       "      <td>0.966925</td>\n",
       "      <td>0.303303</td>\n",
       "      <td>0.591120</td>\n",
       "      <td>0.798025</td>\n",
       "      <td>0.557092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630105.0</td>\n",
       "      <td>1.851187</td>\n",
       "      <td>0.321727</td>\n",
       "      <td>4.662844</td>\n",
       "      <td>0.003946</td>\n",
       "      <td>25.603476</td>\n",
       "      <td>2.889937</td>\n",
       "      <td>4.520046</td>\n",
       "      <td>22.436395</td>\n",
       "      <td>8.003389</td>\n",
       "      <td>...</td>\n",
       "      <td>19.266433</td>\n",
       "      <td>0.541118</td>\n",
       "      <td>2.754461</td>\n",
       "      <td>8.490212</td>\n",
       "      <td>-0.104008</td>\n",
       "      <td>-0.050415</td>\n",
       "      <td>0.758184</td>\n",
       "      <td>0.009365</td>\n",
       "      <td>0.480758</td>\n",
       "      <td>0.460726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>621532.0</td>\n",
       "      <td>0.147777</td>\n",
       "      <td>0.001076</td>\n",
       "      <td>0.477206</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>2.460910</td>\n",
       "      <td>0.003597</td>\n",
       "      <td>4.184232</td>\n",
       "      <td>18.542939</td>\n",
       "      <td>1.090120</td>\n",
       "      <td>...</td>\n",
       "      <td>1.665259</td>\n",
       "      <td>0.062903</td>\n",
       "      <td>2.064791</td>\n",
       "      <td>5.671338</td>\n",
       "      <td>0.140293</td>\n",
       "      <td>0.202812</td>\n",
       "      <td>0.365802</td>\n",
       "      <td>0.223219</td>\n",
       "      <td>0.895560</td>\n",
       "      <td>0.207544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>468504.0</td>\n",
       "      <td>0.046117</td>\n",
       "      <td>0.001027</td>\n",
       "      <td>0.235568</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1.335765</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>5.559476</td>\n",
       "      <td>30.935286</td>\n",
       "      <td>1.579193</td>\n",
       "      <td>...</td>\n",
       "      <td>7.059931</td>\n",
       "      <td>0.936390</td>\n",
       "      <td>3.184795</td>\n",
       "      <td>9.878932</td>\n",
       "      <td>-0.016434</td>\n",
       "      <td>-0.034419</td>\n",
       "      <td>0.495791</td>\n",
       "      <td>-0.071227</td>\n",
       "      <td>0.779922</td>\n",
       "      <td>0.278867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>657108.0</td>\n",
       "      <td>0.888194</td>\n",
       "      <td>0.043234</td>\n",
       "      <td>1.883895</td>\n",
       "      <td>0.004996</td>\n",
       "      <td>7.304291</td>\n",
       "      <td>6.176932</td>\n",
       "      <td>2.601388</td>\n",
       "      <td>5.841344</td>\n",
       "      <td>3.955265</td>\n",
       "      <td>...</td>\n",
       "      <td>4.739336</td>\n",
       "      <td>0.386319</td>\n",
       "      <td>1.349708</td>\n",
       "      <td>1.617276</td>\n",
       "      <td>0.492365</td>\n",
       "      <td>-0.135687</td>\n",
       "      <td>-0.284340</td>\n",
       "      <td>0.192405</td>\n",
       "      <td>0.608338</td>\n",
       "      <td>-0.293661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>606944.0</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.289845</td>\n",
       "      <td>19.732662</td>\n",
       "      <td>0.032395</td>\n",
       "      <td>...</td>\n",
       "      <td>1.081545</td>\n",
       "      <td>1.081545</td>\n",
       "      <td>3.559596</td>\n",
       "      <td>15.202383</td>\n",
       "      <td>0.107582</td>\n",
       "      <td>0.206886</td>\n",
       "      <td>0.432962</td>\n",
       "      <td>-0.066227</td>\n",
       "      <td>0.261404</td>\n",
       "      <td>-0.039798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>620982.0</td>\n",
       "      <td>0.000053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.205614</td>\n",
       "      <td>28.050238</td>\n",
       "      <td>0.012382</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121965</td>\n",
       "      <td>0.018845</td>\n",
       "      <td>1.333308</td>\n",
       "      <td>1.375743</td>\n",
       "      <td>0.044047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109889</td>\n",
       "      <td>0.322029</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>462480.0</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.757828</td>\n",
       "      <td>13.043766</td>\n",
       "      <td>0.003493</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203910</td>\n",
       "      <td>0.123635</td>\n",
       "      <td>1.207814</td>\n",
       "      <td>1.094314</td>\n",
       "      <td>-0.023063</td>\n",
       "      <td>-0.047835</td>\n",
       "      <td>0.407347</td>\n",
       "      <td>0.059401</td>\n",
       "      <td>0.126776</td>\n",
       "      <td>0.021881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>667465.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085977</td>\n",
       "      <td>...</td>\n",
       "      <td>0.350299</td>\n",
       "      <td>0.009643</td>\n",
       "      <td>2.585313</td>\n",
       "      <td>9.256597</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.089247</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.192105</td>\n",
       "      <td>-0.012529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>664852.0</td>\n",
       "      <td>0.028583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.131623</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.745238</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.467650</td>\n",
       "      <td>30.194602</td>\n",
       "      <td>0.462522</td>\n",
       "      <td>...</td>\n",
       "      <td>3.107319</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.320555</td>\n",
       "      <td>11.034992</td>\n",
       "      <td>0.375953</td>\n",
       "      <td>0.993728</td>\n",
       "      <td>0.427557</td>\n",
       "      <td>0.802218</td>\n",
       "      <td>0.838667</td>\n",
       "      <td>0.819693</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerId  target1_mean  target1_median  target1_std  target1_min  \\\n",
       "0     502210.0      0.035258        0.010162     0.098358     0.003972   \n",
       "1     630105.0      1.851187        0.321727     4.662844     0.003946   \n",
       "2     621532.0      0.147777        0.001076     0.477206     0.000128   \n",
       "3     468504.0      0.046117        0.001027     0.235568     0.000115   \n",
       "4     657108.0      0.888194        0.043234     1.883895     0.004996   \n",
       "...        ...           ...             ...          ...          ...   \n",
       "2056  606944.0      0.000016        0.000000     0.000058     0.000000   \n",
       "2057  620982.0      0.000053        0.000000     0.000214     0.000000   \n",
       "2058  462480.0      0.000008        0.000000     0.000030     0.000000   \n",
       "2059  667465.0      0.000000        0.000000     0.000000     0.000000   \n",
       "2060  664852.0      0.028583        0.000000     0.131623     0.000000   \n",
       "\n",
       "      target1_max  target1_prob  target1_skew  target1_kurt  target2_mean  \\\n",
       "0        0.526284      0.004923      4.499717     21.054009      0.919837   \n",
       "1       25.603476      2.889937      4.520046     22.436395      8.003389   \n",
       "2        2.460910      0.003597      4.184232     18.542939      1.090120   \n",
       "3        1.335765      0.003718      5.559476     30.935286      1.579193   \n",
       "4        7.304291      6.176932      2.601388      5.841344      3.955265   \n",
       "...           ...           ...           ...           ...           ...   \n",
       "2056     0.000303      0.000000      4.289845     19.732662      0.032395   \n",
       "2057     0.001201      0.000000      5.205614     28.050238      0.012382   \n",
       "2058     0.000131      0.000000      3.757828     13.043766      0.003493   \n",
       "2059     0.000000      0.000000      0.000000      0.000000      0.085977   \n",
       "2060     0.745238      0.000000      5.467650     30.194602      0.462522   \n",
       "\n",
       "      ...  target4_max  target4_prob  target4_skew  target4_kurt  tgt1_2_corr  \\\n",
       "0     ...    26.192647      1.347459      1.787924      2.122248     0.365838   \n",
       "1     ...    19.266433      0.541118      2.754461      8.490212    -0.104008   \n",
       "2     ...     1.665259      0.062903      2.064791      5.671338     0.140293   \n",
       "3     ...     7.059931      0.936390      3.184795      9.878932    -0.016434   \n",
       "4     ...     4.739336      0.386319      1.349708      1.617276     0.492365   \n",
       "...   ...          ...           ...           ...           ...          ...   \n",
       "2056  ...     1.081545      1.081545      3.559596     15.202383     0.107582   \n",
       "2057  ...     0.121965      0.018845      1.333308      1.375743     0.044047   \n",
       "2058  ...     0.203910      0.123635      1.207814      1.094314    -0.023063   \n",
       "2059  ...     0.350299      0.009643      2.585313      9.256597          NaN   \n",
       "2060  ...     3.107319      0.000000      3.320555     11.034992     0.375953   \n",
       "\n",
       "      tgt1_3_corr  tgt2_3_corr  tgt1_4_corr  tgt2_4_corr  tgt3_4_corr  \n",
       "0        0.966925     0.303303     0.591120     0.798025     0.557092  \n",
       "1       -0.050415     0.758184     0.009365     0.480758     0.460726  \n",
       "2        0.202812     0.365802     0.223219     0.895560     0.207544  \n",
       "3       -0.034419     0.495791    -0.071227     0.779922     0.278867  \n",
       "4       -0.135687    -0.284340     0.192405     0.608338    -0.293661  \n",
       "...           ...          ...          ...          ...          ...  \n",
       "2056     0.206886     0.432962    -0.066227     0.261404    -0.039798  \n",
       "2057          NaN          NaN     0.109889     0.322029          NaN  \n",
       "2058    -0.047835     0.407347     0.059401     0.126776     0.021881  \n",
       "2059          NaN    -0.089247          NaN     0.192105    -0.012529  \n",
       "2060     0.993728     0.427557     0.802218     0.838667     0.819693  \n",
       "\n",
       "[2061 rows x 39 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "player_target_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e5570d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_names=player_target_stats.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3dab72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "players['DOY'] = pd.to_datetime(players['DOB'], format=\"%Y-%m-%d\").dt.year\n",
    "players['mlbDebutYear'] = pd.to_datetime(players['mlbDebutDate'], format=\"%Y-%m-%d\").dt.year\n",
    "players['DebutAge'] = players['mlbDebutYear'] - players['DOY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b32f3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat dataset\n",
    "train = targets[targets_cols].merge(players[players_cols], on=['playerId'], how='left')\n",
    "train = train.merge(rosters[rosters_cols], on=['playerId', 'date'], how='left')\n",
    "train = train.merge(scores[scores_cols], on=['playerId', 'date'], how='left')\n",
    "train = train.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b169336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label encoding\n",
    "player2num = {c: i for i, c in enumerate(train['playerId'].unique())}\n",
    "position2num = {c: i for i, c in enumerate(train['primaryPositionName'].unique())}\n",
    "birthCityn2num = {c: i for i, c in enumerate(train['birthCity'].unique())}\n",
    "teamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\n",
    "status2num = {c: i for i, c in enumerate(train['status'].unique())}\n",
    "train['label_playerId'] = train['playerId'].map(player2num)\n",
    "train['label_primaryPositionName'] = train['primaryPositionName'].map(position2num)\n",
    "train['label_birthCity'] = train['birthCity'].map(birthCityn2num)\n",
    "train['label_teamId'] = train['teamId'].map(teamid2num)\n",
    "train['label_status'] = train['status'].map(status2num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9b73fe8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_ = pd.to_datetime(train['date'], format=\"%Y%m%d\")\n",
    "train['annual_day'] = (date_ - pd.to_datetime(date_.dt.year, format=\"%Y\")) /  timedelta(days=1)\n",
    "train['week_day'] = date_.dt.weekday\n",
    "train['month'] = date_.dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6200ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['gameday'] = ~train['battingOrder'].isna()*1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "de38e268",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.sort_values(by=['playerId','date'],inplace=True,ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fac08f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_consecutive_items_n_cols(df, col_name_list, output_col):\n",
    "    cum_sum_list = [\n",
    "        (df[col_name] != df[col_name].shift(1)).cumsum().tolist() for col_name in col_name_list\n",
    "    ]\n",
    "    df[output_col] = df.groupby(\n",
    "        [\"_\".join(map(str, x)) for x in zip(*cum_sum_list)]\n",
    "    ).cumcount() + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "210413b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=count_consecutive_items_n_cols(train,['playerId','gameday'],'daysSinceLastGame')\n",
    "train.loc[train['gameday']==1,'daysSinceLastGame']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d54b720d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_game = train[train['gameday']==1]\n",
    "train_last_game = train_game[~train_game.duplicated(subset='playerId', keep='last')][['playerId', 'date']]\n",
    "train_last_game.columns = ['playerId', 'lastdate']\n",
    "train_player_unique = pd.DataFrame(train['playerId'].unique(), columns=['playerId'])\n",
    "train_last_game = pd.merge(train_player_unique, train_last_game, on=['playerId'], how='left' )\n",
    "train_last_game = train_last_game.fillna(20171231)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "47dabb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>lastdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>593590</td>\n",
       "      <td>20171231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>670462</td>\n",
       "      <td>20171231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000</th>\n",
       "      <td>670764</td>\n",
       "      <td>20171231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1765</th>\n",
       "      <td>661269</td>\n",
       "      <td>20171231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1932</th>\n",
       "      <td>667674</td>\n",
       "      <td>20171231.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>542932</td>\n",
       "      <td>20210430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>641856</td>\n",
       "      <td>20210430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>641857</td>\n",
       "      <td>20210430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>543037</td>\n",
       "      <td>20210430.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210430.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerId    lastdate\n",
       "856     593590  20171231.0\n",
       "1995    670462  20171231.0\n",
       "2000    670764  20171231.0\n",
       "1765    661269  20171231.0\n",
       "1932    667674  20171231.0\n",
       "...        ...         ...\n",
       "473     542932  20210430.0\n",
       "1480    641856  20210430.0\n",
       "1481    641857  20210430.0\n",
       "483     543037  20210430.0\n",
       "2060    685503  20210430.0\n",
       "\n",
       "[2061 rows x 2 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_last_game.sort_values('lastdate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3e81ff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seasonStartDate</th>\n",
       "      <th>seasonEndDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20170402</td>\n",
       "      <td>20171101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180329</td>\n",
       "      <td>20181028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190320</td>\n",
       "      <td>20191030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20200723</td>\n",
       "      <td>20201028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210228</td>\n",
       "      <td>20211031</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   seasonStartDate  seasonEndDate\n",
       "0         20170402       20171101\n",
       "1         20180329       20181028\n",
       "2         20190320       20191030\n",
       "3         20200723       20201028\n",
       "4         20210228       20211031"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seasons_startend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78e748fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "on_season_idxes = 0\n",
    "for raw in seasons_startend.iloc():\n",
    "    idx_ = ((train['date'].astype(int) >= raw['seasonStartDate']) & (train['date'].astype(int) <= raw['seasonEndDate'])) * 1\n",
    "    on_season_idxes += idx_\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bed6fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[on_season_idxes == 1].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1af9f72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "      <th>date</th>\n",
       "      <th>primaryPositionName</th>\n",
       "      <th>birthCity</th>\n",
       "      <th>DOY</th>\n",
       "      <th>mlbDebutYear</th>\n",
       "      <th>...</th>\n",
       "      <th>label_playerId</th>\n",
       "      <th>label_primaryPositionName</th>\n",
       "      <th>label_birthCity</th>\n",
       "      <th>label_teamId</th>\n",
       "      <th>label_status</th>\n",
       "      <th>annual_day</th>\n",
       "      <th>week_day</th>\n",
       "      <th>month</th>\n",
       "      <th>gameday</th>\n",
       "      <th>daysSinceLastGame</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112526</td>\n",
       "      <td>0.031761</td>\n",
       "      <td>2.731418</td>\n",
       "      <td>0.388556</td>\n",
       "      <td>6.349412</td>\n",
       "      <td>20180329</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Altamira</td>\n",
       "      <td>1973</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>...</td>\n",
       "      <td>969</td>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112526</td>\n",
       "      <td>0.025906</td>\n",
       "      <td>4.622162</td>\n",
       "      <td>0.408017</td>\n",
       "      <td>11.508375</td>\n",
       "      <td>20180330</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Altamira</td>\n",
       "      <td>1973</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>...</td>\n",
       "      <td>969</td>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112526</td>\n",
       "      <td>0.053185</td>\n",
       "      <td>4.767842</td>\n",
       "      <td>0.275408</td>\n",
       "      <td>14.600851</td>\n",
       "      <td>20180331</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Altamira</td>\n",
       "      <td>1973</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>...</td>\n",
       "      <td>969</td>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>89.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>112526</td>\n",
       "      <td>0.771100</td>\n",
       "      <td>63.601677</td>\n",
       "      <td>7.566316</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>20180401</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Altamira</td>\n",
       "      <td>1973</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>...</td>\n",
       "      <td>969</td>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>90.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112526</td>\n",
       "      <td>5.957846</td>\n",
       "      <td>22.427930</td>\n",
       "      <td>33.900803</td>\n",
       "      <td>38.857939</td>\n",
       "      <td>20180402</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Altamira</td>\n",
       "      <td>1973</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>...</td>\n",
       "      <td>969</td>\n",
       "      <td>0</td>\n",
       "      <td>588</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234534</th>\n",
       "      <td>685503</td>\n",
       "      <td>0.044617</td>\n",
       "      <td>1.224728</td>\n",
       "      <td>0.009437</td>\n",
       "      <td>0.737463</td>\n",
       "      <td>20210426</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Hiroshima</td>\n",
       "      <td>1992</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234535</th>\n",
       "      <td>685503</td>\n",
       "      <td>0.019123</td>\n",
       "      <td>1.178880</td>\n",
       "      <td>0.013161</td>\n",
       "      <td>0.790301</td>\n",
       "      <td>20210427</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Hiroshima</td>\n",
       "      <td>1992</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234536</th>\n",
       "      <td>685503</td>\n",
       "      <td>0.015799</td>\n",
       "      <td>4.323489</td>\n",
       "      <td>0.002350</td>\n",
       "      <td>0.970273</td>\n",
       "      <td>20210428</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Hiroshima</td>\n",
       "      <td>1992</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234537</th>\n",
       "      <td>685503</td>\n",
       "      <td>0.018770</td>\n",
       "      <td>31.946021</td>\n",
       "      <td>0.305491</td>\n",
       "      <td>5.938273</td>\n",
       "      <td>20210429</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Hiroshima</td>\n",
       "      <td>1992</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>118.0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1234538</th>\n",
       "      <td>685503</td>\n",
       "      <td>0.014727</td>\n",
       "      <td>6.607196</td>\n",
       "      <td>1.851336</td>\n",
       "      <td>2.014339</td>\n",
       "      <td>20210430</td>\n",
       "      <td>Pitcher</td>\n",
       "      <td>Hiroshima</td>\n",
       "      <td>1992</td>\n",
       "      <td>2021.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1713</td>\n",
       "      <td>0</td>\n",
       "      <td>902</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1234539 rows × 136 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         playerId   target1    target2    target3     target4      date  \\\n",
       "0          112526  0.031761   2.731418   0.388556    6.349412  20180329   \n",
       "1          112526  0.025906   4.622162   0.408017   11.508375  20180330   \n",
       "2          112526  0.053185   4.767842   0.275408   14.600851  20180331   \n",
       "3          112526  0.771100  63.601677   7.566316  100.000000  20180401   \n",
       "4          112526  5.957846  22.427930  33.900803   38.857939  20180402   \n",
       "...           ...       ...        ...        ...         ...       ...   \n",
       "1234534    685503  0.044617   1.224728   0.009437    0.737463  20210426   \n",
       "1234535    685503  0.019123   1.178880   0.013161    0.790301  20210427   \n",
       "1234536    685503  0.015799   4.323489   0.002350    0.970273  20210428   \n",
       "1234537    685503  0.018770  31.946021   0.305491    5.938273  20210429   \n",
       "1234538    685503  0.014727   6.607196   1.851336    2.014339  20210430   \n",
       "\n",
       "        primaryPositionName  birthCity   DOY  mlbDebutYear  ...  \\\n",
       "0                   Pitcher   Altamira  1973        1997.0  ...   \n",
       "1                   Pitcher   Altamira  1973        1997.0  ...   \n",
       "2                   Pitcher   Altamira  1973        1997.0  ...   \n",
       "3                   Pitcher   Altamira  1973        1997.0  ...   \n",
       "4                   Pitcher   Altamira  1973        1997.0  ...   \n",
       "...                     ...        ...   ...           ...  ...   \n",
       "1234534             Pitcher  Hiroshima  1992        2021.0  ...   \n",
       "1234535             Pitcher  Hiroshima  1992        2021.0  ...   \n",
       "1234536             Pitcher  Hiroshima  1992        2021.0  ...   \n",
       "1234537             Pitcher  Hiroshima  1992        2021.0  ...   \n",
       "1234538             Pitcher  Hiroshima  1992        2021.0  ...   \n",
       "\n",
       "         label_playerId  label_primaryPositionName  label_birthCity  \\\n",
       "0                   969                          0              588   \n",
       "1                   969                          0              588   \n",
       "2                   969                          0              588   \n",
       "3                   969                          0              588   \n",
       "4                   969                          0              588   \n",
       "...                 ...                        ...              ...   \n",
       "1234534            1713                          0              902   \n",
       "1234535            1713                          0              902   \n",
       "1234536            1713                          0              902   \n",
       "1234537            1713                          0              902   \n",
       "1234538            1713                          0              902   \n",
       "\n",
       "         label_teamId label_status  annual_day  week_day  month  gameday  \\\n",
       "0                   1            3        87.0         3      3        0   \n",
       "1                   1            3        88.0         4      3        0   \n",
       "2                   1            3        89.0         5      3        0   \n",
       "3                   1            3        90.0         6      4        0   \n",
       "4                   7            0        91.0         0      4        1   \n",
       "...               ...          ...         ...       ...    ...      ...   \n",
       "1234534             7            0       115.0         0      4        0   \n",
       "1234535             7            0       116.0         1      4        0   \n",
       "1234536             7            0       117.0         2      4        0   \n",
       "1234537             7            0       118.0         3      4        0   \n",
       "1234538             7            0       119.0         4      4        1   \n",
       "\n",
       "         daysSinceLastGame  \n",
       "0                       88  \n",
       "1                       89  \n",
       "2                       90  \n",
       "3                       91  \n",
       "4                        0  \n",
       "...                    ...  \n",
       "1234534                  1  \n",
       "1234535                  2  \n",
       "1234536                  3  \n",
       "1234537                  4  \n",
       "1234538                  0  \n",
       "\n",
       "[1234539 rows x 136 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "639aeebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n",
    "#     oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n",
    "#     model = lgbm.LGBMRegressor(**params)\n",
    "#     model.fit(x_train, y_train, \n",
    "#         eval_set=[(x_valid, y_valid)],  \n",
    "#         early_stopping_rounds=verbose, \n",
    "#         verbose=verbose)\n",
    "#     oof_pred = model.predict(x_valid)\n",
    "#     oof_pred = np.clip(oof_pred, 0, 100)\n",
    "#     score = mean_absolute_error(oof_pred, y_valid)\n",
    "#     print('mae:', score)\n",
    "#     return oof_pred, model, score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "271ce5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train\n",
    "train_y = train[['target1', 'target2', 'target3', 'target4']]\n",
    "tr_idxs = []\n",
    "val_idxs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "21bcaeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tr_idx = (train['date'].astype(int) < 20200801)\n",
    "# val_idx = (train['date'].astype(int) >= 20200801) & (train['date'].astype(int) < 20200901)\n",
    "# tr_idxs.append(tr_idx)\n",
    "# val_idxs.append(val_idx)\n",
    "\n",
    "# tr_idx = (train['date'].astype(int) < 20200901)\n",
    "# val_idx = (train['date'].astype(int) >= 20200901) & (train['date'].astype(int) < 20201001)\n",
    "# tr_idxs.append(tr_idx)\n",
    "# val_idxs.append(val_idx)\n",
    "\n",
    "# tr_idx = (train['date'].astype(int) < 20201001)\n",
    "# val_idx = (train['date'].astype(int) >= 20201001) & (train['date'].astype(int) < 20201028)\n",
    "# tr_idxs.append(tr_idx)\n",
    "# val_idxs.append(val_idx)\n",
    "\n",
    "# tr_idx = (train['date'].astype(int) < 20210228)\n",
    "# val_idx = (train['date'].astype(int) >= 20210228) & (train['date'].astype(int) < 20210401)\n",
    "# tr_idxs.append(tr_idx)\n",
    "# val_idxs.append(val_idx)\n",
    "\n",
    "tr_idx = (train['date'].astype(int) < 20210401)\n",
    "val_idx = ~tr_idx\n",
    "tr_idxs.append(tr_idx)\n",
    "val_idxs.append(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8983457e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'objective': 'regression',\n",
    "          'metric': 'mae',\n",
    "          'learning_rate': 0.01,\n",
    "          'early_stopping_rounds':10,\n",
    "          'random_seed':SEED} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cce58ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 11:51:31,896]\u001b[0m A new study created in memory with name: no-name-c560191a-32ba-47fa-b9e1-8e01ad4eb525\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100072 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588:  14%|#4        | 1/7 [00:27<02:44, 27.38s/it]\u001b[32m[I 2021-07-01 11:51:59,278]\u001b[0m Trial 0 finished with value: 0.8415884954480316 and parameters: {'feature_fraction': 0.5}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588:  14%|#4        | 1/7 [00:27<02:44, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.100352 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588:  29%|##8       | 2/7 [00:46<01:52, 22.54s/it]\u001b[32m[I 2021-07-01 11:52:18,428]\u001b[0m Trial 1 finished with value: 0.8455762878947325 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588:  29%|##8       | 2/7 [00:46<01:52, 22.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.096213 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588:  43%|####2     | 3/7 [01:09<01:31, 22.93s/it]\u001b[32m[I 2021-07-01 11:52:41,831]\u001b[0m Trial 2 finished with value: 0.8452034621972825 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588:  43%|####2     | 3/7 [01:09<01:31, 22.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.339672 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588:  57%|#####7    | 4/7 [01:29<01:04, 21.42s/it]\u001b[32m[I 2021-07-01 11:53:00,941]\u001b[0m Trial 3 finished with value: 0.8458906896210545 and parameters: {'feature_fraction': 0.7}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588:  57%|#####7    | 4/7 [01:29<01:04, 21.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.102722 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588:  71%|#######1  | 5/7 [01:50<00:43, 21.56s/it]\u001b[32m[I 2021-07-01 11:53:22,730]\u001b[0m Trial 4 finished with value: 0.8447120403365161 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588:  71%|#######1  | 5/7 [01:50<00:43, 21.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.340798 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588:  86%|########5 | 6/7 [02:10<00:20, 20.86s/it]\u001b[32m[I 2021-07-01 11:53:42,241]\u001b[0m Trial 5 finished with value: 0.8432405999107843 and parameters: {'feature_fraction': 0.6}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588:  86%|########5 | 6/7 [02:10<00:20, 20.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093739 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588: 100%|##########| 7/7 [02:35<00:00, 22.20s/it]\u001b[32m[I 2021-07-01 11:54:07,191]\u001b[0m Trial 6 finished with value: 0.8423686838369902 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.8415884954480316.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588: 100%|##########| 7/7 [02:35<00:00, 22.18s/it]\n",
      "num_leaves, val_score: 0.841588:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087090 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841588:   5%|5         | 1/20 [00:32<10:09, 32.09s/it]\u001b[32m[I 2021-07-01 11:54:39,281]\u001b[0m Trial 7 finished with value: 0.8425216724940608 and parameters: {'num_leaves': 172}. Best is trial 7 with value: 0.8425216724940608.\u001b[0m\n",
      "num_leaves, val_score: 0.841588:   5%|5         | 1/20 [00:32<10:09, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.103939 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  10%|#         | 2/20 [01:06<09:59, 33.30s/it]\u001b[32m[I 2021-07-01 11:55:13,422]\u001b[0m Trial 8 finished with value: 0.8402777917234591 and parameters: {'num_leaves': 134}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  10%|#         | 2/20 [01:06<09:59, 33.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  15%|#5        | 3/20 [01:42<09:50, 34.75s/it]\u001b[32m[I 2021-07-01 11:55:49,903]\u001b[0m Trial 9 finished with value: 0.8425742049109173 and parameters: {'num_leaves': 201}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  15%|#5        | 3/20 [01:42<09:50, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074116 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  20%|##        | 4/20 [02:18<09:22, 35.16s/it]\u001b[32m[I 2021-07-01 11:56:25,702]\u001b[0m Trial 10 finished with value: 0.8421831232341904 and parameters: {'num_leaves': 185}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  20%|##        | 4/20 [02:18<09:22, 35.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070685 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  25%|##5       | 5/20 [02:50<08:31, 34.08s/it]\u001b[32m[I 2021-07-01 11:56:57,847]\u001b[0m Trial 11 finished with value: 0.8409830074207353 and parameters: {'num_leaves': 126}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  25%|##5       | 5/20 [02:50<08:31, 34.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075871 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  30%|###       | 6/20 [03:25<08:01, 34.37s/it]\u001b[32m[I 2021-07-01 11:57:32,779]\u001b[0m Trial 12 finished with value: 0.8442289547111103 and parameters: {'num_leaves': 215}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  30%|###       | 6/20 [03:25<08:01, 34.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077037 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  35%|###5      | 7/20 [03:59<07:22, 34.07s/it]\u001b[32m[I 2021-07-01 11:58:06,228]\u001b[0m Trial 13 finished with value: 0.8405222339444632 and parameters: {'num_leaves': 111}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  35%|###5      | 7/20 [03:59<07:22, 34.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071124 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  40%|####      | 8/20 [04:32<06:46, 33.86s/it]\u001b[32m[I 2021-07-01 11:58:39,638]\u001b[0m Trial 14 finished with value: 0.8405222339444632 and parameters: {'num_leaves': 111}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  40%|####      | 8/20 [04:32<06:46, 33.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.090240 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  45%|####5     | 9/20 [05:00<05:51, 31.97s/it]\u001b[32m[I 2021-07-01 11:59:07,471]\u001b[0m Trial 15 finished with value: 0.8487589662135843 and parameters: {'num_leaves': 6}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  45%|####5     | 9/20 [05:00<05:51, 31.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071773 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  50%|#####     | 10/20 [05:32<05:20, 32.09s/it]\u001b[32m[I 2021-07-01 11:59:39,824]\u001b[0m Trial 16 finished with value: 0.8405652797472938 and parameters: {'num_leaves': 140}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  50%|#####     | 10/20 [05:32<05:20, 32.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077371 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  55%|#####5    | 11/20 [06:01<04:40, 31.14s/it]\u001b[32m[I 2021-07-01 12:00:08,814]\u001b[0m Trial 17 finished with value: 0.840683869346194 and parameters: {'num_leaves': 49}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  55%|#####5    | 11/20 [06:01<04:40, 31.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070195 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840278:  60%|######    | 12/20 [06:32<04:08, 31.11s/it]\u001b[32m[I 2021-07-01 12:00:39,866]\u001b[0m Trial 18 finished with value: 0.8404044791488264 and parameters: {'num_leaves': 77}. Best is trial 8 with value: 0.8402777917234591.\u001b[0m\n",
      "num_leaves, val_score: 0.840278:  60%|######    | 12/20 [06:32<04:08, 31.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  65%|######5   | 13/20 [07:03<03:37, 31.01s/it]\u001b[32m[I 2021-07-01 12:01:10,630]\u001b[0m Trial 19 finished with value: 0.8396831336051603 and parameters: {'num_leaves': 64}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  65%|######5   | 13/20 [07:03<03:37, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078248 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  70%|#######   | 14/20 [07:29<02:56, 29.42s/it]\u001b[32m[I 2021-07-01 12:01:36,368]\u001b[0m Trial 20 finished with value: 0.8425323934708157 and parameters: {'num_leaves': 33}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  70%|#######   | 14/20 [07:29<02:56, 29.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089230 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  75%|#######5  | 15/20 [07:56<02:23, 28.65s/it]\u001b[32m[I 2021-07-01 12:02:03,256]\u001b[0m Trial 21 finished with value: 0.8408103511666205 and parameters: {'num_leaves': 70}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  75%|#######5  | 15/20 [07:56<02:23, 28.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080926 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  80%|########  | 16/20 [08:35<02:07, 31.83s/it]\u001b[32m[I 2021-07-01 12:02:42,447]\u001b[0m Trial 22 finished with value: 0.8440941746040824 and parameters: {'num_leaves': 243}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  80%|########  | 16/20 [08:35<02:07, 31.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.088747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  85%|########5 | 17/20 [09:03<01:32, 30.80s/it]\u001b[32m[I 2021-07-01 12:03:10,872]\u001b[0m Trial 23 finished with value: 0.8914242365285361 and parameters: {'num_leaves': 2}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  85%|########5 | 17/20 [09:03<01:32, 30.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.086543 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  90%|######### | 18/20 [09:33<01:00, 30.41s/it]\u001b[32m[I 2021-07-01 12:03:40,362]\u001b[0m Trial 24 finished with value: 0.8411478241536862 and parameters: {'num_leaves': 90}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  90%|######### | 18/20 [09:33<01:00, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.089141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683:  95%|#########5| 19/20 [10:06<00:31, 31.40s/it]\u001b[32m[I 2021-07-01 12:04:14,065]\u001b[0m Trial 25 finished with value: 0.8410815922386427 and parameters: {'num_leaves': 159}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683:  95%|#########5| 19/20 [10:06<00:31, 31.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839683: 100%|##########| 20/20 [10:34<00:00, 30.24s/it]\u001b[32m[I 2021-07-01 12:04:41,615]\u001b[0m Trial 26 finished with value: 0.8412249278032793 and parameters: {'num_leaves': 45}. Best is trial 19 with value: 0.8396831336051603.\u001b[0m\n",
      "num_leaves, val_score: 0.839683: 100%|##########| 20/20 [10:34<00:00, 31.72s/it]\n",
      "bagging, val_score: 0.839683:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076137 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  10%|#         | 1/10 [00:27<04:07, 27.54s/it]\u001b[32m[I 2021-07-01 12:05:09,155]\u001b[0m Trial 27 finished with value: 0.8430297176708098 and parameters: {'bagging_fraction': 0.6069251349152245, 'bagging_freq': 1}. Best is trial 27 with value: 0.8430297176708098.\u001b[0m\n",
      "bagging, val_score: 0.839683:  10%|#         | 1/10 [00:27<04:07, 27.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.109204 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  20%|##        | 2/10 [00:57<03:53, 29.13s/it]\u001b[32m[I 2021-07-01 12:05:39,401]\u001b[0m Trial 28 finished with value: 0.8436026809187944 and parameters: {'bagging_fraction': 0.7140625451730391, 'bagging_freq': 2}. Best is trial 27 with value: 0.8430297176708098.\u001b[0m\n",
      "bagging, val_score: 0.839683:  20%|##        | 2/10 [00:57<03:53, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071439 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  30%|###       | 3/10 [01:25<03:20, 28.69s/it]\u001b[32m[I 2021-07-01 12:06:07,567]\u001b[0m Trial 29 finished with value: 0.8420602363870496 and parameters: {'bagging_fraction': 0.7579156262260451, 'bagging_freq': 1}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  30%|###       | 3/10 [01:25<03:20, 28.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087892 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  40%|####      | 4/10 [01:53<02:50, 28.35s/it]\u001b[32m[I 2021-07-01 12:06:35,396]\u001b[0m Trial 30 finished with value: 0.8424751652973774 and parameters: {'bagging_fraction': 0.6897335526453404, 'bagging_freq': 3}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  40%|####      | 4/10 [01:53<02:50, 28.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.107019 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  50%|#####     | 5/10 [02:22<02:22, 28.42s/it]\u001b[32m[I 2021-07-01 12:07:03,940]\u001b[0m Trial 31 finished with value: 0.8442235922595999 and parameters: {'bagging_fraction': 0.4564157544854211, 'bagging_freq': 1}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  50%|#####     | 5/10 [02:22<02:22, 28.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  60%|######    | 6/10 [02:53<01:57, 29.30s/it]\u001b[32m[I 2021-07-01 12:07:34,953]\u001b[0m Trial 32 finished with value: 0.8429365795373517 and parameters: {'bagging_fraction': 0.7970985047585878, 'bagging_freq': 3}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  60%|######    | 6/10 [02:53<01:57, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075465 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  70%|#######   | 7/10 [03:21<01:26, 28.82s/it]\u001b[32m[I 2021-07-01 12:08:02,795]\u001b[0m Trial 33 finished with value: 0.8429510771218144 and parameters: {'bagging_fraction': 0.6708771256927155, 'bagging_freq': 3}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  70%|#######   | 7/10 [03:21<01:26, 28.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077246 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  80%|########  | 8/10 [03:46<00:55, 27.68s/it]\u001b[32m[I 2021-07-01 12:08:28,010]\u001b[0m Trial 34 finished with value: 0.8435265767859961 and parameters: {'bagging_fraction': 0.6524472006541215, 'bagging_freq': 1}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  80%|########  | 8/10 [03:46<00:55, 27.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072373 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683:  90%|######### | 9/10 [04:08<00:25, 25.90s/it]\u001b[32m[I 2021-07-01 12:08:50,020]\u001b[0m Trial 35 finished with value: 0.8443470044254225 and parameters: {'bagging_fraction': 0.527697425312406, 'bagging_freq': 3}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683:  90%|######### | 9/10 [04:08<00:25, 25.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069062 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839683: 100%|##########| 10/10 [04:35<00:00, 26.16s/it]\u001b[32m[I 2021-07-01 12:09:16,744]\u001b[0m Trial 36 finished with value: 0.8447197412258994 and parameters: {'bagging_fraction': 0.9865984832045058, 'bagging_freq': 6}. Best is trial 29 with value: 0.8420602363870496.\u001b[0m\n",
      "bagging, val_score: 0.839683: 100%|##########| 10/10 [04:35<00:00, 27.51s/it]\n",
      "feature_fraction_stage2, val_score: 0.839683:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224475 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839683:  17%|#6        | 1/6 [00:22<01:53, 22.71s/it]\u001b[32m[I 2021-07-01 12:09:39,459]\u001b[0m Trial 37 finished with value: 0.8401147877640363 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 37 with value: 0.8401147877640363.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839683:  17%|#6        | 1/6 [00:22<01:53, 22.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.108102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839683:  33%|###3      | 2/6 [00:51<01:44, 26.03s/it]\u001b[32m[I 2021-07-01 12:10:07,819]\u001b[0m Trial 38 finished with value: 0.8406607847823522 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.8401147877640363.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839683:  33%|###3      | 2/6 [00:51<01:44, 26.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.356989 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839683:  50%|#####     | 3/6 [01:15<01:15, 25.20s/it]\u001b[32m[I 2021-07-01 12:10:32,028]\u001b[0m Trial 39 finished with value: 0.8401074076372135 and parameters: {'feature_fraction': 0.58}. Best is trial 39 with value: 0.8401074076372135.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839683:  50%|#####     | 3/6 [01:15<01:15, 25.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.210514 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839545:  67%|######6   | 4/6 [01:40<00:50, 25.07s/it]\u001b[32m[I 2021-07-01 12:10:56,891]\u001b[0m Trial 40 finished with value: 0.8395453257604739 and parameters: {'feature_fraction': 0.516}. Best is trial 40 with value: 0.8395453257604739.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839545:  67%|######6   | 4/6 [01:40<00:50, 25.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839545:  83%|########3 | 5/6 [02:10<00:26, 26.91s/it]\u001b[32m[I 2021-07-01 12:11:27,056]\u001b[0m Trial 41 finished with value: 0.8395484706148058 and parameters: {'feature_fraction': 0.484}. Best is trial 40 with value: 0.8395453257604739.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839545:  83%|########3 | 5/6 [02:10<00:26, 26.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071120 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839545: 100%|##########| 6/6 [02:38<00:00, 27.48s/it]\u001b[32m[I 2021-07-01 12:11:55,647]\u001b[0m Trial 42 finished with value: 0.8396282957629482 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 40 with value: 0.8395453257604739.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839545: 100%|##########| 6/6 [02:38<00:00, 26.48s/it]\n",
      "regularization_factors, val_score: 0.839545:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:   5%|5         | 1/20 [00:24<07:43, 24.41s/it]\u001b[32m[I 2021-07-01 12:12:20,058]\u001b[0m Trial 43 finished with value: 0.8400079412877199 and parameters: {'lambda_l1': 0.0006549681158359463, 'lambda_l2': 0.7494258614217761}. Best is trial 43 with value: 0.8400079412877199.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:   5%|5         | 1/20 [00:24<07:43, 24.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.317139 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  10%|#         | 2/20 [00:46<06:50, 22.78s/it]\u001b[32m[I 2021-07-01 12:12:41,700]\u001b[0m Trial 44 finished with value: 0.8416684910151307 and parameters: {'lambda_l1': 1.3530456604367954e-05, 'lambda_l2': 0.000899302856118919}. Best is trial 43 with value: 0.8400079412877199.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  10%|#         | 2/20 [00:46<06:50, 22.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.221102 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  15%|#5        | 3/20 [01:11<06:45, 23.88s/it]\u001b[32m[I 2021-07-01 12:13:06,884]\u001b[0m Trial 45 finished with value: 0.8401246574955821 and parameters: {'lambda_l1': 0.001467454405460565, 'lambda_l2': 1.8392732202238025}. Best is trial 43 with value: 0.8400079412877199.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  15%|#5        | 3/20 [01:11<06:45, 23.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220660 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  20%|##        | 4/20 [01:35<06:27, 24.21s/it]\u001b[32m[I 2021-07-01 12:13:31,602]\u001b[0m Trial 46 finished with value: 0.8400649669497544 and parameters: {'lambda_l1': 5.8995627187957654e-08, 'lambda_l2': 0.5935994844995075}. Best is trial 43 with value: 0.8400079412877199.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  20%|##        | 4/20 [01:35<06:27, 24.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223706 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  25%|##5       | 5/20 [02:00<06:04, 24.29s/it]\u001b[32m[I 2021-07-01 12:13:56,034]\u001b[0m Trial 47 finished with value: 0.8404050640416312 and parameters: {'lambda_l1': 0.0001655158206135022, 'lambda_l2': 0.002019350163668505}. Best is trial 43 with value: 0.8400079412877199.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  25%|##5       | 5/20 [02:00<06:04, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.315731 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  30%|###       | 6/20 [02:24<05:40, 24.35s/it]\u001b[32m[I 2021-07-01 12:14:20,514]\u001b[0m Trial 48 finished with value: 0.8399591323786216 and parameters: {'lambda_l1': 0.0033460537504857693, 'lambda_l2': 3.0606591294118702e-06}. Best is trial 48 with value: 0.8399591323786216.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  30%|###       | 6/20 [02:24<05:40, 24.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.316888 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  35%|###5      | 7/20 [02:50<05:21, 24.72s/it]\u001b[32m[I 2021-07-01 12:14:45,988]\u001b[0m Trial 49 finished with value: 0.8395462921413341 and parameters: {'lambda_l1': 7.218692065636632e-08, 'lambda_l2': 1.8552975326846705e-06}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  35%|###5      | 7/20 [02:50<05:21, 24.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.229979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  40%|####      | 8/20 [03:12<04:46, 23.89s/it]\u001b[32m[I 2021-07-01 12:15:08,097]\u001b[0m Trial 50 finished with value: 0.841024388849199 and parameters: {'lambda_l1': 0.5205354492312455, 'lambda_l2': 0.02959821295919829}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  40%|####      | 8/20 [03:12<04:46, 23.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.315304 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  45%|####5     | 9/20 [03:37<04:25, 24.18s/it]\u001b[32m[I 2021-07-01 12:15:32,903]\u001b[0m Trial 51 finished with value: 0.8400740377520014 and parameters: {'lambda_l1': 4.8356018246111477e-08, 'lambda_l2': 0.0005964238177001331}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  45%|####5     | 9/20 [03:37<04:25, 24.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.235446 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  50%|#####     | 10/20 [04:00<03:57, 23.77s/it]\u001b[32m[I 2021-07-01 12:15:55,761]\u001b[0m Trial 52 finished with value: 0.8409173619140651 and parameters: {'lambda_l1': 0.23054396113742065, 'lambda_l2': 2.3393694525524516e-05}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  50%|#####     | 10/20 [04:00<03:57, 23.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.334172 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  55%|#####5    | 11/20 [04:25<03:38, 24.24s/it]\u001b[32m[I 2021-07-01 12:16:21,074]\u001b[0m Trial 53 finished with value: 0.8395472941393685 and parameters: {'lambda_l1': 1.268595318180578e-06, 'lambda_l2': 3.764510753722336e-08}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  55%|#####5    | 11/20 [04:25<03:38, 24.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222575 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  60%|######    | 12/20 [04:50<03:16, 24.52s/it]\u001b[32m[I 2021-07-01 12:16:46,246]\u001b[0m Trial 54 finished with value: 0.8395483392432356 and parameters: {'lambda_l1': 2.7397880313361974e-06, 'lambda_l2': 4.3290531134372665e-08}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  60%|######    | 12/20 [04:50<03:16, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  65%|######5   | 13/20 [05:15<02:52, 24.66s/it]\u001b[32m[I 2021-07-01 12:17:11,202]\u001b[0m Trial 55 finished with value: 0.8395462922292446 and parameters: {'lambda_l1': 6.120752996485344e-07, 'lambda_l2': 1.3609776739676554e-08}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  65%|######5   | 13/20 [05:15<02:52, 24.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.202305 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839545:  70%|#######   | 14/20 [05:40<02:28, 24.74s/it]\u001b[32m[I 2021-07-01 12:17:36,145]\u001b[0m Trial 56 finished with value: 0.8395497098030652 and parameters: {'lambda_l1': 1.3685895388030993e-08, 'lambda_l2': 8.472615779938854e-07}. Best is trial 49 with value: 0.8395462921413341.\u001b[0m\n",
      "regularization_factors, val_score: 0.839545:  70%|#######   | 14/20 [05:40<02:28, 24.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185223 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839543:  75%|#######5  | 15/20 [06:05<02:03, 24.80s/it]\u001b[32m[I 2021-07-01 12:18:01,071]\u001b[0m Trial 57 finished with value: 0.8395431743071844 and parameters: {'lambda_l1': 7.635951631226586e-07, 'lambda_l2': 1.3545756002061381e-08}. Best is trial 57 with value: 0.8395431743071844.\u001b[0m\n",
      "regularization_factors, val_score: 0.839543:  75%|#######5  | 15/20 [06:05<02:03, 24.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.214213 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839543:  80%|########  | 16/20 [06:26<01:34, 23.73s/it]\u001b[32m[I 2021-07-01 12:18:22,331]\u001b[0m Trial 58 finished with value: 0.8411180921972645 and parameters: {'lambda_l1': 2.683017646084961e-05, 'lambda_l2': 1.055870523214746e-06}. Best is trial 57 with value: 0.8395431743071844.\u001b[0m\n",
      "regularization_factors, val_score: 0.839543:  80%|########  | 16/20 [06:26<01:34, 23.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.224639 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839543:  85%|########5 | 17/20 [06:48<01:09, 23.09s/it]\u001b[32m[I 2021-07-01 12:18:43,936]\u001b[0m Trial 59 finished with value: 0.8411183022700179 and parameters: {'lambda_l1': 2.2176205858881008e-07, 'lambda_l2': 3.196593320482968e-05}. Best is trial 57 with value: 0.8395431743071844.\u001b[0m\n",
      "regularization_factors, val_score: 0.839543:  85%|########5 | 17/20 [06:48<01:09, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.247128 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839543:  90%|######### | 18/20 [07:13<00:47, 23.76s/it]\u001b[32m[I 2021-07-01 12:19:09,264]\u001b[0m Trial 60 finished with value: 0.8395462922188183 and parameters: {'lambda_l1': 1.9635873365010807e-08, 'lambda_l2': 2.0130906847301412e-07}. Best is trial 57 with value: 0.8395431743071844.\u001b[0m\n",
      "regularization_factors, val_score: 0.839543:  90%|######### | 18/20 [07:13<00:47, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.223812 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839543:  95%|#########5| 19/20 [07:35<00:23, 23.11s/it]\u001b[32m[I 2021-07-01 12:19:30,858]\u001b[0m Trial 61 finished with value: 0.841118302349509 and parameters: {'lambda_l1': 1.1180121118239414e-05, 'lambda_l2': 3.1040636586987836e-05}. Best is trial 57 with value: 0.8395431743071844.\u001b[0m\n",
      "regularization_factors, val_score: 0.839543:  95%|#########5| 19/20 [07:35<00:23, 23.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.222580 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839543: 100%|##########| 20/20 [08:00<00:00, 23.77s/it]\u001b[32m[I 2021-07-01 12:19:56,154]\u001b[0m Trial 62 finished with value: 0.8395462922282192 and parameters: {'lambda_l1': 2.3646114675370645e-07, 'lambda_l2': 1.4169040926147706e-08}. Best is trial 57 with value: 0.8395431743071844.\u001b[0m\n",
      "regularization_factors, val_score: 0.839543: 100%|##########| 20/20 [08:00<00:00, 24.03s/it]\n",
      "min_data_in_leaf, val_score: 0.839543:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.239340 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839543:  20%|##        | 1/5 [00:21<01:26, 21.50s/it]\u001b[32m[I 2021-07-01 12:20:17,661]\u001b[0m Trial 63 finished with value: 0.8440272455085996 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.8440272455085996.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839543:  20%|##        | 1/5 [00:21<01:26, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.248573 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839543:  40%|####      | 2/5 [00:47<01:12, 24.16s/it]\u001b[32m[I 2021-07-01 12:20:43,684]\u001b[0m Trial 64 finished with value: 0.8411128581893728 and parameters: {'min_child_samples': 10}. Best is trial 64 with value: 0.8411128581893728.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839543:  40%|####      | 2/5 [00:47<01:12, 24.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.294148 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.837773:  60%|######    | 3/5 [01:11<00:48, 24.29s/it]\u001b[32m[I 2021-07-01 12:21:08,135]\u001b[0m Trial 65 finished with value: 0.8377729798663713 and parameters: {'min_child_samples': 100}. Best is trial 65 with value: 0.8377729798663713.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.837773:  60%|######    | 3/5 [01:11<00:48, 24.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.185653 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.837773:  80%|########  | 4/5 [01:36<00:24, 24.43s/it]\u001b[32m[I 2021-07-01 12:21:32,783]\u001b[0m Trial 66 finished with value: 0.8386489328383949 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.8377729798663713.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.837773:  80%|########  | 4/5 [01:36<00:24, 24.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.302689 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.837773: 100%|##########| 5/5 [02:01<00:00, 24.69s/it]\u001b[32m[I 2021-07-01 12:21:57,917]\u001b[0m Trial 67 finished with value: 0.837921389177031 and parameters: {'min_child_samples': 50}. Best is trial 65 with value: 0.8377729798663713.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.837773: 100%|##########| 5/5 [02:01<00:00, 24.35s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "NFOLDS = 1\n",
    "idx = 0\n",
    "    \n",
    "tr_idx = tr_idxs[idx]\n",
    "val_idx = val_idxs[idx]\n",
    "\n",
    "x_train = train_X.loc[tr_idx].reset_index(drop=True)\n",
    "y_train = train_y.loc[tr_idx].reset_index(drop=True)\n",
    "x_valid = train_X.loc[val_idx].reset_index(drop=True)\n",
    "y_valid = train_y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "\n",
    "trains = lgbm.Dataset(x_train[feature_cols1], y_train['target1'])\n",
    "valids = lgbm.Dataset(x_valid[feature_cols1], y_valid['target1'])\n",
    "\n",
    "\n",
    "model1 = lgbm.train(params, trains, valid_sets=[trains, valids],\n",
    "                    verbose_eval=False)\n",
    "\n",
    "\n",
    "# score = (score1+score2+score3+score4) / 4\n",
    "# print(f'score: {score}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43612bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 12:21:58,587]\u001b[0m A new study created in memory with name: no-name-5b8a256c-0c51-41ec-ae6c-50e68282c34f\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067594 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843538:  14%|#4        | 1/7 [00:25<02:33, 25.62s/it]\u001b[32m[I 2021-07-01 12:22:24,210]\u001b[0m Trial 0 finished with value: 0.843538222017043 and parameters: {'feature_fraction': 0.4}. Best is trial 0 with value: 0.843538222017043.\u001b[0m\n",
      "feature_fraction, val_score: 0.843538:  14%|#4        | 1/7 [00:25<02:33, 25.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.092748 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843538:  29%|##8       | 2/7 [00:45<01:50, 22.14s/it]\u001b[32m[I 2021-07-01 12:22:43,916]\u001b[0m Trial 1 finished with value: 0.8479566071546832 and parameters: {'feature_fraction': 1.0}. Best is trial 0 with value: 0.843538222017043.\u001b[0m\n",
      "feature_fraction, val_score: 0.843538:  29%|##8       | 2/7 [00:45<01:50, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071669 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843176:  43%|####2     | 3/7 [01:11<01:35, 23.82s/it]\u001b[32m[I 2021-07-01 12:23:09,726]\u001b[0m Trial 2 finished with value: 0.8431755872467733 and parameters: {'feature_fraction': 0.5}. Best is trial 2 with value: 0.8431755872467733.\u001b[0m\n",
      "feature_fraction, val_score: 0.843176:  43%|####2     | 3/7 [01:11<01:35, 23.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076284 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843176:  57%|#####7    | 4/7 [01:31<01:07, 22.64s/it]\u001b[32m[I 2021-07-01 12:23:30,560]\u001b[0m Trial 3 finished with value: 0.8463917579794593 and parameters: {'feature_fraction': 0.8}. Best is trial 2 with value: 0.8431755872467733.\u001b[0m\n",
      "feature_fraction, val_score: 0.843176:  57%|#####7    | 4/7 [01:31<01:07, 22.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.227619 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843176:  71%|#######1  | 5/7 [01:52<00:43, 21.73s/it]\u001b[32m[I 2021-07-01 12:23:50,686]\u001b[0m Trial 4 finished with value: 0.8457103213295811 and parameters: {'feature_fraction': 0.7}. Best is trial 2 with value: 0.8431755872467733.\u001b[0m\n",
      "feature_fraction, val_score: 0.843176:  71%|#######1  | 5/7 [01:52<00:43, 21.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843176:  86%|########5 | 6/7 [02:12<00:21, 21.18s/it]\u001b[32m[I 2021-07-01 12:24:10,784]\u001b[0m Trial 5 finished with value: 0.8480806681604952 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 2 with value: 0.8431755872467733.\u001b[0m\n",
      "feature_fraction, val_score: 0.843176:  86%|########5 | 6/7 [02:12<00:21, 21.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.393081 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843176: 100%|##########| 7/7 [02:32<00:00, 20.92s/it]\u001b[32m[I 2021-07-01 12:24:31,170]\u001b[0m Trial 6 finished with value: 0.8451769686348224 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.8431755872467733.\u001b[0m\n",
      "feature_fraction, val_score: 0.843176: 100%|##########| 7/7 [02:32<00:00, 21.80s/it]\n",
      "num_leaves, val_score: 0.843176:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072874 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.842643:   5%|5         | 1/20 [00:25<08:13, 25.99s/it]\u001b[32m[I 2021-07-01 12:24:57,162]\u001b[0m Trial 7 finished with value: 0.84264255333966 and parameters: {'num_leaves': 55}. Best is trial 7 with value: 0.84264255333966.\u001b[0m\n",
      "num_leaves, val_score: 0.842643:   5%|5         | 1/20 [00:25<08:13, 25.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841220:  10%|#         | 2/20 [00:58<08:54, 29.69s/it]\u001b[32m[I 2021-07-01 12:25:29,448]\u001b[0m Trial 8 finished with value: 0.8412202615781307 and parameters: {'num_leaves': 102}. Best is trial 8 with value: 0.8412202615781307.\u001b[0m\n",
      "num_leaves, val_score: 0.841220:  10%|#         | 2/20 [00:58<08:54, 29.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076165 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841220:  15%|#5        | 3/20 [01:32<09:00, 31.77s/it]\u001b[32m[I 2021-07-01 12:26:03,690]\u001b[0m Trial 9 finished with value: 0.8463691533384394 and parameters: {'num_leaves': 231}. Best is trial 8 with value: 0.8412202615781307.\u001b[0m\n",
      "num_leaves, val_score: 0.841220:  15%|#5        | 3/20 [01:32<09:00, 31.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074097 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841220:  20%|##        | 4/20 [02:04<08:30, 31.91s/it]\u001b[32m[I 2021-07-01 12:26:35,822]\u001b[0m Trial 10 finished with value: 0.8438285854204748 and parameters: {'num_leaves': 146}. Best is trial 8 with value: 0.8412202615781307.\u001b[0m\n",
      "num_leaves, val_score: 0.841220:  20%|##        | 4/20 [02:04<08:30, 31.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076051 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841220:  25%|##5       | 5/20 [02:31<07:29, 29.96s/it]\u001b[32m[I 2021-07-01 12:27:02,318]\u001b[0m Trial 11 finished with value: 0.8423084773137478 and parameters: {'num_leaves': 72}. Best is trial 8 with value: 0.8412202615781307.\u001b[0m\n",
      "num_leaves, val_score: 0.841220:  25%|##5       | 5/20 [02:31<07:29, 29.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075996 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  30%|###       | 6/20 [03:02<07:05, 30.41s/it]\u001b[32m[I 2021-07-01 12:27:33,597]\u001b[0m Trial 12 finished with value: 0.8411670032605851 and parameters: {'num_leaves': 89}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  30%|###       | 6/20 [03:02<07:05, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072397 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  35%|###5      | 7/20 [03:33<06:38, 30.63s/it]\u001b[32m[I 2021-07-01 12:28:04,680]\u001b[0m Trial 13 finished with value: 0.8433951076371446 and parameters: {'num_leaves': 130}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  35%|###5      | 7/20 [03:33<06:38, 30.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069918 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  40%|####      | 8/20 [04:00<05:52, 29.37s/it]\u001b[32m[I 2021-07-01 12:28:31,343]\u001b[0m Trial 14 finished with value: 0.8430476909169943 and parameters: {'num_leaves': 29}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  40%|####      | 8/20 [04:00<05:52, 29.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069993 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  45%|####5     | 9/20 [04:27<05:14, 28.63s/it]\u001b[32m[I 2021-07-01 12:28:58,364]\u001b[0m Trial 15 finished with value: 0.8422298674598687 and parameters: {'num_leaves': 54}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  45%|####5     | 9/20 [04:27<05:14, 28.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068639 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  50%|#####     | 10/20 [04:53<04:37, 27.79s/it]\u001b[32m[I 2021-07-01 12:29:24,264]\u001b[0m Trial 16 finished with value: 0.8431110029741593 and parameters: {'num_leaves': 62}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  50%|#####     | 10/20 [04:53<04:37, 27.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  55%|#####5    | 11/20 [05:24<04:19, 28.81s/it]\u001b[32m[I 2021-07-01 12:29:55,404]\u001b[0m Trial 17 finished with value: 0.8445781540126148 and parameters: {'num_leaves': 182}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  55%|#####5    | 11/20 [05:24<04:19, 28.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072114 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  60%|######    | 12/20 [05:54<03:53, 29.22s/it]\u001b[32m[I 2021-07-01 12:30:25,552]\u001b[0m Trial 18 finished with value: 0.8420738313569656 and parameters: {'num_leaves': 99}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  60%|######    | 12/20 [05:54<03:53, 29.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  65%|######5   | 13/20 [06:23<03:25, 29.31s/it]\u001b[32m[I 2021-07-01 12:30:55,076]\u001b[0m Trial 19 finished with value: 0.8419636925645139 and parameters: {'num_leaves': 106}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  65%|######5   | 13/20 [06:23<03:25, 29.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068827 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  70%|#######   | 14/20 [06:53<02:55, 29.30s/it]\u001b[32m[I 2021-07-01 12:31:24,337]\u001b[0m Trial 20 finished with value: 0.8531718486675232 and parameters: {'num_leaves': 4}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  70%|#######   | 14/20 [06:53<02:55, 29.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074671 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  75%|#######5  | 15/20 [07:23<02:27, 29.57s/it]\u001b[32m[I 2021-07-01 12:31:54,544]\u001b[0m Trial 21 finished with value: 0.8439685712247581 and parameters: {'num_leaves': 168}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  75%|#######5  | 15/20 [07:23<02:27, 29.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  80%|########  | 16/20 [07:53<01:59, 29.78s/it]\u001b[32m[I 2021-07-01 12:32:24,799]\u001b[0m Trial 22 finished with value: 0.8417153488936117 and parameters: {'num_leaves': 101}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  80%|########  | 16/20 [07:53<01:59, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  85%|########5 | 17/20 [08:23<01:28, 29.66s/it]\u001b[32m[I 2021-07-01 12:32:54,186]\u001b[0m Trial 23 finished with value: 0.8531718486675233 and parameters: {'num_leaves': 4}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  85%|########5 | 17/20 [08:23<01:28, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074096 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  90%|######### | 18/20 [08:55<01:01, 30.56s/it]\u001b[32m[I 2021-07-01 12:33:26,849]\u001b[0m Trial 24 finished with value: 0.8445851189165539 and parameters: {'num_leaves': 205}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  90%|######### | 18/20 [08:55<01:01, 30.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167:  95%|#########5| 19/20 [09:24<00:30, 30.08s/it]\u001b[32m[I 2021-07-01 12:33:55,823]\u001b[0m Trial 25 finished with value: 0.8421885535596957 and parameters: {'num_leaves': 87}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167:  95%|#########5| 19/20 [09:24<00:30, 30.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.841167: 100%|##########| 20/20 [09:56<00:00, 30.74s/it]\u001b[32m[I 2021-07-01 12:34:28,074]\u001b[0m Trial 26 finished with value: 0.8426264012299838 and parameters: {'num_leaves': 123}. Best is trial 12 with value: 0.8411670032605851.\u001b[0m\n",
      "num_leaves, val_score: 0.841167: 100%|##########| 20/20 [09:56<00:00, 29.85s/it]\n",
      "bagging, val_score: 0.841167:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069081 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  10%|#         | 1/10 [00:22<03:19, 22.20s/it]\u001b[32m[I 2021-07-01 12:34:50,278]\u001b[0m Trial 27 finished with value: 0.844431472570985 and parameters: {'bagging_fraction': 0.5068373193071081, 'bagging_freq': 5}. Best is trial 27 with value: 0.844431472570985.\u001b[0m\n",
      "bagging, val_score: 0.841167:  10%|#         | 1/10 [00:22<03:19, 22.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  20%|##        | 2/10 [00:47<03:10, 23.76s/it]\u001b[32m[I 2021-07-01 12:35:15,128]\u001b[0m Trial 28 finished with value: 0.8457356189643034 and parameters: {'bagging_fraction': 0.5844948150823437, 'bagging_freq': 1}. Best is trial 27 with value: 0.844431472570985.\u001b[0m\n",
      "bagging, val_score: 0.841167:  20%|##        | 2/10 [00:47<03:10, 23.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072406 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  30%|###       | 3/10 [01:14<02:59, 25.58s/it]\u001b[32m[I 2021-07-01 12:35:42,870]\u001b[0m Trial 29 finished with value: 0.8432428743219487 and parameters: {'bagging_fraction': 0.7116152030343603, 'bagging_freq': 6}. Best is trial 29 with value: 0.8432428743219487.\u001b[0m\n",
      "bagging, val_score: 0.841167:  30%|###       | 3/10 [01:14<02:59, 25.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071659 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  40%|####      | 4/10 [01:32<02:14, 22.40s/it]\u001b[32m[I 2021-07-01 12:36:00,401]\u001b[0m Trial 30 finished with value: 0.8457231329908186 and parameters: {'bagging_fraction': 0.43697899018576675, 'bagging_freq': 5}. Best is trial 29 with value: 0.8432428743219487.\u001b[0m\n",
      "bagging, val_score: 0.841167:  40%|####      | 4/10 [01:32<02:14, 22.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069070 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  50%|#####     | 5/10 [02:09<02:18, 27.61s/it]\u001b[32m[I 2021-07-01 12:36:37,256]\u001b[0m Trial 31 finished with value: 0.8420533382683743 and parameters: {'bagging_fraction': 0.9322481091574355, 'bagging_freq': 2}. Best is trial 31 with value: 0.8420533382683743.\u001b[0m\n",
      "bagging, val_score: 0.841167:  50%|#####     | 5/10 [02:09<02:18, 27.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070626 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  60%|######    | 6/10 [02:45<02:01, 30.41s/it]\u001b[32m[I 2021-07-01 12:37:13,084]\u001b[0m Trial 32 finished with value: 0.8420028212637581 and parameters: {'bagging_fraction': 0.9556007251462276, 'bagging_freq': 5}. Best is trial 32 with value: 0.8420028212637581.\u001b[0m\n",
      "bagging, val_score: 0.841167:  60%|######    | 6/10 [02:45<02:01, 30.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068638 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  70%|#######   | 7/10 [03:09<01:25, 28.47s/it]\u001b[32m[I 2021-07-01 12:37:37,573]\u001b[0m Trial 33 finished with value: 0.8459491139821979 and parameters: {'bagging_fraction': 0.579335813138124, 'bagging_freq': 1}. Best is trial 32 with value: 0.8420028212637581.\u001b[0m\n",
      "bagging, val_score: 0.841167:  70%|#######   | 7/10 [03:09<01:25, 28.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073829 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  80%|########  | 8/10 [03:45<01:01, 30.78s/it]\u001b[32m[I 2021-07-01 12:38:13,302]\u001b[0m Trial 34 finished with value: 0.8429091176645739 and parameters: {'bagging_fraction': 0.9266504390435455, 'bagging_freq': 4}. Best is trial 32 with value: 0.8420028212637581.\u001b[0m\n",
      "bagging, val_score: 0.841167:  80%|########  | 8/10 [03:45<01:01, 30.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073516 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167:  90%|######### | 9/10 [04:12<00:29, 29.78s/it]\u001b[32m[I 2021-07-01 12:38:40,863]\u001b[0m Trial 35 finished with value: 0.8432369291591039 and parameters: {'bagging_fraction': 0.719951836055245, 'bagging_freq': 7}. Best is trial 32 with value: 0.8420028212637581.\u001b[0m\n",
      "bagging, val_score: 0.841167:  90%|######### | 9/10 [04:12<00:29, 29.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074487 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.841167: 100%|##########| 10/10 [04:35<00:00, 27.73s/it]\u001b[32m[I 2021-07-01 12:39:04,016]\u001b[0m Trial 36 finished with value: 0.8480504158686432 and parameters: {'bagging_fraction': 0.652763296669931, 'bagging_freq': 3}. Best is trial 32 with value: 0.8420028212637581.\u001b[0m\n",
      "bagging, val_score: 0.841167: 100%|##########| 10/10 [04:35<00:00, 27.59s/it]\n",
      "feature_fraction_stage2, val_score: 0.841167:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.293902 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.841167:  17%|#6        | 1/6 [00:25<02:09, 25.98s/it]\u001b[32m[I 2021-07-01 12:39:30,000]\u001b[0m Trial 37 finished with value: 0.8414056190421098 and parameters: {'feature_fraction': 0.58}. Best is trial 37 with value: 0.8414056190421098.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.841167:  17%|#6        | 1/6 [00:25<02:09, 25.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073108 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.841167:  33%|###3      | 2/6 [00:56<01:53, 28.50s/it]\u001b[32m[I 2021-07-01 12:40:00,259]\u001b[0m Trial 38 finished with value: 0.8414183282637371 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 37 with value: 0.8414056190421098.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.841167:  33%|###3      | 2/6 [00:56<01:53, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.840908:  50%|#####     | 3/6 [01:27<01:28, 29.63s/it]\u001b[32m[I 2021-07-01 12:40:31,229]\u001b[0m Trial 39 finished with value: 0.840908307601635 and parameters: {'feature_fraction': 0.516}. Best is trial 39 with value: 0.840908307601635.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.840908:  50%|#####     | 3/6 [01:27<01:28, 29.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.220121 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.840908:  67%|######6   | 4/6 [01:51<00:55, 27.66s/it]\u001b[32m[I 2021-07-01 12:40:55,879]\u001b[0m Trial 40 finished with value: 0.8417393522433607 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 39 with value: 0.840908307601635.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.840908:  67%|######6   | 4/6 [01:51<00:55, 27.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072337 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.840908:  83%|########3 | 5/6 [02:16<00:26, 26.53s/it]\u001b[32m[I 2021-07-01 12:41:20,407]\u001b[0m Trial 41 finished with value: 0.845919097448745 and parameters: {'feature_fraction': 0.42}. Best is trial 39 with value: 0.840908307601635.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.840908:  83%|########3 | 5/6 [02:16<00:26, 26.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.840908: 100%|##########| 6/6 [02:47<00:00, 27.94s/it]\u001b[32m[I 2021-07-01 12:41:51,092]\u001b[0m Trial 42 finished with value: 0.8420260231656468 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.840908307601635.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.840908: 100%|##########| 6/6 [02:47<00:00, 27.85s/it]\n",
      "regularization_factors, val_score: 0.840908:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076113 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:   5%|5         | 1/20 [00:30<09:31, 30.08s/it]\u001b[32m[I 2021-07-01 12:42:21,180]\u001b[0m Trial 43 finished with value: 0.842006624367795 and parameters: {'lambda_l1': 3.67468407750813e-08, 'lambda_l2': 0.018985812370998504}. Best is trial 43 with value: 0.842006624367795.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:   5%|5         | 1/20 [00:30<09:31, 30.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  10%|#         | 2/20 [00:58<08:43, 29.09s/it]\u001b[32m[I 2021-07-01 12:42:49,584]\u001b[0m Trial 44 finished with value: 0.8422190657845253 and parameters: {'lambda_l1': 0.0035480715442131345, 'lambda_l2': 1.6318091032750463e-08}. Best is trial 43 with value: 0.842006624367795.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  10%|#         | 2/20 [00:58<08:43, 29.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  15%|#5        | 3/20 [01:30<08:34, 30.24s/it]\u001b[32m[I 2021-07-01 12:43:21,194]\u001b[0m Trial 45 finished with value: 0.841125385251633 and parameters: {'lambda_l1': 0.018391505258294957, 'lambda_l2': 0.13028800037290442}. Best is trial 45 with value: 0.841125385251633.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  15%|#5        | 3/20 [01:30<08:34, 30.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073720 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  20%|##        | 4/20 [01:58<07:51, 29.48s/it]\u001b[32m[I 2021-07-01 12:43:49,513]\u001b[0m Trial 46 finished with value: 0.8422300559844658 and parameters: {'lambda_l1': 2.6872696947229008e-08, 'lambda_l2': 0.226517183807592}. Best is trial 45 with value: 0.841125385251633.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  20%|##        | 4/20 [01:58<07:51, 29.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079224 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  25%|##5       | 5/20 [02:28<07:27, 29.85s/it]\u001b[32m[I 2021-07-01 12:44:20,009]\u001b[0m Trial 47 finished with value: 0.8413853875122286 and parameters: {'lambda_l1': 0.00014945384540268072, 'lambda_l2': 0.00024047012876639642}. Best is trial 45 with value: 0.841125385251633.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  25%|##5       | 5/20 [02:28<07:27, 29.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073479 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  30%|###       | 6/20 [03:01<07:09, 30.65s/it]\u001b[32m[I 2021-07-01 12:44:52,205]\u001b[0m Trial 48 finished with value: 0.8409962362191514 and parameters: {'lambda_l1': 6.992003813142629e-08, 'lambda_l2': 0.031616216929345554}. Best is trial 48 with value: 0.8409962362191514.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  30%|###       | 6/20 [03:01<07:09, 30.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  35%|###5      | 7/20 [03:29<06:28, 29.88s/it]\u001b[32m[I 2021-07-01 12:45:20,507]\u001b[0m Trial 49 finished with value: 0.8419976647096663 and parameters: {'lambda_l1': 3.8567101465079583, 'lambda_l2': 8.180037518103602e-06}. Best is trial 48 with value: 0.8409962362191514.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  35%|###5      | 7/20 [03:29<06:28, 29.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070458 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  40%|####      | 8/20 [03:59<05:58, 29.91s/it]\u001b[32m[I 2021-07-01 12:45:50,485]\u001b[0m Trial 50 finished with value: 0.8420081200427056 and parameters: {'lambda_l1': 5.455329996054334e-07, 'lambda_l2': 0.019492842001103128}. Best is trial 48 with value: 0.8409962362191514.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  40%|####      | 8/20 [03:59<05:58, 29.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070343 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  45%|####5     | 9/20 [04:26<05:19, 29.07s/it]\u001b[32m[I 2021-07-01 12:46:17,702]\u001b[0m Trial 51 finished with value: 0.8422740106076583 and parameters: {'lambda_l1': 0.09653345064234002, 'lambda_l2': 2.645860462360501e-07}. Best is trial 48 with value: 0.8409962362191514.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  45%|####5     | 9/20 [04:26<05:19, 29.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074800 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840908:  50%|#####     | 10/20 [04:55<04:49, 28.92s/it]\u001b[32m[I 2021-07-01 12:46:46,286]\u001b[0m Trial 52 finished with value: 0.8414244674893786 and parameters: {'lambda_l1': 0.6132331358295141, 'lambda_l2': 1.187165043590008e-05}. Best is trial 48 with value: 0.8409962362191514.\u001b[0m\n",
      "regularization_factors, val_score: 0.840908:  50%|#####     | 10/20 [04:55<04:49, 28.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  55%|#####5    | 11/20 [05:24<04:22, 29.19s/it]\u001b[32m[I 2021-07-01 12:47:16,081]\u001b[0m Trial 53 finished with value: 0.8408851468434623 and parameters: {'lambda_l1': 5.98074224615756e-06, 'lambda_l2': 4.259448834054004}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  55%|#####5    | 11/20 [05:24<04:22, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075333 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  60%|######    | 12/20 [05:52<03:48, 28.62s/it]\u001b[32m[I 2021-07-01 12:47:43,399]\u001b[0m Trial 54 finished with value: 0.8424625014205201 and parameters: {'lambda_l1': 7.365961371764639e-06, 'lambda_l2': 7.97429149905711}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  60%|######    | 12/20 [05:52<03:48, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070302 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  65%|######5   | 13/20 [06:22<03:23, 29.00s/it]\u001b[32m[I 2021-07-01 12:48:13,279]\u001b[0m Trial 55 finished with value: 0.8414670932737066 and parameters: {'lambda_l1': 7.025945600578102e-06, 'lambda_l2': 0.63749698825338}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  65%|######5   | 13/20 [06:22<03:23, 29.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070021 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  70%|#######   | 14/20 [06:54<02:59, 29.86s/it]\u001b[32m[I 2021-07-01 12:48:45,133]\u001b[0m Trial 56 finished with value: 0.8415629755674315 and parameters: {'lambda_l1': 7.52963312354377e-07, 'lambda_l2': 3.914215792503631}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  70%|#######   | 14/20 [06:54<02:59, 29.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071840 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  75%|#######5  | 15/20 [07:24<02:30, 30.05s/it]\u001b[32m[I 2021-07-01 12:49:15,604]\u001b[0m Trial 57 finished with value: 0.8413013953464789 and parameters: {'lambda_l1': 1.00265105434484e-08, 'lambda_l2': 0.004057559164820877}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  75%|#######5  | 15/20 [07:24<02:30, 30.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076196 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  80%|########  | 16/20 [07:53<01:58, 29.66s/it]\u001b[32m[I 2021-07-01 12:49:44,373]\u001b[0m Trial 58 finished with value: 0.8422997380233054 and parameters: {'lambda_l1': 0.00014560205462777124, 'lambda_l2': 0.0005798643526568987}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  80%|########  | 16/20 [07:53<01:58, 29.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073296 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840885:  85%|########5 | 17/20 [08:24<01:30, 30.25s/it]\u001b[32m[I 2021-07-01 12:50:15,991]\u001b[0m Trial 59 finished with value: 0.8410904818740742 and parameters: {'lambda_l1': 3.9507438579700504e-07, 'lambda_l2': 6.285485226978477}. Best is trial 53 with value: 0.8408851468434623.\u001b[0m\n",
      "regularization_factors, val_score: 0.840885:  85%|########5 | 17/20 [08:24<01:30, 30.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078640 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840212:  90%|######### | 18/20 [08:56<01:01, 30.77s/it]\u001b[32m[I 2021-07-01 12:50:47,986]\u001b[0m Trial 60 finished with value: 0.840212085204121 and parameters: {'lambda_l1': 9.507051735075546e-06, 'lambda_l2': 1.7992356814795836}. Best is trial 60 with value: 0.840212085204121.\u001b[0m\n",
      "regularization_factors, val_score: 0.840212:  90%|######### | 18/20 [08:56<01:01, 30.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073564 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840212:  95%|#########5| 19/20 [09:29<00:31, 31.43s/it]\u001b[32m[I 2021-07-01 12:51:20,933]\u001b[0m Trial 61 finished with value: 0.8408613905416163 and parameters: {'lambda_l1': 1.193531453892734e-05, 'lambda_l2': 1.4045776888578276}. Best is trial 60 with value: 0.840212085204121.\u001b[0m\n",
      "regularization_factors, val_score: 0.840212:  95%|#########5| 19/20 [09:29<00:31, 31.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077384 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.840212: 100%|##########| 20/20 [10:01<00:00, 31.45s/it]\u001b[32m[I 2021-07-01 12:51:52,434]\u001b[0m Trial 62 finished with value: 0.8413333295359076 and parameters: {'lambda_l1': 0.0009764569062548537, 'lambda_l2': 0.8337716674609761}. Best is trial 60 with value: 0.840212085204121.\u001b[0m\n",
      "regularization_factors, val_score: 0.840212: 100%|##########| 20/20 [10:01<00:00, 30.07s/it]\n",
      "min_data_in_leaf, val_score: 0.840212:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.838817:  20%|##        | 1/5 [00:30<02:02, 30.52s/it]\u001b[32m[I 2021-07-01 12:52:22,955]\u001b[0m Trial 63 finished with value: 0.8388168817054826 and parameters: {'min_child_samples': 100}. Best is trial 63 with value: 0.8388168817054826.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.838817:  20%|##        | 1/5 [00:30<02:02, 30.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077074 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.838817:  40%|####      | 2/5 [01:02<01:34, 31.37s/it]\u001b[32m[I 2021-07-01 12:52:54,921]\u001b[0m Trial 64 finished with value: 0.8429568723821009 and parameters: {'min_child_samples': 5}. Best is trial 63 with value: 0.8388168817054826.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.838817:  40%|####      | 2/5 [01:02<01:34, 31.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070849 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.838817:  60%|######    | 3/5 [01:32<01:01, 30.73s/it]\u001b[32m[I 2021-07-01 12:53:24,888]\u001b[0m Trial 65 finished with value: 0.8410246110758759 and parameters: {'min_child_samples': 25}. Best is trial 63 with value: 0.8388168817054826.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.838817:  60%|######    | 3/5 [01:32<01:01, 30.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073354 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.838817:  80%|########  | 4/5 [02:03<00:31, 31.01s/it]\u001b[32m[I 2021-07-01 12:53:56,338]\u001b[0m Trial 66 finished with value: 0.8420457242220096 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.8388168817054826.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.838817:  80%|########  | 4/5 [02:03<00:31, 31.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074014 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10184\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 112\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.838817: 100%|##########| 5/5 [02:34<00:00, 30.78s/it]\u001b[32m[I 2021-07-01 12:54:26,692]\u001b[0m Trial 67 finished with value: 0.8404862256299214 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.8388168817054826.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.838817: 100%|##########| 5/5 [02:34<00:00, 30.85s/it]\n"
     ]
    }
   ],
   "source": [
    "tr_idx = tr_idxs[idx]\n",
    "val_idx = val_idxs[idx]\n",
    "\n",
    "x_train = train_X.loc[tr_idx].reset_index(drop=True)\n",
    "y_train = train_y.loc[tr_idx].reset_index(drop=True)\n",
    "x_valid = train_X.loc[val_idx].reset_index(drop=True)\n",
    "y_valid = train_y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "trains = lgbm.Dataset(x_train[feature_cols2], y_train['target1'])\n",
    "valids = lgbm.Dataset(x_valid[feature_cols2], y_valid['target1'])\n",
    "\n",
    "\n",
    "model2 = lgbm.train(params, trains, valid_sets=[trains, valids],\n",
    "                    verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea49fc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 12:54:27,407]\u001b[0m A new study created in memory with name: no-name-8e11746e-6a94-4f62-82cc-87b28750bf98\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.845576:  14%|#4        | 1/7 [00:18<01:53, 19.00s/it]\u001b[32m[I 2021-07-01 12:54:46,406]\u001b[0m Trial 0 finished with value: 0.8455762878947325 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.8455762878947325.\u001b[0m\n",
      "feature_fraction, val_score: 0.845576:  14%|#4        | 1/7 [00:18<01:53, 19.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082593 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.845203:  29%|##8       | 2/7 [00:42<01:47, 21.49s/it]\u001b[32m[I 2021-07-01 12:55:09,648]\u001b[0m Trial 1 finished with value: 0.8452034621972824 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 1 with value: 0.8452034621972824.\u001b[0m\n",
      "feature_fraction, val_score: 0.845203:  29%|##8       | 2/7 [00:42<01:47, 21.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.217979 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843241:  43%|####2     | 3/7 [01:01<01:22, 20.61s/it]\u001b[32m[I 2021-07-01 12:55:29,203]\u001b[0m Trial 2 finished with value: 0.8432405999107841 and parameters: {'feature_fraction': 0.6}. Best is trial 2 with value: 0.8432405999107841.\u001b[0m\n",
      "feature_fraction, val_score: 0.843241:  43%|####2     | 3/7 [01:01<01:22, 20.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.083631 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.843241:  57%|#####7    | 4/7 [01:23<01:03, 21.08s/it]\u001b[32m[I 2021-07-01 12:55:51,009]\u001b[0m Trial 3 finished with value: 0.8447120403365161 and parameters: {'feature_fraction': 1.0}. Best is trial 2 with value: 0.8432405999107841.\u001b[0m\n",
      "feature_fraction, val_score: 0.843241:  57%|#####7    | 4/7 [01:23<01:03, 21.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.842369:  71%|#######1  | 5/7 [01:49<00:45, 22.66s/it]\u001b[32m[I 2021-07-01 12:56:16,459]\u001b[0m Trial 4 finished with value: 0.8423686838369902 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.8423686838369902.\u001b[0m\n",
      "feature_fraction, val_score: 0.842369:  71%|#######1  | 5/7 [01:49<00:45, 22.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.304357 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.842369:  86%|########5 | 6/7 [02:08<00:21, 21.50s/it]\u001b[32m[I 2021-07-01 12:56:35,717]\u001b[0m Trial 5 finished with value: 0.8458906896210545 and parameters: {'feature_fraction': 0.7}. Best is trial 4 with value: 0.8423686838369902.\u001b[0m\n",
      "feature_fraction, val_score: 0.842369:  86%|########5 | 6/7 [02:08<00:21, 21.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072704 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.841588: 100%|##########| 7/7 [02:35<00:00, 23.46s/it]\u001b[32m[I 2021-07-01 12:57:03,206]\u001b[0m Trial 6 finished with value: 0.8415884954480315 and parameters: {'feature_fraction': 0.5}. Best is trial 6 with value: 0.8415884954480315.\u001b[0m\n",
      "feature_fraction, val_score: 0.841588: 100%|##########| 7/7 [02:35<00:00, 22.26s/it]\n",
      "num_leaves, val_score: 0.841588:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071257 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:   5%|5         | 1/20 [00:31<09:56, 31.40s/it]\u001b[32m[I 2021-07-01 12:57:34,611]\u001b[0m Trial 7 finished with value: 0.8401811298167521 and parameters: {'num_leaves': 95}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:   5%|5         | 1/20 [00:31<09:56, 31.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069185 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  10%|#         | 2/20 [01:07<10:19, 34.41s/it]\u001b[32m[I 2021-07-01 12:58:11,126]\u001b[0m Trial 8 finished with value: 0.8425742049109173 and parameters: {'num_leaves': 201}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  10%|#         | 2/20 [01:07<10:19, 34.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075758 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  15%|#5        | 3/20 [01:38<09:15, 32.69s/it]\u001b[32m[I 2021-07-01 12:58:41,767]\u001b[0m Trial 9 finished with value: 0.840184090592921 and parameters: {'num_leaves': 80}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  15%|#5        | 3/20 [01:38<09:15, 32.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070277 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  20%|##        | 4/20 [02:17<09:21, 35.10s/it]\u001b[32m[I 2021-07-01 12:59:20,557]\u001b[0m Trial 10 finished with value: 0.8437415356742526 and parameters: {'num_leaves': 230}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  20%|##        | 4/20 [02:17<09:21, 35.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.081653 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  25%|##5       | 5/20 [02:47<08:22, 33.49s/it]\u001b[32m[I 2021-07-01 12:59:51,198]\u001b[0m Trial 11 finished with value: 0.840184090592921 and parameters: {'num_leaves': 80}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  25%|##5       | 5/20 [02:47<08:22, 33.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068875 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  30%|###       | 6/20 [03:14<07:15, 31.10s/it]\u001b[32m[I 2021-07-01 13:00:17,663]\u001b[0m Trial 12 finished with value: 0.8417475077881461 and parameters: {'num_leaves': 34}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  30%|###       | 6/20 [03:14<07:15, 31.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  35%|###5      | 7/20 [03:49<07:01, 32.43s/it]\u001b[32m[I 2021-07-01 13:00:52,830]\u001b[0m Trial 13 finished with value: 0.8438291185085893 and parameters: {'num_leaves': 216}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  35%|###5      | 7/20 [03:49<07:01, 32.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076788 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  40%|####      | 8/20 [04:17<06:10, 30.88s/it]\u001b[32m[I 2021-07-01 13:01:20,380]\u001b[0m Trial 14 finished with value: 0.8412249278032792 and parameters: {'num_leaves': 45}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  40%|####      | 8/20 [04:17<06:10, 30.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070297 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  45%|####5     | 9/20 [04:52<05:54, 32.25s/it]\u001b[32m[I 2021-07-01 13:01:55,633]\u001b[0m Trial 15 finished with value: 0.8425684778925207 and parameters: {'num_leaves': 182}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  45%|####5     | 9/20 [04:52<05:54, 32.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073499 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.840181:  50%|#####     | 10/20 [05:20<05:10, 31.03s/it]\u001b[32m[I 2021-07-01 13:02:23,958]\u001b[0m Trial 16 finished with value: 0.8407893906350804 and parameters: {'num_leaves': 46}. Best is trial 7 with value: 0.8401811298167521.\u001b[0m\n",
      "num_leaves, val_score: 0.840181:  50%|#####     | 10/20 [05:20<05:10, 31.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839588:  55%|#####5    | 11/20 [05:55<04:50, 32.31s/it]\u001b[32m[I 2021-07-01 13:02:59,144]\u001b[0m Trial 17 finished with value: 0.8395880916407972 and parameters: {'num_leaves': 147}. Best is trial 17 with value: 0.8395880916407972.\u001b[0m\n",
      "num_leaves, val_score: 0.839588:  55%|#####5    | 11/20 [05:55<04:50, 32.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078984 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  60%|######    | 12/20 [06:32<04:28, 33.56s/it]\u001b[32m[I 2021-07-01 13:03:35,583]\u001b[0m Trial 18 finished with value: 0.8392390513079521 and parameters: {'num_leaves': 152}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  60%|######    | 12/20 [06:32<04:28, 33.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075819 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  65%|######5   | 13/20 [07:08<04:01, 34.47s/it]\u001b[32m[I 2021-07-01 13:04:12,157]\u001b[0m Trial 19 finished with value: 0.8392390513079521 and parameters: {'num_leaves': 152}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  65%|######5   | 13/20 [07:08<04:01, 34.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070193 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  70%|#######   | 14/20 [07:44<03:28, 34.69s/it]\u001b[32m[I 2021-07-01 13:04:47,348]\u001b[0m Trial 20 finished with value: 0.8402934894323719 and parameters: {'num_leaves': 144}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  70%|#######   | 14/20 [07:44<03:28, 34.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071426 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  75%|#######5  | 15/20 [08:16<02:49, 33.90s/it]\u001b[32m[I 2021-07-01 13:05:19,423]\u001b[0m Trial 21 finished with value: 0.8425216724940608 and parameters: {'num_leaves': 172}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  75%|#######5  | 15/20 [08:16<02:49, 33.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075695 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  80%|########  | 16/20 [08:48<02:13, 33.48s/it]\u001b[32m[I 2021-07-01 13:05:51,910]\u001b[0m Trial 22 finished with value: 0.8403332861880592 and parameters: {'num_leaves': 114}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  80%|########  | 16/20 [08:48<02:13, 33.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073794 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  85%|########5 | 17/20 [09:25<01:43, 34.58s/it]\u001b[32m[I 2021-07-01 13:06:29,067]\u001b[0m Trial 23 finished with value: 0.8405515381832573 and parameters: {'num_leaves': 164}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  85%|########5 | 17/20 [09:25<01:43, 34.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078654 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  90%|######### | 18/20 [10:01<01:10, 35.05s/it]\u001b[32m[I 2021-07-01 13:07:05,202]\u001b[0m Trial 24 finished with value: 0.8447816975238909 and parameters: {'num_leaves': 244}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  90%|######### | 18/20 [10:01<01:10, 35.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239:  95%|#########5| 19/20 [10:35<00:34, 34.69s/it]\u001b[32m[I 2021-07-01 13:07:39,071]\u001b[0m Trial 25 finished with value: 0.8403780587871206 and parameters: {'num_leaves': 130}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239:  95%|#########5| 19/20 [10:35<00:34, 34.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.839239: 100%|##########| 20/20 [11:12<00:00, 35.16s/it]\u001b[32m[I 2021-07-01 13:08:15,320]\u001b[0m Trial 26 finished with value: 0.8429820974246299 and parameters: {'num_leaves': 195}. Best is trial 18 with value: 0.8392390513079521.\u001b[0m\n",
      "num_leaves, val_score: 0.839239: 100%|##########| 20/20 [11:12<00:00, 33.61s/it]\n",
      "bagging, val_score: 0.839239:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  10%|#         | 1/10 [00:34<05:06, 34.05s/it]\u001b[32m[I 2021-07-01 13:08:49,377]\u001b[0m Trial 27 finished with value: 0.8420649993507893 and parameters: {'bagging_fraction': 0.9401227049287499, 'bagging_freq': 1}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  10%|#         | 1/10 [00:34<05:06, 34.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069149 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  20%|##        | 2/10 [00:54<03:30, 26.33s/it]\u001b[32m[I 2021-07-01 13:09:10,308]\u001b[0m Trial 28 finished with value: 0.8459424580480376 and parameters: {'bagging_fraction': 0.41681945824111505, 'bagging_freq': 7}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  20%|##        | 2/10 [00:54<03:30, 26.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069597 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  30%|###       | 3/10 [01:25<03:16, 28.03s/it]\u001b[32m[I 2021-07-01 13:09:40,353]\u001b[0m Trial 29 finished with value: 0.8441866650289152 and parameters: {'bagging_fraction': 0.7222220640757772, 'bagging_freq': 1}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  30%|###       | 3/10 [01:25<03:16, 28.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079780 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  40%|####      | 4/10 [01:48<02:38, 26.40s/it]\u001b[32m[I 2021-07-01 13:10:04,265]\u001b[0m Trial 30 finished with value: 0.8439856813080325 and parameters: {'bagging_fraction': 0.4945579052238475, 'bagging_freq': 6}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  40%|####      | 4/10 [01:48<02:38, 26.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071809 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  50%|#####     | 5/10 [02:16<02:14, 26.96s/it]\u001b[32m[I 2021-07-01 13:10:32,224]\u001b[0m Trial 31 finished with value: 0.843445244807587 and parameters: {'bagging_fraction': 0.6232490261164851, 'bagging_freq': 6}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  50%|#####     | 5/10 [02:16<02:14, 26.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072753 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  60%|######    | 6/10 [02:38<01:40, 25.14s/it]\u001b[32m[I 2021-07-01 13:10:53,833]\u001b[0m Trial 32 finished with value: 0.8485345306014868 and parameters: {'bagging_fraction': 0.4837440329376601, 'bagging_freq': 5}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  60%|######    | 6/10 [02:38<01:40, 25.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071836 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  70%|#######   | 7/10 [03:08<01:20, 26.88s/it]\u001b[32m[I 2021-07-01 13:11:24,276]\u001b[0m Trial 33 finished with value: 0.844230678921952 and parameters: {'bagging_fraction': 0.7824285927923332, 'bagging_freq': 6}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  70%|#######   | 7/10 [03:08<01:20, 26.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070975 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  80%|########  | 8/10 [03:44<00:59, 29.62s/it]\u001b[32m[I 2021-07-01 13:11:59,769]\u001b[0m Trial 34 finished with value: 0.8435970089996496 and parameters: {'bagging_fraction': 0.7444521558227084, 'bagging_freq': 2}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  80%|########  | 8/10 [03:44<00:59, 29.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072454 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239:  90%|######### | 9/10 [04:24<00:32, 32.77s/it]\u001b[32m[I 2021-07-01 13:12:39,480]\u001b[0m Trial 35 finished with value: 0.8425640067571518 and parameters: {'bagging_fraction': 0.900806117481939, 'bagging_freq': 3}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239:  90%|######### | 9/10 [04:24<00:32, 32.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073162 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.839239: 100%|##########| 10/10 [04:59<00:00, 33.46s/it]\u001b[32m[I 2021-07-01 13:13:14,473]\u001b[0m Trial 36 finished with value: 0.842806040464949 and parameters: {'bagging_fraction': 0.9323887500329092, 'bagging_freq': 6}. Best is trial 27 with value: 0.8420649993507893.\u001b[0m\n",
      "bagging, val_score: 0.839239: 100%|##########| 10/10 [04:59<00:00, 29.92s/it]\n",
      "feature_fraction_stage2, val_score: 0.839239:   0%|          | 0/6 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839239:  17%|#6        | 1/6 [00:30<02:33, 30.68s/it]\u001b[32m[I 2021-07-01 13:13:45,159]\u001b[0m Trial 37 finished with value: 0.8432094080577117 and parameters: {'feature_fraction': 0.42}. Best is trial 37 with value: 0.8432094080577117.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839239:  17%|#6        | 1/6 [00:30<02:33, 30.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342397 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839239:  33%|###3      | 2/6 [01:01<02:02, 30.74s/it]\u001b[32m[I 2021-07-01 13:14:15,945]\u001b[0m Trial 38 finished with value: 0.8406898331012688 and parameters: {'feature_fraction': 0.5479999999999999}. Best is trial 38 with value: 0.8406898331012688.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839239:  33%|###3      | 2/6 [01:01<02:02, 30.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.342293 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839239:  50%|#####     | 3/6 [01:32<01:32, 30.70s/it]\u001b[32m[I 2021-07-01 13:14:46,587]\u001b[0m Trial 39 finished with value: 0.8400629234208128 and parameters: {'feature_fraction': 0.516}. Best is trial 39 with value: 0.8400629234208128.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839239:  50%|#####     | 3/6 [01:32<01:32, 30.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076157 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839239:  67%|######6   | 4/6 [02:01<01:00, 30.35s/it]\u001b[32m[I 2021-07-01 13:15:16,407]\u001b[0m Trial 40 finished with value: 0.8426325444703027 and parameters: {'feature_fraction': 0.45199999999999996}. Best is trial 39 with value: 0.8400629234208128.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839239:  67%|######6   | 4/6 [02:01<01:00, 30.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.282806 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839239:  83%|########3 | 5/6 [02:32<00:30, 30.52s/it]\u001b[32m[I 2021-07-01 13:15:47,232]\u001b[0m Trial 41 finished with value: 0.8417430536390799 and parameters: {'feature_fraction': 0.58}. Best is trial 39 with value: 0.8400629234208128.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839239:  83%|########3 | 5/6 [02:32<00:30, 30.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072581 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.839239: 100%|##########| 6/6 [03:07<00:00, 32.04s/it]\u001b[32m[I 2021-07-01 13:16:22,228]\u001b[0m Trial 42 finished with value: 0.8405526091475896 and parameters: {'feature_fraction': 0.484}. Best is trial 39 with value: 0.8400629234208128.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.839239: 100%|##########| 6/6 [03:07<00:00, 31.29s/it]\n",
      "regularization_factors, val_score: 0.839239:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069848 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839239:   5%|5         | 1/20 [00:33<10:37, 33.57s/it]\u001b[32m[I 2021-07-01 13:16:55,803]\u001b[0m Trial 43 finished with value: 0.8408435828446237 and parameters: {'lambda_l1': 0.07937639476711635, 'lambda_l2': 0.007670806460835616}. Best is trial 43 with value: 0.8408435828446237.\u001b[0m\n",
      "regularization_factors, val_score: 0.839239:   5%|5         | 1/20 [00:33<10:37, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069500 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839239:  10%|#         | 2/20 [01:09<10:34, 35.24s/it]\u001b[32m[I 2021-07-01 13:17:32,202]\u001b[0m Trial 44 finished with value: 0.8396022354219087 and parameters: {'lambda_l1': 1.3879940015016036e-06, 'lambda_l2': 2.488109428047979e-06}. Best is trial 44 with value: 0.8396022354219087.\u001b[0m\n",
      "regularization_factors, val_score: 0.839239:  10%|#         | 2/20 [01:09<10:34, 35.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069562 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839239:  15%|#5        | 3/20 [01:43<09:42, 34.29s/it]\u001b[32m[I 2021-07-01 13:18:05,369]\u001b[0m Trial 45 finished with value: 0.8405701349158785 and parameters: {'lambda_l1': 0.0008150034179633222, 'lambda_l2': 9.845291500709718e-07}. Best is trial 44 with value: 0.8396022354219087.\u001b[0m\n",
      "regularization_factors, val_score: 0.839239:  15%|#5        | 3/20 [01:43<09:42, 34.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069519 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839239:  20%|##        | 4/20 [02:19<09:23, 35.23s/it]\u001b[32m[I 2021-07-01 13:18:42,051]\u001b[0m Trial 46 finished with value: 0.8392395896623202 and parameters: {'lambda_l1': 5.7841067227711136e-08, 'lambda_l2': 1.03768991332696e-08}. Best is trial 46 with value: 0.8392395896623202.\u001b[0m\n",
      "regularization_factors, val_score: 0.839239:  20%|##        | 4/20 [02:19<09:23, 35.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075475 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  25%|##5       | 5/20 [02:56<08:57, 35.86s/it]\u001b[32m[I 2021-07-01 13:19:19,031]\u001b[0m Trial 47 finished with value: 0.8391857867430473 and parameters: {'lambda_l1': 3.7613071959208517e-07, 'lambda_l2': 3.9794556502989556e-08}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  25%|##5       | 5/20 [02:56<08:57, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080205 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  30%|###       | 6/20 [03:33<08:23, 36.00s/it]\u001b[32m[I 2021-07-01 13:19:55,285]\u001b[0m Trial 48 finished with value: 0.8396043376413213 and parameters: {'lambda_l1': 1.1613678824096253e-06, 'lambda_l2': 1.1635775910976045e-05}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  30%|###       | 6/20 [03:33<08:23, 36.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069513 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  35%|###5      | 7/20 [04:04<07:29, 34.58s/it]\u001b[32m[I 2021-07-01 13:20:26,958]\u001b[0m Trial 49 finished with value: 0.8415021505638374 and parameters: {'lambda_l1': 2.019543754136995e-05, 'lambda_l2': 0.01606292964551952}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  35%|###5      | 7/20 [04:04<07:29, 34.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  40%|####      | 8/20 [04:40<07:00, 35.06s/it]\u001b[32m[I 2021-07-01 13:21:03,046]\u001b[0m Trial 50 finished with value: 0.8401815090282847 and parameters: {'lambda_l1': 0.01466851507423689, 'lambda_l2': 0.00037761637899273536}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  40%|####      | 8/20 [04:40<07:00, 35.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073623 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  45%|####5     | 9/20 [05:13<06:19, 34.46s/it]\u001b[32m[I 2021-07-01 13:21:36,196]\u001b[0m Trial 51 finished with value: 0.8404695701729538 and parameters: {'lambda_l1': 0.00010019847296633243, 'lambda_l2': 1.7568874170500095e-05}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  45%|####5     | 9/20 [05:13<06:19, 34.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070561 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  50%|#####     | 10/20 [05:47<05:41, 34.12s/it]\u001b[32m[I 2021-07-01 13:22:09,532]\u001b[0m Trial 52 finished with value: 0.8404351772879344 and parameters: {'lambda_l1': 3.577095119159607e-07, 'lambda_l2': 0.0049029008433299605}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  50%|#####     | 10/20 [05:47<05:41, 34.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070766 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  55%|#####5    | 11/20 [06:24<05:14, 34.97s/it]\u001b[32m[I 2021-07-01 13:22:46,453]\u001b[0m Trial 53 finished with value: 0.8407822774645716 and parameters: {'lambda_l1': 9.31092205981237, 'lambda_l2': 1.1540260953794454e-08}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  55%|#####5    | 11/20 [06:24<05:14, 34.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071022 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  60%|######    | 12/20 [07:02<04:48, 36.11s/it]\u001b[32m[I 2021-07-01 13:23:25,154]\u001b[0m Trial 54 finished with value: 0.8406272679296094 and parameters: {'lambda_l1': 1.2083947949949666e-08, 'lambda_l2': 5.827426608171863}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  60%|######    | 12/20 [07:02<04:48, 36.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071878 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  65%|######5   | 13/20 [07:39<04:14, 36.29s/it]\u001b[32m[I 2021-07-01 13:24:01,852]\u001b[0m Trial 55 finished with value: 0.8392439364212065 and parameters: {'lambda_l1': 1.944929638284906e-08, 'lambda_l2': 1.3768240662154603e-08}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  65%|######5   | 13/20 [07:39<04:14, 36.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071043 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  70%|#######   | 14/20 [08:16<03:38, 36.43s/it]\u001b[32m[I 2021-07-01 13:24:38,602]\u001b[0m Trial 56 finished with value: 0.8392435817221289 and parameters: {'lambda_l1': 1.1139575762811157e-08, 'lambda_l2': 5.771448354574591e-08}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  70%|#######   | 14/20 [08:16<03:38, 36.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070747 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839186:  75%|#######5  | 15/20 [08:53<03:02, 36.56s/it]\u001b[32m[I 2021-07-01 13:25:15,465]\u001b[0m Trial 57 finished with value: 0.8395772941911691 and parameters: {'lambda_l1': 2.033411495157404e-07, 'lambda_l2': 2.2744428102507649e-07}. Best is trial 47 with value: 0.8391857867430473.\u001b[0m\n",
      "regularization_factors, val_score: 0.839186:  75%|#######5  | 15/20 [08:53<03:02, 36.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075126 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839184:  80%|########  | 16/20 [09:30<02:26, 36.63s/it]\u001b[32m[I 2021-07-01 13:25:52,264]\u001b[0m Trial 58 finished with value: 0.839183517833361 and parameters: {'lambda_l1': 8.481151951951655e-08, 'lambda_l2': 1.1181371584967872e-08}. Best is trial 58 with value: 0.839183517833361.\u001b[0m\n",
      "regularization_factors, val_score: 0.839184:  80%|########  | 16/20 [09:30<02:26, 36.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069751 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839184:  85%|########5 | 17/20 [10:06<01:49, 36.62s/it]\u001b[32m[I 2021-07-01 13:26:28,865]\u001b[0m Trial 59 finished with value: 0.8396012721065109 and parameters: {'lambda_l1': 8.456992013823041e-06, 'lambda_l2': 1.1599158903018748e-07}. Best is trial 58 with value: 0.839183517833361.\u001b[0m\n",
      "regularization_factors, val_score: 0.839184:  85%|########5 | 17/20 [10:06<01:49, 36.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074552 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839184:  90%|######### | 18/20 [10:43<01:13, 36.68s/it]\u001b[32m[I 2021-07-01 13:27:05,676]\u001b[0m Trial 60 finished with value: 0.8398706504800485 and parameters: {'lambda_l1': 0.0009377887498097112, 'lambda_l2': 0.34568249553537017}. Best is trial 58 with value: 0.839183517833361.\u001b[0m\n",
      "regularization_factors, val_score: 0.839184:  90%|######### | 18/20 [10:43<01:13, 36.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069884 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839184:  95%|#########5| 19/20 [11:20<00:36, 36.76s/it]\u001b[32m[I 2021-07-01 13:27:42,629]\u001b[0m Trial 61 finished with value: 0.839923405779517 and parameters: {'lambda_l1': 5.840422289813484e-06, 'lambda_l2': 0.00012390913259202797}. Best is trial 58 with value: 0.839183517833361.\u001b[0m\n",
      "regularization_factors, val_score: 0.839184:  95%|#########5| 19/20 [11:20<00:36, 36.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069991 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.839184: 100%|##########| 20/20 [11:57<00:00, 36.77s/it]\u001b[32m[I 2021-07-01 13:28:19,429]\u001b[0m Trial 62 finished with value: 0.8396041692103585 and parameters: {'lambda_l1': 1.165786723829069e-07, 'lambda_l2': 8.76717077081482e-07}. Best is trial 58 with value: 0.839183517833361.\u001b[0m\n",
      "regularization_factors, val_score: 0.839184: 100%|##########| 20/20 [11:57<00:00, 35.86s/it]\n",
      "min_data_in_leaf, val_score: 0.839184:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069468 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839184:  20%|##        | 1/5 [00:31<02:07, 31.98s/it]\u001b[32m[I 2021-07-01 13:28:51,414]\u001b[0m Trial 63 finished with value: 0.8408736342427766 and parameters: {'min_child_samples': 50}. Best is trial 63 with value: 0.8408736342427766.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839184:  20%|##        | 1/5 [00:31<02:07, 31.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070708 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839184:  40%|####      | 2/5 [01:06<01:40, 33.57s/it]\u001b[32m[I 2021-07-01 13:29:26,095]\u001b[0m Trial 64 finished with value: 0.8411053334319188 and parameters: {'min_child_samples': 10}. Best is trial 63 with value: 0.8408736342427766.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839184:  40%|####      | 2/5 [01:06<01:40, 33.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069303 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839184:  60%|######    | 3/5 [01:41<01:08, 34.37s/it]\u001b[32m[I 2021-07-01 13:30:01,428]\u001b[0m Trial 65 finished with value: 0.8408224801964944 and parameters: {'min_child_samples': 25}. Best is trial 65 with value: 0.8408224801964944.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839184:  60%|######    | 3/5 [01:41<01:08, 34.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071176 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839184:  80%|########  | 4/5 [02:11<00:32, 32.40s/it]\u001b[32m[I 2021-07-01 13:30:30,796]\u001b[0m Trial 66 finished with value: 0.8462326206563607 and parameters: {'min_child_samples': 5}. Best is trial 65 with value: 0.8408224801964944.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839184:  80%|########  | 4/5 [02:11<00:32, 32.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076104 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10191\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 113\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.839184: 100%|##########| 5/5 [02:43<00:00, 32.24s/it]\u001b[32m[I 2021-07-01 13:31:02,763]\u001b[0m Trial 67 finished with value: 0.8400495532100003 and parameters: {'min_child_samples': 100}. Best is trial 67 with value: 0.8400495532100003.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.839184: 100%|##########| 5/5 [02:43<00:00, 32.67s/it]\n"
     ]
    }
   ],
   "source": [
    "tr_idx = tr_idxs[idx]\n",
    "val_idx = val_idxs[idx]\n",
    "\n",
    "x_train = train_X.loc[tr_idx].reset_index(drop=True)\n",
    "y_train = train_y.loc[tr_idx].reset_index(drop=True)\n",
    "x_valid = train_X.loc[val_idx].reset_index(drop=True)\n",
    "y_valid = train_y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "\n",
    "trains = lgbm.Dataset(x_train[feature_cols3], y_train['target1'])\n",
    "valids = lgbm.Dataset(x_valid[feature_cols3], y_valid['target1'])\n",
    "\n",
    "\n",
    "model3 = lgbm.train(params, trains, valid_sets=[trains, valids],\n",
    "                    verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "095a8530",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-01 13:31:03,446]\u001b[0m A new study created in memory with name: no-name-e635b12b-b3ed-47e0-8e23-d53538536a8a\u001b[0m\n",
      "feature_fraction, val_score: inf:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.832514:  14%|#4        | 1/7 [00:17<01:43, 17.21s/it]\u001b[32m[I 2021-07-01 13:31:20,662]\u001b[0m Trial 0 finished with value: 0.832513804231159 and parameters: {'feature_fraction': 0.8}. Best is trial 0 with value: 0.832513804231159.\u001b[0m\n",
      "feature_fraction, val_score: 0.832514:  14%|#4        | 1/7 [00:17<01:43, 17.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.304620 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.831528:  29%|##8       | 2/7 [00:33<01:22, 16.41s/it]\u001b[32m[I 2021-07-01 13:31:36,505]\u001b[0m Trial 1 finished with value: 0.8315282283303522 and parameters: {'feature_fraction': 0.6}. Best is trial 1 with value: 0.8315282283303522.\u001b[0m\n",
      "feature_fraction, val_score: 0.831528:  29%|##8       | 2/7 [00:33<01:22, 16.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.234608 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.831528:  43%|####2     | 3/7 [00:49<01:04, 16.23s/it]\u001b[32m[I 2021-07-01 13:31:52,522]\u001b[0m Trial 2 finished with value: 0.8336576248814375 and parameters: {'feature_fraction': 0.7}. Best is trial 1 with value: 0.8315282283303522.\u001b[0m\n",
      "feature_fraction, val_score: 0.831528:  43%|####2     | 3/7 [00:49<01:04, 16.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073627 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.828988:  57%|#####7    | 4/7 [01:10<00:54, 18.24s/it]\u001b[32m[I 2021-07-01 13:32:13,856]\u001b[0m Trial 3 finished with value: 0.828987505583712 and parameters: {'feature_fraction': 0.5}. Best is trial 3 with value: 0.828987505583712.\u001b[0m\n",
      "feature_fraction, val_score: 0.828988:  57%|#####7    | 4/7 [01:10<00:54, 18.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075730 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.826222:  71%|#######1  | 5/7 [01:30<00:37, 18.91s/it]\u001b[32m[I 2021-07-01 13:32:33,948]\u001b[0m Trial 4 finished with value: 0.826222391187974 and parameters: {'feature_fraction': 0.4}. Best is trial 4 with value: 0.826222391187974.\u001b[0m\n",
      "feature_fraction, val_score: 0.826222:  71%|#######1  | 5/7 [01:30<00:37, 18.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.082461 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.826222:  86%|########5 | 6/7 [01:47<00:18, 18.18s/it]\u001b[32m[I 2021-07-01 13:32:50,720]\u001b[0m Trial 5 finished with value: 0.8333954300605318 and parameters: {'feature_fraction': 0.8999999999999999}. Best is trial 4 with value: 0.826222391187974.\u001b[0m\n",
      "feature_fraction, val_score: 0.826222:  86%|########5 | 6/7 [01:47<00:18, 18.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079910 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction, val_score: 0.826222: 100%|##########| 7/7 [02:04<00:00, 17.81s/it]\u001b[32m[I 2021-07-01 13:33:07,774]\u001b[0m Trial 6 finished with value: 0.8322831434172417 and parameters: {'feature_fraction': 1.0}. Best is trial 4 with value: 0.826222391187974.\u001b[0m\n",
      "feature_fraction, val_score: 0.826222: 100%|##########| 7/7 [02:04<00:00, 17.76s/it]\n",
      "num_leaves, val_score: 0.826222:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069179 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.822830:   5%|5         | 1/20 [00:21<06:50, 21.62s/it]\u001b[32m[I 2021-07-01 13:33:29,400]\u001b[0m Trial 7 finished with value: 0.8228299724145174 and parameters: {'num_leaves': 85}. Best is trial 7 with value: 0.8228299724145174.\u001b[0m\n",
      "num_leaves, val_score: 0.822830:   5%|5         | 1/20 [00:21<06:50, 21.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070615 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820819:  10%|#         | 2/20 [00:52<08:12, 27.35s/it]\u001b[32m[I 2021-07-01 13:34:00,757]\u001b[0m Trial 8 finished with value: 0.8208193325756277 and parameters: {'num_leaves': 246}. Best is trial 8 with value: 0.8208193325756277.\u001b[0m\n",
      "num_leaves, val_score: 0.820819:  10%|#         | 2/20 [00:52<08:12, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070178 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820819:  15%|#5        | 3/20 [01:20<07:46, 27.42s/it]\u001b[32m[I 2021-07-01 13:34:28,260]\u001b[0m Trial 9 finished with value: 0.8212774050799011 and parameters: {'num_leaves': 217}. Best is trial 8 with value: 0.8208193325756277.\u001b[0m\n",
      "num_leaves, val_score: 0.820819:  15%|#5        | 3/20 [01:20<07:46, 27.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072569 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820819:  20%|##        | 4/20 [01:42<06:43, 25.22s/it]\u001b[32m[I 2021-07-01 13:34:50,121]\u001b[0m Trial 10 finished with value: 0.8232186363806696 and parameters: {'num_leaves': 86}. Best is trial 8 with value: 0.8208193325756277.\u001b[0m\n",
      "num_leaves, val_score: 0.820819:  20%|##        | 4/20 [01:42<06:43, 25.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068925 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820010:  25%|##5       | 5/20 [02:11<06:39, 26.62s/it]\u001b[32m[I 2021-07-01 13:35:19,226]\u001b[0m Trial 11 finished with value: 0.8200100002434364 and parameters: {'num_leaves': 196}. Best is trial 11 with value: 0.8200100002434364.\u001b[0m\n",
      "num_leaves, val_score: 0.820010:  25%|##5       | 5/20 [02:11<06:39, 26.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820010:  30%|###       | 6/20 [02:31<05:43, 24.56s/it]\u001b[32m[I 2021-07-01 13:35:39,774]\u001b[0m Trial 12 finished with value: 0.8297735225320949 and parameters: {'num_leaves': 18}. Best is trial 11 with value: 0.8200100002434364.\u001b[0m\n",
      "num_leaves, val_score: 0.820010:  30%|###       | 6/20 [02:31<05:43, 24.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072141 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820010:  35%|###5      | 7/20 [02:53<05:07, 23.68s/it]\u001b[32m[I 2021-07-01 13:36:01,632]\u001b[0m Trial 13 finished with value: 0.8232186363806696 and parameters: {'num_leaves': 86}. Best is trial 11 with value: 0.8200100002434364.\u001b[0m\n",
      "num_leaves, val_score: 0.820010:  35%|###5      | 7/20 [02:53<05:07, 23.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072492 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820010:  40%|####      | 8/20 [03:20<04:56, 24.70s/it]\u001b[32m[I 2021-07-01 13:36:28,512]\u001b[0m Trial 14 finished with value: 0.8209858926431445 and parameters: {'num_leaves': 200}. Best is trial 11 with value: 0.8200100002434364.\u001b[0m\n",
      "num_leaves, val_score: 0.820010:  40%|####      | 8/20 [03:20<04:56, 24.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073013 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820010:  45%|####5     | 9/20 [03:43<04:25, 24.17s/it]\u001b[32m[I 2021-07-01 13:36:51,521]\u001b[0m Trial 15 finished with value: 0.8221557116884256 and parameters: {'num_leaves': 109}. Best is trial 11 with value: 0.8200100002434364.\u001b[0m\n",
      "num_leaves, val_score: 0.820010:  45%|####5     | 9/20 [03:43<04:25, 24.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072145 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.820010:  50%|#####     | 10/20 [04:12<04:17, 25.71s/it]\u001b[32m[I 2021-07-01 13:37:20,692]\u001b[0m Trial 16 finished with value: 0.822554467170886 and parameters: {'num_leaves': 253}. Best is trial 11 with value: 0.8200100002434364.\u001b[0m\n",
      "num_leaves, val_score: 0.820010:  50%|#####     | 10/20 [04:12<04:17, 25.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.067601 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819976:  55%|#####5    | 11/20 [04:38<03:51, 25.74s/it]\u001b[32m[I 2021-07-01 13:37:46,487]\u001b[0m Trial 17 finished with value: 0.8199760895820278 and parameters: {'num_leaves': 166}. Best is trial 17 with value: 0.8199760895820278.\u001b[0m\n",
      "num_leaves, val_score: 0.819976:  55%|#####5    | 11/20 [04:38<03:51, 25.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071727 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819976:  60%|######    | 12/20 [05:04<03:25, 25.72s/it]\u001b[32m[I 2021-07-01 13:38:12,164]\u001b[0m Trial 18 finished with value: 0.820890636093535 and parameters: {'num_leaves': 175}. Best is trial 17 with value: 0.8199760895820278.\u001b[0m\n",
      "num_leaves, val_score: 0.819976:  60%|######    | 12/20 [05:04<03:25, 25.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070214 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819976:  65%|######5   | 13/20 [05:29<02:58, 25.50s/it]\u001b[32m[I 2021-07-01 13:38:37,157]\u001b[0m Trial 19 finished with value: 0.8206912891827693 and parameters: {'num_leaves': 153}. Best is trial 17 with value: 0.8199760895820278.\u001b[0m\n",
      "num_leaves, val_score: 0.819976:  65%|######5   | 13/20 [05:29<02:58, 25.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070786 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819976:  70%|#######   | 14/20 [05:53<02:31, 25.19s/it]\u001b[32m[I 2021-07-01 13:39:01,623]\u001b[0m Trial 20 finished with value: 0.8201594633267121 and parameters: {'num_leaves': 147}. Best is trial 17 with value: 0.8199760895820278.\u001b[0m\n",
      "num_leaves, val_score: 0.819976:  70%|#######   | 14/20 [05:53<02:31, 25.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.077774 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819976:  75%|#######5  | 15/20 [06:21<02:10, 26.02s/it]\u001b[32m[I 2021-07-01 13:39:29,584]\u001b[0m Trial 21 finished with value: 0.8213976108157465 and parameters: {'num_leaves': 192}. Best is trial 17 with value: 0.8199760895820278.\u001b[0m\n",
      "num_leaves, val_score: 0.819976:  75%|#######5  | 15/20 [06:21<02:10, 26.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079896 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819064:  80%|########  | 16/20 [06:53<01:51, 27.75s/it]\u001b[32m[I 2021-07-01 13:40:01,346]\u001b[0m Trial 22 finished with value: 0.819063565044368 and parameters: {'num_leaves': 227}. Best is trial 22 with value: 0.819063565044368.\u001b[0m\n",
      "num_leaves, val_score: 0.819064:  80%|########  | 16/20 [06:53<01:51, 27.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074372 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819064:  85%|########5 | 17/20 [07:24<01:25, 28.62s/it]\u001b[32m[I 2021-07-01 13:40:31,988]\u001b[0m Trial 23 finished with value: 0.8209121798105943 and parameters: {'num_leaves': 232}. Best is trial 22 with value: 0.819063565044368.\u001b[0m\n",
      "num_leaves, val_score: 0.819064:  85%|########5 | 17/20 [07:24<01:25, 28.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819064:  90%|######### | 18/20 [07:49<00:55, 27.57s/it]\u001b[32m[I 2021-07-01 13:40:57,115]\u001b[0m Trial 24 finished with value: 0.8209880472605453 and parameters: {'num_leaves': 160}. Best is trial 22 with value: 0.819063565044368.\u001b[0m\n",
      "num_leaves, val_score: 0.819064:  90%|######### | 18/20 [07:49<00:55, 27.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071599 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819064:  95%|#########5| 19/20 [08:13<00:26, 26.45s/it]\u001b[32m[I 2021-07-01 13:41:20,943]\u001b[0m Trial 25 finished with value: 0.820874225139093 and parameters: {'num_leaves': 122}. Best is trial 22 with value: 0.819063565044368.\u001b[0m\n",
      "num_leaves, val_score: 0.819064:  95%|#########5| 19/20 [08:13<00:26, 26.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078261 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "num_leaves, val_score: 0.819064: 100%|##########| 20/20 [08:32<00:00, 24.44s/it]\u001b[32m[I 2021-07-01 13:41:40,701]\u001b[0m Trial 26 finished with value: 0.8326906993254494 and parameters: {'num_leaves': 14}. Best is trial 22 with value: 0.819063565044368.\u001b[0m\n",
      "num_leaves, val_score: 0.819064: 100%|##########| 20/20 [08:32<00:00, 25.65s/it]\n",
      "bagging, val_score: 0.819064:   0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071698 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  10%|#         | 1/10 [00:28<04:16, 28.49s/it]\u001b[32m[I 2021-07-01 13:42:09,201]\u001b[0m Trial 27 finished with value: 0.8212361839930951 and parameters: {'bagging_fraction': 0.6780724731766345, 'bagging_freq': 7}. Best is trial 27 with value: 0.8212361839930951.\u001b[0m\n",
      "bagging, val_score: 0.819064:  10%|#         | 1/10 [00:28<04:16, 28.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069539 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  20%|##        | 2/10 [00:52<03:26, 25.79s/it]\u001b[32m[I 2021-07-01 13:42:33,099]\u001b[0m Trial 28 finished with value: 0.8240409035624507 and parameters: {'bagging_fraction': 0.5162343252344551, 'bagging_freq': 4}. Best is trial 27 with value: 0.8212361839930951.\u001b[0m\n",
      "bagging, val_score: 0.819064:  20%|##        | 2/10 [00:52<03:26, 25.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073154 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  30%|###       | 3/10 [01:31<03:42, 31.80s/it]\u001b[32m[I 2021-07-01 13:43:12,052]\u001b[0m Trial 29 finished with value: 0.8211681820023855 and parameters: {'bagging_fraction': 0.808169501779253, 'bagging_freq': 2}. Best is trial 29 with value: 0.8211681820023855.\u001b[0m\n",
      "bagging, val_score: 0.819064:  30%|###       | 3/10 [01:31<03:42, 31.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074450 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  40%|####      | 4/10 [01:56<02:54, 29.13s/it]\u001b[32m[I 2021-07-01 13:43:37,096]\u001b[0m Trial 30 finished with value: 0.8225687731423604 and parameters: {'bagging_fraction': 0.5981694670925423, 'bagging_freq': 7}. Best is trial 29 with value: 0.8211681820023855.\u001b[0m\n",
      "bagging, val_score: 0.819064:  40%|####      | 4/10 [01:56<02:54, 29.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070030 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  50%|#####     | 5/10 [02:25<02:25, 29.20s/it]\u001b[32m[I 2021-07-01 13:44:06,399]\u001b[0m Trial 31 finished with value: 0.8213982304023653 and parameters: {'bagging_fraction': 0.7023324666385827, 'bagging_freq': 7}. Best is trial 29 with value: 0.8211681820023855.\u001b[0m\n",
      "bagging, val_score: 0.819064:  50%|#####     | 5/10 [02:25<02:25, 29.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070529 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  60%|######    | 6/10 [03:01<02:06, 31.52s/it]\u001b[32m[I 2021-07-01 13:44:42,430]\u001b[0m Trial 32 finished with value: 0.8210602953672592 and parameters: {'bagging_fraction': 0.9825165684400282, 'bagging_freq': 7}. Best is trial 32 with value: 0.8210602953672592.\u001b[0m\n",
      "bagging, val_score: 0.819064:  60%|######    | 6/10 [03:01<02:06, 31.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071105 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  70%|#######   | 7/10 [03:26<01:28, 29.43s/it]\u001b[32m[I 2021-07-01 13:45:07,559]\u001b[0m Trial 33 finished with value: 0.8222099257424154 and parameters: {'bagging_fraction': 0.5367372536896495, 'bagging_freq': 5}. Best is trial 32 with value: 0.8210602953672592.\u001b[0m\n",
      "bagging, val_score: 0.819064:  70%|#######   | 7/10 [03:26<01:28, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071328 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  80%|########  | 8/10 [03:48<00:53, 26.87s/it]\u001b[32m[I 2021-07-01 13:45:28,960]\u001b[0m Trial 34 finished with value: 0.8230488777292368 and parameters: {'bagging_fraction': 0.48055160451668205, 'bagging_freq': 5}. Best is trial 32 with value: 0.8210602953672592.\u001b[0m\n",
      "bagging, val_score: 0.819064:  80%|########  | 8/10 [03:48<00:53, 26.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071983 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064:  90%|######### | 9/10 [04:21<00:28, 28.85s/it]\u001b[32m[I 2021-07-01 13:46:02,166]\u001b[0m Trial 35 finished with value: 0.8218324788363985 and parameters: {'bagging_fraction': 0.9056249891810431, 'bagging_freq': 6}. Best is trial 32 with value: 0.8210602953672592.\u001b[0m\n",
      "bagging, val_score: 0.819064:  90%|######### | 9/10 [04:21<00:28, 28.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076968 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "bagging, val_score: 0.819064: 100%|##########| 10/10 [04:48<00:00, 28.38s/it]\u001b[32m[I 2021-07-01 13:46:29,500]\u001b[0m Trial 36 finished with value: 0.8221524571870338 and parameters: {'bagging_fraction': 0.7072414109295165, 'bagging_freq': 5}. Best is trial 32 with value: 0.8210602953672592.\u001b[0m\n",
      "bagging, val_score: 0.819064: 100%|##########| 10/10 [04:48<00:00, 28.88s/it]\n",
      "feature_fraction_stage2, val_score: 0.819064:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072700 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.819056:  33%|###3      | 1/3 [00:34<01:08, 34.12s/it]\u001b[32m[I 2021-07-01 13:47:03,625]\u001b[0m Trial 37 finished with value: 0.8190556125152745 and parameters: {'feature_fraction': 0.48000000000000004}. Best is trial 37 with value: 0.8190556125152745.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.819056:  33%|###3      | 1/3 [00:34<01:08, 34.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070999 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.819056:  67%|######6   | 2/3 [01:05<00:32, 32.40s/it]\u001b[32m[I 2021-07-01 13:47:34,815]\u001b[0m Trial 38 finished with value: 0.8216490272751789 and parameters: {'feature_fraction': 0.41600000000000004}. Best is trial 37 with value: 0.8190556125152745.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.819056:  67%|######6   | 2/3 [01:05<00:32, 32.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072254 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "feature_fraction_stage2, val_score: 0.819056: 100%|##########| 3/3 [01:34<00:00, 30.91s/it]\u001b[32m[I 2021-07-01 13:48:03,953]\u001b[0m Trial 39 finished with value: 0.8234859085733076 and parameters: {'feature_fraction': 0.44800000000000006}. Best is trial 37 with value: 0.8190556125152745.\u001b[0m\n",
      "feature_fraction_stage2, val_score: 0.819056: 100%|##########| 3/3 [01:34<00:00, 31.48s/it]\n",
      "regularization_factors, val_score: 0.819056:   0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071006 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819056:   5%|5         | 1/20 [00:34<10:55, 34.50s/it]\u001b[32m[I 2021-07-01 13:48:38,459]\u001b[0m Trial 40 finished with value: 0.8194717959974063 and parameters: {'lambda_l1': 8.629473924881948e-05, 'lambda_l2': 1.489265972097687e-07}. Best is trial 40 with value: 0.8194717959974063.\u001b[0m\n",
      "regularization_factors, val_score: 0.819056:   5%|5         | 1/20 [00:34<10:55, 34.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070481 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  10%|#         | 2/20 [01:09<10:21, 34.55s/it]\u001b[32m[I 2021-07-01 13:49:13,045]\u001b[0m Trial 41 finished with value: 0.8190310667487753 and parameters: {'lambda_l1': 3.7100699008253825e-07, 'lambda_l2': 2.374061535888586e-07}. Best is trial 41 with value: 0.8190310667487753.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  10%|#         | 2/20 [01:09<10:21, 34.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.076901 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  15%|#5        | 3/20 [01:43<09:46, 34.48s/it]\u001b[32m[I 2021-07-01 13:49:47,433]\u001b[0m Trial 42 finished with value: 0.819445712418473 and parameters: {'lambda_l1': 4.961361659522586e-06, 'lambda_l2': 0.0017208522717947765}. Best is trial 41 with value: 0.8190310667487753.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  15%|#5        | 3/20 [01:43<09:46, 34.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072956 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  20%|##        | 4/20 [02:18<09:15, 34.70s/it]\u001b[32m[I 2021-07-01 13:50:22,463]\u001b[0m Trial 43 finished with value: 0.8190324390090823 and parameters: {'lambda_l1': 5.060738845616527e-06, 'lambda_l2': 9.11165022696235e-07}. Best is trial 41 with value: 0.8190310667487753.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  20%|##        | 4/20 [02:18<09:15, 34.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.074416 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  25%|##5       | 5/20 [02:53<08:41, 34.75s/it]\u001b[32m[I 2021-07-01 13:50:57,296]\u001b[0m Trial 44 finished with value: 0.8190308692581827 and parameters: {'lambda_l1': 1.6075624265646878e-06, 'lambda_l2': 3.753863207154084e-08}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  25%|##5       | 5/20 [02:53<08:41, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071613 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  30%|###       | 6/20 [03:28<08:06, 34.76s/it]\u001b[32m[I 2021-07-01 13:51:32,084]\u001b[0m Trial 45 finished with value: 0.8190374763124968 and parameters: {'lambda_l1': 4.8555953756719245e-06, 'lambda_l2': 1.4609378201772397e-07}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  30%|###       | 6/20 [03:28<08:06, 34.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072041 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  35%|###5      | 7/20 [04:01<07:26, 34.32s/it]\u001b[32m[I 2021-07-01 13:52:05,505]\u001b[0m Trial 46 finished with value: 0.8213807796128707 and parameters: {'lambda_l1': 1.0216302954893506e-06, 'lambda_l2': 0.002618666403678978}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  35%|###5      | 7/20 [04:01<07:26, 34.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.080842 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  40%|####      | 8/20 [04:34<06:48, 34.00s/it]\u001b[32m[I 2021-07-01 13:52:38,830]\u001b[0m Trial 47 finished with value: 0.8198853008559291 and parameters: {'lambda_l1': 0.3038736287759215, 'lambda_l2': 7.648999679374733e-06}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  40%|####      | 8/20 [04:34<06:48, 34.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070846 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  45%|####5     | 9/20 [05:09<06:16, 34.19s/it]\u001b[32m[I 2021-07-01 13:53:13,428]\u001b[0m Trial 48 finished with value: 0.8190571384448602 and parameters: {'lambda_l1': 7.300899897388483e-06, 'lambda_l2': 1.4707028586142285e-07}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  45%|####5     | 9/20 [05:09<06:16, 34.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.079681 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  50%|#####     | 10/20 [05:43<05:40, 34.05s/it]\u001b[32m[I 2021-07-01 13:53:47,154]\u001b[0m Trial 49 finished with value: 0.8203385874703946 and parameters: {'lambda_l1': 5.562667974618576e-05, 'lambda_l2': 7.003781289653303}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  50%|#####     | 10/20 [05:43<05:40, 34.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072410 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  55%|#####5    | 11/20 [06:13<04:57, 33.00s/it]\u001b[32m[I 2021-07-01 13:54:17,797]\u001b[0m Trial 50 finished with value: 0.8213891591214004 and parameters: {'lambda_l1': 1.257276238426162e-08, 'lambda_l2': 1.9215973289985162}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  55%|#####5    | 11/20 [06:13<04:57, 33.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.068790 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  60%|######    | 12/20 [06:48<04:28, 33.59s/it]\u001b[32m[I 2021-07-01 13:54:52,711]\u001b[0m Trial 51 finished with value: 0.8190318525907664 and parameters: {'lambda_l1': 1.5094993883906808e-08, 'lambda_l2': 1.3079200343650199e-08}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  60%|######    | 12/20 [06:48<04:28, 33.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070233 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  65%|######5   | 13/20 [07:17<03:45, 32.22s/it]\u001b[32m[I 2021-07-01 13:55:21,788]\u001b[0m Trial 52 finished with value: 0.8215895571345487 and parameters: {'lambda_l1': 7.840542570667646e-08, 'lambda_l2': 6.257996285528987e-05}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  65%|######5   | 13/20 [07:17<03:45, 32.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070761 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  70%|#######   | 14/20 [07:50<03:14, 32.48s/it]\u001b[32m[I 2021-07-01 13:55:54,868]\u001b[0m Trial 53 finished with value: 0.8204046083374092 and parameters: {'lambda_l1': 0.004316450188190123, 'lambda_l2': 1.1203232887586629e-08}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  70%|#######   | 14/20 [07:50<03:14, 32.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072428 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819031:  75%|#######5  | 15/20 [08:21<02:39, 31.98s/it]\u001b[32m[I 2021-07-01 13:56:25,684]\u001b[0m Trial 54 finished with value: 0.8216907444251543 and parameters: {'lambda_l1': 0.003594087384035224, 'lambda_l2': 0.08032003567807668}. Best is trial 44 with value: 0.8190308692581827.\u001b[0m\n",
      "regularization_factors, val_score: 0.819031:  75%|#######5  | 15/20 [08:21<02:39, 31.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071456 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819023:  80%|########  | 16/20 [08:56<02:11, 32.86s/it]\u001b[32m[I 2021-07-01 13:57:00,606]\u001b[0m Trial 55 finished with value: 0.8190227321727632 and parameters: {'lambda_l1': 1.3522116780407148e-07, 'lambda_l2': 6.7666887821856935e-06}. Best is trial 55 with value: 0.8190227321727632.\u001b[0m\n",
      "regularization_factors, val_score: 0.819023:  80%|########  | 16/20 [08:56<02:11, 32.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078733 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819023:  85%|########5 | 17/20 [09:31<01:40, 33.39s/it]\u001b[32m[I 2021-07-01 13:57:35,224]\u001b[0m Trial 56 finished with value: 0.8190280084556057 and parameters: {'lambda_l1': 1.1457334070680105e-07, 'lambda_l2': 1.2586417250115777e-05}. Best is trial 55 with value: 0.8190227321727632.\u001b[0m\n",
      "regularization_factors, val_score: 0.819023:  85%|########5 | 17/20 [09:31<01:40, 33.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069462 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819023:  90%|######### | 18/20 [10:03<01:06, 33.06s/it]\u001b[32m[I 2021-07-01 13:58:07,514]\u001b[0m Trial 57 finished with value: 0.8218231797789527 and parameters: {'lambda_l1': 7.677347942944716, 'lambda_l2': 1.84373091713061e-05}. Best is trial 55 with value: 0.8190227321727632.\u001b[0m\n",
      "regularization_factors, val_score: 0.819023:  90%|######### | 18/20 [10:03<01:06, 33.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.072832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819023:  95%|#########5| 19/20 [10:36<00:33, 33.14s/it]\u001b[32m[I 2021-07-01 13:58:40,832]\u001b[0m Trial 58 finished with value: 0.8206913202605028 and parameters: {'lambda_l1': 8.108226005382036e-08, 'lambda_l2': 0.00020569481712420863}. Best is trial 55 with value: 0.8190227321727632.\u001b[0m\n",
      "regularization_factors, val_score: 0.819023:  95%|#########5| 19/20 [10:36<00:33, 33.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075336 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "regularization_factors, val_score: 0.819023: 100%|##########| 20/20 [11:11<00:00, 33.69s/it]\u001b[32m[I 2021-07-01 13:59:15,817]\u001b[0m Trial 59 finished with value: 0.8190328332542695 and parameters: {'lambda_l1': 1.1735525342541399e-07, 'lambda_l2': 3.1884735334445535e-06}. Best is trial 55 with value: 0.8190227321727632.\u001b[0m\n",
      "regularization_factors, val_score: 0.819023: 100%|##########| 20/20 [11:11<00:00, 33.59s/it]\n",
      "min_data_in_leaf, val_score: 0.819023:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073034 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.819023:  20%|##        | 1/5 [00:31<02:06, 31.59s/it]\u001b[32m[I 2021-07-01 13:59:47,408]\u001b[0m Trial 60 finished with value: 0.8220181044350098 and parameters: {'min_child_samples': 50}. Best is trial 60 with value: 0.8220181044350098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.819023:  20%|##        | 1/5 [00:31<02:06, 31.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.073590 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.819023:  40%|####      | 2/5 [01:01<01:31, 30.56s/it]\u001b[32m[I 2021-07-01 14:00:17,255]\u001b[0m Trial 61 finished with value: 0.8241211872098564 and parameters: {'min_child_samples': 25}. Best is trial 60 with value: 0.8220181044350098.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.819023:  40%|####      | 2/5 [01:01<01:31, 30.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071044 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817006:  60%|######    | 3/5 [01:37<01:06, 33.12s/it]\u001b[32m[I 2021-07-01 14:00:53,415]\u001b[0m Trial 62 finished with value: 0.8170056455037346 and parameters: {'min_child_samples': 100}. Best is trial 62 with value: 0.8170056455037346.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817006:  60%|######    | 3/5 [01:37<01:06, 33.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.070405 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817006:  80%|########  | 4/5 [02:06<00:31, 31.51s/it]\u001b[32m[I 2021-07-01 14:01:22,451]\u001b[0m Trial 63 finished with value: 0.8241189964083229 and parameters: {'min_child_samples': 10}. Best is trial 62 with value: 0.8170056455037346.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817006:  80%|########  | 4/5 [02:06<00:31, 31.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069455 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 10899\n",
      "[LightGBM] [Info] Number of data points in the train set: 1172709, number of used features: 121\n",
      "[LightGBM] [Info] Start training from score 0.699385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "min_data_in_leaf, val_score: 0.817006: 100%|##########| 5/5 [02:35<00:00, 30.71s/it]\u001b[32m[I 2021-07-01 14:01:51,744]\u001b[0m Trial 64 finished with value: 0.8296990566732315 and parameters: {'min_child_samples': 5}. Best is trial 62 with value: 0.8170056455037346.\u001b[0m\n",
      "min_data_in_leaf, val_score: 0.817006: 100%|##########| 5/5 [02:35<00:00, 31.19s/it]\n"
     ]
    }
   ],
   "source": [
    "tr_idx = tr_idxs[idx]\n",
    "val_idx = val_idxs[idx]\n",
    "\n",
    "x_train = train_X.loc[tr_idx].reset_index(drop=True)\n",
    "y_train = train_y.loc[tr_idx].reset_index(drop=True)\n",
    "x_valid = train_X.loc[val_idx].reset_index(drop=True)\n",
    "y_valid = train_y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "\n",
    "trains = lgbm.Dataset(x_train[feature_cols4], y_train['target1'])\n",
    "valids = lgbm.Dataset(x_valid[feature_cols4], y_valid['target1'])\n",
    "\n",
    "\n",
    "model4 = lgbm.train(params, trains, valid_sets=[trains, valids],\n",
    "                    verbose_eval=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0909e986",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22e7a57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "339cafe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression',\n",
       " 'metric': 'l1',\n",
       " 'learning_rate': 0.01,\n",
       " 'random_seed': 777,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 7.635951631226586e-07,\n",
       " 'lambda_l2': 1.3545756002061381e-08,\n",
       " 'num_leaves': 64,\n",
       " 'feature_fraction': 0.516,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 100,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3547ebc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression',\n",
       " 'metric': 'l1',\n",
       " 'learning_rate': 0.01,\n",
       " 'random_seed': 777,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 9.507051735075546e-06,\n",
       " 'lambda_l2': 1.7992356814795836,\n",
       " 'num_leaves': 89,\n",
       " 'feature_fraction': 0.516,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 100,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99bde9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression',\n",
       " 'metric': 'l1',\n",
       " 'learning_rate': 0.01,\n",
       " 'random_seed': 777,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 8.481151951951655e-08,\n",
       " 'lambda_l2': 1.1181371584967872e-08,\n",
       " 'num_leaves': 152,\n",
       " 'feature_fraction': 0.5,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 20,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "75748c69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'regression',\n",
       " 'metric': 'l1',\n",
       " 'learning_rate': 0.01,\n",
       " 'random_seed': 777,\n",
       " 'feature_pre_filter': False,\n",
       " 'lambda_l1': 1.3522116780407148e-07,\n",
       " 'lambda_l2': 6.7666887821856935e-06,\n",
       " 'num_leaves': 227,\n",
       " 'feature_fraction': 0.48000000000000004,\n",
       " 'bagging_fraction': 1.0,\n",
       " 'bagging_freq': 0,\n",
       " 'min_child_samples': 100,\n",
       " 'num_iterations': 1000,\n",
       " 'early_stopping_round': 10}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7a411ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6254922 , 0.6254922 , 0.6254922 , ..., 0.136638  , 0.35353022,\n",
       "       0.1115049 ])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.predict(x_valid[feature_cols1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febc178",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccfd0540",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7905fa2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f1a65a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_indexes = []\n",
    "for i in range(NFOLDS):\n",
    "    oof_indexes.extend(val_idxs[i][val_idxs[i]==True].index.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4ae4bec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 1.0068916599762827\n"
     ]
    }
   ],
   "source": [
    "y_valids[val_idx, :]\n",
    "mae = mean_absolute_error(y_valids[oof_indexes, :], oof[oof_indexes, :])\n",
    "print(\"mae:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "641d743e",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df = train[targets_cols]\n",
    "oof_df.iloc[oof_indexes, 1:5] = oof[oof_indexes, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "12c8b943",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.iloc[oof_indexes].to_csv(OUTPUT_DIR / f'oof{EXP_NUM}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5df036f",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_df.to_csv(OUTPUT_DIR / f'oof{EXP_NUM}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e8e92152",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = np.array([model1s, model2s, model3s, model4s])\n",
    "with open(OUTPUT_DIR / f\"models{EXP_NUM}.pickle\", mode=\"wb\") as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3897bcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = [0.05, 0.1, 0.15, 0.2, 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "89729a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.9243639988545487\n",
      "mae: 0.9280874388198368\n",
      "mae: 0.9461138707647198\n",
      "mae: 0.9205080119615825\n",
      "mae: 0.9206798501283971\n"
     ]
    }
   ],
   "source": [
    "pred1s = 0\n",
    "pred2s = 0\n",
    "pred3s = 0\n",
    "pred4s = 0\n",
    "for i in range(NFOLDS):\n",
    "    pred1 = models[0][i].predict(x_valid[feature_cols1])\n",
    "    pred2 = models[1][i].predict(x_valid[feature_cols2])\n",
    "    pred3 = models[2][i].predict(x_valid[feature_cols3])\n",
    "    pred4 = models[3][i].predict(x_valid[feature_cols4])\n",
    "    oof_valid_april = np.clip(np.array([pred1, pred2, pred3, pred4]).T, 0, 100)\n",
    "    mae = mean_absolute_error(y_valid, oof_valid_april)\n",
    "    print(\"mae:\", mae)\n",
    "    pred1s += pred1 * weights[i]\n",
    "    pred2s += pred2 * weights[i]\n",
    "    pred3s += pred3 * weights[i]\n",
    "    pred4s += pred4 * weights[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c1bab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_valid_april = np.clip(np.array([pred1s, pred2s, pred3s, pred4s]).T, 0, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d26192bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof_valid_april = np.where(oof_valid_april < 0.1, 0, oof_valid_april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "46007fb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.9177646897044414\n"
     ]
    }
   ],
   "source": [
    "mae = mean_absolute_error(y_valid, oof_valid_april)\n",
    "print(\"mae:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ee6c850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9163249956481581"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.9165205542502022\n",
    "0.9163249956481581"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9561a135",
   "metadata": {},
   "source": [
    "## EDA pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "04ad3c48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(model1.feature_importances_, index=feature_cols1, columns=['importance'])\n",
    "importance = importance.sort_values('importance', ascending=False)\n",
    "importance.iloc[30:30].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61fea6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbm.plot_importance(model1, figsize=(12, 6), max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6900ffc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['daysSinceLastGame', 'target4_min', 'label_status', 'label_teamId',\n",
       "       'target4_median', 'target2_mean', 'target2_median', 'label_playerId',\n",
       "       'target2_min', 'target2_max', 'label_primaryPositionName',\n",
       "       'target2_std', 'target2_skew', 'tgt1_3_corr', 'tgt1_2_corr',\n",
       "       'tgt2_4_corr', 'target3_min', 'tgt1_4_corr', 'target4_std',\n",
       "       'target4_skew', 'target4_mean', 'totalBases', 'target1_min',\n",
       "       'target3_median', 'target4_max', 'plateAppearances', 'target1_mean',\n",
       "       'battingOrder', 'target1_std', 'tgt2_3_corr'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(model2.feature_importances_, index=feature_cols2, columns=['importance'])\n",
    "importance = importance.sort_values('importance', ascending=False)\n",
    "importance.iloc[:30].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "36c8ba8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbm.plot_importance(model2, figsize=(12, 6), max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a260195f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['daysSinceLastGame', 'label_playerId', 'label_teamId', 'tgt1_3_corr',\n",
       "       'target4_min', 'tgt3_4_corr', 'tgt1_2_corr', 'tgt2_4_corr',\n",
       "       'target4_mean', 'target2_min', 'target4_median', 'target1_skew',\n",
       "       'target1_mean', 'target2_mean', 'tgt2_3_corr', 'target2_skew',\n",
       "       'tgt1_4_corr', 'target2_median', 'target4_skew', 'target2_std',\n",
       "       'label_primaryPositionName', 'target3_skew', 'target3_mean',\n",
       "       'target2_max', 'target3_median', 'target4_std', 'target3_std',\n",
       "       'label_status', 'target4_kurt', 'target1_median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(model3.feature_importances_, index=feature_cols3, columns=['importance'])\n",
    "importance = importance.sort_values('importance', ascending=False)\n",
    "importance.iloc[:30].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5008d08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbm.plot_importance(model3, figsize=(12, 6), max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6d83e56c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['annual_day', 'daysSinceLastGame', 'week_day', 'target4_min',\n",
       "       'label_teamId', 'month', 'target4_mean', 'target4_median',\n",
       "       'label_playerId', 'tgt1_2_corr', 'mlbDebutYear', 'tgt1_3_corr',\n",
       "       'tgt2_3_corr', 'target2_median', 'label_birthCity', 'tgt3_4_corr',\n",
       "       'weight', 'tgt1_4_corr', 'tgt2_4_corr', 'DOY', 'target4_skew',\n",
       "       'target2_skew', 'target2_min', 'target3_skew', 'target2_mean',\n",
       "       'target4_std', 'target4_kurt', 'target2_std', 'target1_skew',\n",
       "       'target2_kurt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importance = pd.DataFrame(model4.feature_importances_, index=feature_cols4, columns=['importance'])\n",
    "importance = importance.sort_values('importance', ascending=False)\n",
    "importance.iloc[:30].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1496fd72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Feature importance'}, xlabel='Feature importance', ylabel='Features'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lgbm.plot_importance(model4, figsize=(12, 6), max_num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7ce8820",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "506c2dec",
   "metadata": {},
   "source": [
    "## テストで取ってこれる一行はこんな感じ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d105cea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_sample_submission = pd.read_csv(MAIN_DATA_DIR / \"example_sample_submission.csv\")\n",
    "example_test = pd.read_csv(MAIN_DATA_DIR / \"example_test.csv\")\n",
    "test_df = example_test.set_index('date').iloc[:1]\n",
    "sample_prediction_df = example_sample_submission[example_sample_submission['date']==test_df.index[0]].set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "349bbbf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "players_cols = ['playerId', 'primaryPositionName', 'birthCity', 'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight']\n",
    "rosters_cols = ['playerId', 'teamId', 'status']\n",
    "scores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "       'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "       'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "       'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "       'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "       'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "       'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "       'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "       'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "       'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "       'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "       'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "       'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "       'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "       'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "       'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "       'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "       'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "       'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "       'assists', 'putOuts', 'errors', 'chances']\n",
    "\n",
    "null = np.nan\n",
    "true = True\n",
    "false = False\n",
    "\n",
    "# env = mlb.make_env() # initialize the environment\n",
    "# iter_test = env.iter_test() # iterator which loops over each date in test set\n",
    "\n",
    "# for (test_df, sample_prediction_df) in iter_test: # make predictions here\n",
    "    \n",
    "sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n",
    "\n",
    "# creat dataset\n",
    "sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n",
    "                                    .map(lambda x: int(x.split('_')[1]))\n",
    "# Dealing with missing values\n",
    "if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n",
    "    test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n",
    "else:\n",
    "    test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "    for col in rosters.columns:\n",
    "        if col == 'playerId': continue\n",
    "        test_rosters[col] = np.nan\n",
    "\n",
    "if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n",
    "    test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n",
    "else:\n",
    "    test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "    for col in scores.columns:\n",
    "        if col == 'playerId': continue\n",
    "        test_scores[col] = np.nan\n",
    "test_scores = test_scores.groupby('playerId').sum().reset_index()\n",
    "test = sample_prediction_df[['playerId']].copy()\n",
    "test = test.merge(players[players_cols], on='playerId', how='left')\n",
    "test = test.merge(test_rosters[rosters_cols], on='playerId', how='left')\n",
    "test = test.merge(test_scores[scores_cols], on='playerId', how='left')\n",
    "test = test.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n",
    "\n",
    "\n",
    "test['label_playerId'] = test['playerId'].map(player2num)\n",
    "test['label_primaryPositionName'] = test['primaryPositionName'].map(position2num)\n",
    "test['label_teamId'] = test['teamId'].map(teamid2num)\n",
    "test['label_status'] = test['status'].map(status2num)\n",
    "test['label_birthCity'] = test['birthCity'].map(birthCityn2num)\n",
    "\n",
    "date_ = pd.to_datetime(test_df.index[0], format=\"%Y%m%d\")\n",
    "test['annual_day'] = (date_ - pd.to_datetime(date_.year, format=\"%Y\")) /  timedelta(days=1)\n",
    "test['week_day'] = date_.weekday()\n",
    "test['month'] = date_.month\n",
    "\n",
    "\n",
    "test_X = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "75ed75c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X['gameday'] = ~test_X['battingOrder'].isna()*1\n",
    "test_X['date'] = test_df.index[0]\n",
    "test_X = pd.merge(test_X, train_last_game, on=['playerId'], how='left')\n",
    "test_X['daysSinceLastGame'] = (pd.to_datetime(test_X['date'], format=\"%Y%m%d\") - pd.to_datetime(test_X['lastdate'], format=\"%Y%m%d\")).dt.days\n",
    "test_X.loc[test_X['gameday']==1,'daysSinceLastGame']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7cdd5ef5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerId</th>\n",
       "      <th>lastdate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112526</td>\n",
       "      <td>20180922.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>134181</td>\n",
       "      <td>20180930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279571</td>\n",
       "      <td>20180930.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>282332</td>\n",
       "      <td>20191017.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>400085</td>\n",
       "      <td>20190321.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2056</th>\n",
       "      <td>681911</td>\n",
       "      <td>20210426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2057</th>\n",
       "      <td>683232</td>\n",
       "      <td>20210426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2058</th>\n",
       "      <td>683734</td>\n",
       "      <td>20210426.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>685493</td>\n",
       "      <td>20200927.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>685503</td>\n",
       "      <td>20210426.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2061 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      playerId    lastdate\n",
       "0       112526  20180922.0\n",
       "1       134181  20180930.0\n",
       "2       279571  20180930.0\n",
       "3       282332  20191017.0\n",
       "4       400085  20190321.0\n",
       "...        ...         ...\n",
       "2056    681911  20210426.0\n",
       "2057    683232  20210426.0\n",
       "2058    683734  20210426.0\n",
       "2059    685493  20200927.0\n",
       "2060    685503  20210426.0\n",
       "\n",
       "[2061 rows x 2 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_last_game = pd.merge(train_last_game, test_X[test_X['gameday']==1][['playerId','date']], on=['playerId'], how='left')\n",
    "train_last_game['lastdate'].update(train_last_game['date'])\n",
    "train_last_game = train_last_game[['playerId', 'lastdate']]\n",
    "train_last_game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cdc065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79b6360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict\n",
    "pred1 = model1.predict(test_X[feature_cols1])\n",
    "pred2 = model2.predict(test_X[feature_cols2])\n",
    "pred3 = model3.predict(test_X[feature_cols3])\n",
    "pred4 = model4.predict(test_X[feature_cols4])\n",
    "\n",
    "# merge submission\n",
    "sample_prediction_df['target1'] = np.clip(pred1, 0, 100)\n",
    "sample_prediction_df['target2'] = np.clip(pred2, 0, 100)\n",
    "sample_prediction_df['target3'] = np.clip(pred3, 0, 100)\n",
    "sample_prediction_df['target4'] = np.clip(pred4, 0, 100)\n",
    "sample_prediction_df = sample_prediction_df.fillna(0.)\n",
    "\n",
    "del sample_prediction_df['playerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1a55d382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date_playerId</th>\n",
       "      <th>target1</th>\n",
       "      <th>target2</th>\n",
       "      <th>target3</th>\n",
       "      <th>target4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210427_656669</td>\n",
       "      <td>4.523566</td>\n",
       "      <td>7.302453</td>\n",
       "      <td>2.559227e-01</td>\n",
       "      <td>2.723813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210427_543475</td>\n",
       "      <td>0.147992</td>\n",
       "      <td>3.124557</td>\n",
       "      <td>2.008687e-01</td>\n",
       "      <td>1.193542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210427_592866</td>\n",
       "      <td>0.006262</td>\n",
       "      <td>1.240768</td>\n",
       "      <td>1.289277e-02</td>\n",
       "      <td>1.045266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210427_452678</td>\n",
       "      <td>0.028216</td>\n",
       "      <td>3.628774</td>\n",
       "      <td>4.949686e-02</td>\n",
       "      <td>1.776316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210427_570257</td>\n",
       "      <td>0.008472</td>\n",
       "      <td>1.085709</td>\n",
       "      <td>1.132856e-02</td>\n",
       "      <td>0.437531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182</th>\n",
       "      <td>20210427_593590</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.013661</td>\n",
       "      <td>1.073450e-18</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183</th>\n",
       "      <td>20210427_642180</td>\n",
       "      <td>0.002000</td>\n",
       "      <td>1.000161</td>\n",
       "      <td>3.896596e-03</td>\n",
       "      <td>0.397934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>20210427_663399</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>0.336076</td>\n",
       "      <td>1.736459e-03</td>\n",
       "      <td>0.087545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185</th>\n",
       "      <td>20210427_664199</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>0.919104</td>\n",
       "      <td>5.898664e-03</td>\n",
       "      <td>0.507688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186</th>\n",
       "      <td>20210427_595453</td>\n",
       "      <td>0.007222</td>\n",
       "      <td>1.106129</td>\n",
       "      <td>6.004617e-03</td>\n",
       "      <td>0.473643</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1187 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date_playerId   target1   target2       target3   target4\n",
       "0     20210427_656669  4.523566  7.302453  2.559227e-01  2.723813\n",
       "1     20210427_543475  0.147992  3.124557  2.008687e-01  1.193542\n",
       "2     20210427_592866  0.006262  1.240768  1.289277e-02  1.045266\n",
       "3     20210427_452678  0.028216  3.628774  4.949686e-02  1.776316\n",
       "4     20210427_570257  0.008472  1.085709  1.132856e-02  0.437531\n",
       "...               ...       ...       ...           ...       ...\n",
       "1182  20210427_593590  0.000010  0.013661  1.073450e-18  0.000000\n",
       "1183  20210427_642180  0.002000  1.000161  3.896596e-03  0.397934\n",
       "1184  20210427_663399  0.000242  0.336076  1.736459e-03  0.087545\n",
       "1185  20210427_664199  0.000847  0.919104  5.898664e-03  0.507688\n",
       "1186  20210427_595453  0.007222  1.106129  6.004617e-03  0.473643\n",
       "\n",
       "[1187 rows x 5 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_prediction_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34922f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
