{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db4ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "from statsmodels.tsa.deterministic import (CalendarFourier,\n",
    "                                           CalendarSeasonality,\n",
    "                                           CalendarTimeTrend,\n",
    "                                           DeterministicProcess)\n",
    "import optuna\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize()\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import ctypes as ct\n",
    "from datetime import timedelta\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import statistics as st\n",
    "import lightgbm as lgbm\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b9f1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('../../')\n",
    "import src.utils as utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fa42da",
   "metadata": {},
   "source": [
    "## Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d51583f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXP_NUM = 72\n",
    "NFOLDS = 5\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0671c098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def set_seed(seed: int = 42):\n",
    "#     random.seed(seed)\n",
    "#     np.random.seed(seed)\n",
    "#     os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "#     torch.manual_seed(seed)\n",
    "#     torch.cuda.manual_seed(seed)  # type: ignore\n",
    "#     torch.backends.cudnn.deterministic = True  # type: ignore\n",
    "#     torch.backends.cudnn.benchmark = False  # type: ignore\n",
    "# set_seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1ae3295",
   "metadata": {},
   "source": [
    "## Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af37f286",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/MLB-Player-Digital-Engagement-Forecasting/data/\")\n",
    "MAIN_DATA_DIR = DATA_DIR / 'mlb-player-digital-engagement-forecasting'\n",
    "TRAIN_DIR = MAIN_DATA_DIR / 'train'\n",
    "OUTPUT_DIR = Path('./output/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76c8fa43",
   "metadata": {},
   "outputs": [],
   "source": [
    "players = pd.read_csv(MAIN_DATA_DIR / 'players.csv')\n",
    "\n",
    "rosters = pd.read_csv(TRAIN_DIR / 'rosters_train.csv')\n",
    "targets = pd.read_csv(TRAIN_DIR / 'nextDayPlayerEngagement_train.csv')\n",
    "scores = pd.read_csv(TRAIN_DIR / 'playerBoxScores_train.csv')\n",
    "scores = scores.groupby(['playerId', 'date']).sum().reset_index()\n",
    "seasons = pd.read_csv(MAIN_DATA_DIR / 'seasons.csv')\n",
    "salaries = pd.read_csv(MAIN_DATA_DIR / 'mlbSalaries.csv')\n",
    "teams = pd.read_csv(MAIN_DATA_DIR / 'teams.csv')\n",
    "\n",
    "standings = pd.read_csv(TRAIN_DIR / 'standings_train.csv')\n",
    "playerTwitterFollowers = pd.read_csv(TRAIN_DIR / 'playerTwitterFollowers_train.csv')\n",
    "\n",
    "# events = pd.read_csv(TRAIN_DIR / 'events_train.csv')\n",
    "# events = events.groupby(['gameDate']).sum().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01c2c86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_elements_dict = {\"players\":players, \n",
    "                       \"rosters\":rosters, \n",
    "                       \"targets\":targets, \n",
    "                       \"scores\":scores, \n",
    "                       \"seasons\":seasons, \n",
    "                       \"teams\":teams, \n",
    "                       \"standings\":standings}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "faddb7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_team_name(name):\n",
    "    names = name.split('-')\n",
    "    result = ''\n",
    "    for n in names:\n",
    "        if n == 'st':\n",
    "            n = 'st.'\n",
    "        result += f' {n.capitalize()}'\n",
    "\n",
    "    return result[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a127fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_corr(df):\n",
    "    # 相関係数行列を作成\n",
    "    corr_mat = df.corr(method='pearson')\n",
    "\n",
    "    # 行（列）サイズを取得\n",
    "    n = corr_mat.shape[0]\n",
    "    corr_ary = []\n",
    "\n",
    "    for i in range(n):\n",
    "        for j in range(i):\n",
    "            if i == j:\n",
    "                continue\n",
    "            corr_ary.append(corr_mat.iloc[i,j])\n",
    "\n",
    "    return corr_ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99b5169c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_probs(pid,df,temp):\n",
    "    to_append=[pid,'','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','','']\n",
    "    targets=['target1','target2','target3','target4']\n",
    "    z=1\n",
    "    for target in targets:\n",
    "        target_prob = temp[target].tolist()\n",
    "        mean = np.mean(target_prob)\n",
    "        std = np.std(target_prob)\n",
    "        median = st.median(target_prob)\n",
    "        distribution = norm(mean, std)\n",
    "        min_weight = min(target_prob)\n",
    "        max_weight = max(target_prob)\n",
    "        values = list(np.linspace(min_weight, max_weight))\n",
    "        probabilities = [distribution.pdf(v) for v in values]\n",
    "        max_value = max(probabilities)\n",
    "        max_index = probabilities.index(max_value)\n",
    "        to_append[z]=mean\n",
    "        to_append[z+1]=median\n",
    "        to_append[z+2]=std\n",
    "        to_append[z+3]=min_weight\n",
    "        to_append[z+4]=max_weight\n",
    "        to_append[z+5]=temp[target].skew()\n",
    "        to_append[z+6]=temp[target].kurt()\n",
    "\n",
    "        z=z+7\n",
    "    corr_ = calc_corr(temp[['target1', 'target2', 'target3', 'target4']])\n",
    "    to_append[z:] = corr_  \n",
    "    df_length = len(df)\n",
    "    df.loc[df_length] = to_append\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a58b8397",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_consecutive_items_n_cols(df, col_name_list, output_col):\n",
    "    cum_sum_list = [\n",
    "        (df[col_name] != df[col_name].shift(1)).cumsum().tolist() for col_name in col_name_list\n",
    "    ]\n",
    "    df[output_col] = df.groupby(\n",
    "        [\"_\".join(map(str, x)) for x in zip(*cum_sum_list)]\n",
    "    ).cumcount() + 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec136a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_season(date_raw, season_start_end):\n",
    "    idxes = 0\n",
    "    for raw in season_start_end.iloc():\n",
    "        idx_ = ((date_raw >= raw.iloc[0]) & (date_raw <= raw.iloc[1])) * 1\n",
    "        idxes += idx_\n",
    "    return idxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5765cea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n",
    "#     oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n",
    "#     model = lgbm.LGBMRegressor(**params)\n",
    "#     model.fit(x_train, y_train, \n",
    "#         eval_set=[(x_valid, y_valid)],  \n",
    "#         early_stopping_rounds=verbose, \n",
    "#         verbose=verbose)\n",
    "#     oof_pred = model.predict(x_valid)\n",
    "#     oof_pred = np.clip(oof_pred, 0, 100)\n",
    "#     score = mean_absolute_error(oof_pred, y_valid)\n",
    "#     print('mae:', score)\n",
    "#     return oof_pred, model, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea3d73ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(x_train, y_train, x_valid, y_valid, verbose=100):\n",
    "    def opt(trial):\n",
    "        params = {\n",
    "                'random_state': SEED,\n",
    "                'objective':'mae',\n",
    "                'n_estimators': 10000,\n",
    "                'learning_rate': 0.1,\n",
    "                'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "                'min_child_weight': trial.suggest_int('min_child_weight', 1, 20),\n",
    "                'subsample': trial.suggest_discrete_uniform('subsample', 0.5, 0.9, 0.1),\n",
    "                'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.5, 0.9, 0.1),\n",
    "                'reg_lambda': trial.suggest_loguniform('reg_lambda', 1e-3, 1e3),\n",
    "                'reg_alpha': trial.suggest_loguniform('reg_alpha', 1e-3, 1e3),\n",
    "                'feature_fraction': trial.suggest_uniform('feature_fraction', 0.2, 1.0),\n",
    "                'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.2, 1.0),\n",
    "                'bagging_freq': trial.suggest_int('bagging_freq', 1, 20),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 10, 1000),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 100)\n",
    "        }\n",
    "\n",
    "        model_opt = lgbm.LGBMRegressor(**params)\n",
    "\n",
    "        model_opt.fit(x_train, y_train, \n",
    "            eval_set=[(x_train, y_train), (x_valid, y_valid)],  \n",
    "            early_stopping_rounds=verbose, \n",
    "            verbose=verbose)\n",
    "        oof_pred = model_opt.predict(x_valid)\n",
    "        oof_pred = np.clip(oof_pred, 0, 100)\n",
    "        score = mean_absolute_error(oof_pred, y_valid)\n",
    "        return -score\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37471f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_timeseries_fold(train):\n",
    "    \n",
    "    tr_idxs = []\n",
    "    val_idxs = []\n",
    "    \n",
    "    tr_idx = (train['date'].astype(int) < 20200801)\n",
    "    val_idx = (train['date'].astype(int) >= 20200801) & (train['date'].astype(int) < 20200901)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "\n",
    "    tr_idx = (train['date'].astype(int) < 20200901)\n",
    "    val_idx = (train['date'].astype(int) >= 20200901) & (train['date'].astype(int) < 20201001)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "\n",
    "    tr_idx = (train['date'].astype(int) < 20201001)\n",
    "    val_idx = (train['date'].astype(int) >= 20201001) & (train['date'].astype(int) < 20201028)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "\n",
    "    tr_idx = (train['date'].astype(int) < 20210228)\n",
    "    val_idx = (train['date'].astype(int) >= 20210228) & (train['date'].astype(int) < 20210401)\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "\n",
    "    tr_idx = (train['date'].astype(int) < 20210401)\n",
    "    val_idx = ~tr_idx\n",
    "    tr_idxs.append(tr_idx)\n",
    "    val_idxs.append(val_idx)\n",
    "    \n",
    "    return tr_idxs, val_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7592719",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rt4kaidoTrain:\n",
    "    def __init__(self, usetimelinefeature=False):\n",
    "        \n",
    "        self.usetimelinefeature = usetimelinefeature\n",
    "        self.targets_cols = ['playerId', 'target1', 'target2', 'target3', 'target4', 'date']\n",
    "        self.players_cols = ['playerId', 'primaryPositionName', 'birthCity', 'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight', 'playerForTestSetAndFuturePreds']\n",
    "        self.rosters_cols = ['playerId', 'teamId', 'status', 'date']\n",
    "        self.salaries_cols = ['teamId', 'salary', 'year']\n",
    "        self.standings_cols = ['teamId', 'wildCardRank', 'sportGamesBack', 'date']\n",
    "        self.transactions_cols = ['playerId', 'transaction_flag', 'date']\n",
    "        self.stat_cols = [\"playerId\", \"target1_mean\",\"target1_median\",\"target1_std\",\"target1_min\",\"target1_max\",\"target1_skew\",\"target1_kurt\",\n",
    "                        \"target2_mean\",\"target2_median\",\"target2_std\",\"target2_min\",\"target2_max\",\"target2_skew\",\"target2_kurt\",\n",
    "                        \"target3_mean\",\"target3_median\",\"target3_std\",\"target3_min\",\"target3_max\",\"target3_skew\",\"target3_kurt\",\n",
    "                        \"target4_mean\",\"target4_median\",\"target4_std\",\"target4_min\",\"target4_max\",\"target4_skew\",\"target4_kurt\",\n",
    "                        'tgt1_2_corr', 'tgt1_3_corr', 'tgt2_3_corr', 'tgt1_4_corr', 'tgt2_4_corr', 'tgt3_4_corr']\n",
    "\n",
    "        self.scores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances', 'date']\n",
    "\n",
    "        self.feature_cols1 = ['week_day','label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank'] \n",
    "\n",
    "        self.feature_cols2 = ['label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank'] \n",
    "\n",
    "        self.feature_cols3 = ['week_day','label_playerId', 'label_primaryPositionName', 'label_teamId',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank'] \n",
    "\n",
    "        self.feature_cols4 = ['week_day', 'annual_day', 'month', 'label_playerId', 'label_primaryPositionName', 'label_teamId', 'label_birthCity',\n",
    "                        'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight',\n",
    "               'label_status', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances',\n",
    "                'season_info', 'wildCardRank'] \n",
    "        \n",
    "        \n",
    "        # lightgbm\n",
    "        self.params1 = {'objective':'mae',\n",
    "                       'reg_alpha': 0.14947461820098767, \n",
    "                       'reg_lambda': 0.10185644384043743, \n",
    "                       'n_estimators': 3633, \n",
    "                       'learning_rate': 0.08046301304430488, \n",
    "                       'num_leaves': 674, \n",
    "                       'feature_fraction': 0.9101240539122566, \n",
    "                       'bagging_fraction': 0.9884451442950513, \n",
    "                       'bagging_freq': 8, \n",
    "                       'min_child_samples': 51}\n",
    "\n",
    "\n",
    "        self.params2 = {'objective':'mae',\n",
    "                       'reg_alpha': 0.1,\n",
    "                       'reg_lambda': 0.1, \n",
    "                       'n_estimators': 80,\n",
    "                       'learning_rate': 0.1,\n",
    "                       'random_state': 42,\n",
    "                       \"num_leaves\": 22}\n",
    "\n",
    "\n",
    "\n",
    "        self.params3 = {'objective':'mae',\n",
    "                       'reg_alpha': 0.1,\n",
    "                       'reg_lambda': 0.1, \n",
    "                       'n_estimators': 10000,\n",
    "                       'learning_rate': 0.1,\n",
    "                       'random_state': 42,\n",
    "                       \"num_leaves\": 100}\n",
    "\n",
    "        self.params4 = {'objective':'mae',\n",
    "                       'reg_alpha': 0.016468100279441976, \n",
    "                       'reg_lambda': 0.09128335764019105, \n",
    "                       'n_estimators': 9868, \n",
    "                       'learning_rate': 0.10528150510326864, \n",
    "                       'num_leaves': 157, \n",
    "                       'feature_fraction': 0.5419185713426886, \n",
    "                       'bagging_fraction': 0.2637405128936662, \n",
    "                       'bagging_freq': 19, \n",
    "                       'min_child_samples': 71}\n",
    "\n",
    "    def make_feature(self, train_elements_dict):\n",
    "\n",
    "        players = train_elements_dict['players']\n",
    "        rosters = train_elements_dict['rosters']\n",
    "        targets = train_elements_dict['targets']\n",
    "        scores = train_elements_dict['scores']\n",
    "        seasons = train_elements_dict['seasons']\n",
    "        teams = train_elements_dict['teams']\n",
    "        standings = train_elements_dict['standings']\n",
    "\n",
    "        print('calc target stat ... ', end=\"\")\n",
    "\n",
    "        ## target stats\n",
    "        targets_train = targets.merge(rosters[self.rosters_cols], on=['playerId', 'date'], how='left')\n",
    "        targets_train = targets_train[(targets_train['date'] >= 20210401)]\n",
    "\n",
    "        playerId_list = targets_train['playerId'].unique()\n",
    "        player_target_probs = pd.DataFrame(columns = self.stat_cols)  \n",
    "        for pid in tqdm(playerId_list):\n",
    "            temp = targets_train[targets_train['playerId'] == pid]\n",
    "            player_target_stats=calc_probs(pid,player_target_probs,temp)\n",
    "\n",
    "        teamId_list = targets_train['teamId'].dropna().unique()\n",
    "        team_target_probs = pd.DataFrame(columns = self.stat_cols)\n",
    "        for pid in tqdm(teamId_list):\n",
    "            temp = targets_train[targets_train['teamId'] == pid]\n",
    "            team_target_stats=calc_probs(pid,team_target_probs,temp)\n",
    "\n",
    "        team_stat_cols = self.stat_cols\n",
    "        team_stat_cols = team_stat_cols[:1] + [\"team_\" + word for word in team_stat_cols[1:]]\n",
    "        team_target_stats.columns = team_stat_cols\n",
    "\n",
    "        self.feature_cols1 += self.stat_cols[1:-6]\n",
    "        self.feature_cols2 += self.stat_cols[1:-6]\n",
    "        self.feature_cols3 += self.stat_cols[1:-6]\n",
    "        self.feature_cols4 += self.stat_cols[1:-6]\n",
    "\n",
    "        self.feature_cols1 += team_stat_cols[1:]\n",
    "        self.feature_cols2 += team_stat_cols[1:]\n",
    "        self.feature_cols3 += team_stat_cols[1:]\n",
    "        self.feature_cols4 += team_stat_cols[1:]\n",
    "\n",
    "        print('done.')\n",
    "\n",
    "        print('preprocess ... ', end=\"\")\n",
    "        ## salaries\n",
    "        # salaries = salaries.groupby(['year', 'team']).sum()['salary'].reset_index()\n",
    "        # salaries['team'] = salaries['team'].apply(map_team_name)\n",
    "        # salaries = salaries.merge(teams, left_on='team', right_on='name', how='inner')\n",
    "        # salaries = salaries.rename(columns={'id': 'teamId'})\n",
    "\n",
    "        ## seasons\n",
    "        seasons = seasons.fillna('0000-00-00')\n",
    "        for c_ in seasons.columns[1:]:\n",
    "            seasons[c_] = seasons[c_].str.replace('-', '').astype(int)\n",
    "\n",
    "        ## players\n",
    "        players['DOY'] = pd.to_datetime(players['DOB'], format=\"%Y-%m-%d\").dt.year\n",
    "        players['mlbDebutYear'] = pd.to_datetime(players['mlbDebutDate'], format=\"%Y-%m-%d\").dt.year\n",
    "        players['DebutAge'] = players['mlbDebutYear'] - players['DOY']\n",
    "\n",
    "        print('done.')\n",
    "\n",
    "        print('creat feature ... ', end=\"\")\n",
    "        # creat feature\n",
    "        train = targets[self.targets_cols].merge(players[self.players_cols], on=['playerId'], how='left')\n",
    "        train = train.merge(rosters[self.rosters_cols], on=['playerId', 'date'], how='left')\n",
    "        train = train.merge(scores[self.scores_cols], on=['playerId', 'date'], how='left')\n",
    "        train = train.merge(player_target_stats, how='inner', left_on=[\"playerId\"],right_on=[\"playerId\"])\n",
    "        train = train.merge(standings[self.standings_cols], on=['teamId', 'date'], how='left')\n",
    "        train = train.merge(team_target_stats, how='left', left_on=[\"teamId\"],right_on=[\"playerId\"], suffixes=('', 'team_'))\n",
    "        date_ = pd.to_datetime(train['date'], format=\"%Y%m%d\")\n",
    "        train['annual_day'] = (date_ - pd.to_datetime(date_.dt.year, format=\"%Y\")) /  timedelta(days=1)\n",
    "        train['week_day'] = date_.dt.weekday\n",
    "        train['month'] = date_.dt.month\n",
    "        train['year'] = date_.dt.year\n",
    "\n",
    "        # label encoding\n",
    "        player2num = {c: i for i, c in enumerate(train['playerId'].unique())}\n",
    "        position2num = {c: i for i, c in enumerate(train['primaryPositionName'].unique())}\n",
    "        birthCityn2num = {c: i for i, c in enumerate(train['birthCity'].unique())}\n",
    "        teamid2num = {c: i for i, c in enumerate(train['teamId'].unique())}\n",
    "        status2num = {c: i for i, c in enumerate(train['status'].unique())}\n",
    "        train['label_playerId'] = train['playerId'].map(player2num)\n",
    "        train['label_primaryPositionName'] = train['primaryPositionName'].map(position2num)\n",
    "        train['label_birthCity'] = train['birthCity'].map(birthCityn2num)\n",
    "        train['label_teamId'] = train['teamId'].map(teamid2num)\n",
    "        train['label_status'] = train['status'].map(status2num)\n",
    "\n",
    "        ## season_info\n",
    "        on_preseason_idxes = extract_season(train['date'], seasons[['preSeasonStartDate', 'preSeasonEndDate']])\n",
    "        on_season_idxes = extract_season(train['date'], seasons[['regularSeasonStartDate', 'regularSeasonEndDate']]) * 2\n",
    "        on_postseason_idxes = extract_season(train['date'], seasons[['postSeasonStartDate', 'postSeasonEndDate']]) * 3\n",
    "\n",
    "        special_days = seasons['lastDate1stHalf'].to_list() + seasons['allStarDate'].to_list() + seasons['firstDate2ndHalf'].to_list()\n",
    "        special_idxes = 0\n",
    "        for day in special_days:\n",
    "            special_idxes += (train['date'] == day) * 4\n",
    "\n",
    "        on_total_season_idxes = on_preseason_idxes\n",
    "        on_total_season_idxes[on_season_idxes==2] = 2\n",
    "        on_total_season_idxes[on_postseason_idxes==3] = 3\n",
    "        on_total_season_idxes[special_idxes==4] = 4\n",
    "\n",
    "        train['season_info'] = on_total_season_idxes\n",
    "\n",
    "        ## only on season\n",
    "        on_whole_idxes = extract_season(train['date'], seasons[['seasonStartDate', 'seasonEndDate']])\n",
    "        train = train[on_whole_idxes == 1].reset_index(drop=True)\n",
    "\n",
    "        # train = train.merge(playerTwitterFollowers, how='left', on=[\"playerId\", 'date'])\n",
    "\n",
    "        ## only test_player\n",
    "        train = train[train['playerForTestSetAndFuturePreds']==True].reset_index(drop=True)\n",
    "\n",
    "        print('done.')\n",
    "        \n",
    "        train_features_dict = {'players': players,\n",
    "                                'player_target_stats': player_target_stats,\n",
    "                                'team_target_stats': team_target_stats,\n",
    "                                'player2num': player2num, \n",
    "                                'position2num': position2num, \n",
    "                                'birthCityn2num': birthCityn2num,\n",
    "                                'teamid2num': teamid2num,\n",
    "                                'status2num': status2num,\n",
    "                                'feature_cols1': self.feature_cols1,\n",
    "                                'feature_cols2': self.feature_cols2,\n",
    "                                'feature_cols3': self.feature_cols3,\n",
    "                                'feature_cols4': self.feature_cols4\n",
    "                              }\n",
    "        \n",
    "        if self.usetimelinefeature:\n",
    "            ## game_info\n",
    "            train['gameday'] = ~train['battingOrder'].isna()*1\n",
    "            train.sort_values(by=['playerId','date'],inplace=True,ascending=True)\n",
    "\n",
    "            train=count_consecutive_items_n_cols(train,['playerId','gameday'],'daysSinceLastGame')\n",
    "            train.loc[train['gameday']==1,'daysSinceLastGame'] = 0\n",
    "\n",
    "            train_game = train[train['gameday']==1]\n",
    "            train_last_game = train_game[~train_game.duplicated(subset='playerId', keep='last')][['playerId', 'date']]\n",
    "            train_last_game.columns = ['playerId', 'lastdate']\n",
    "            train_player_unique = pd.DataFrame(train['playerId'].unique(), columns=['playerId'])\n",
    "            train_last_game = pd.merge(train_player_unique, train_last_game, on=['playerId'], how='left' )\n",
    "            train_last_game = train_last_game.fillna(20171231)\n",
    "            \n",
    "            train_features_dict['train_last_game'] = train_last_game\n",
    "            self.feature_cols1 += ['daysSinceLastGame']\n",
    "            self.feature_cols2 += ['daysSinceLastGame']\n",
    "            self.feature_cols3 += ['daysSinceLastGame']\n",
    "            self.feature_cols4 += ['daysSinceLastGame']\n",
    "            \n",
    "            \n",
    "            ## rosters_info\n",
    "            train['rosterday'] = ~train['status'].isna()*1\n",
    "            train.sort_values(by=['playerId','date'],inplace=True,ascending=True)\n",
    "\n",
    "            train=count_consecutive_items_n_cols(train,['playerId','rosterday'],'daysSinceLastRoster')\n",
    "            train.loc[train['rosterday']==1,'daysSinceLastRoster'] = 0\n",
    "\n",
    "            train_roster= train[train['rosterday']==1]\n",
    "            train_last_roster = train_roster[~train_roster.duplicated(subset='playerId', keep='last')][['playerId', 'date']]\n",
    "            train_last_roster.columns = ['playerId', 'lastroster']\n",
    "            train_player_unique = pd.DataFrame(train['playerId'].unique(), columns=['playerId'])\n",
    "            train_last_roster = pd.merge(train_player_unique, train_last_roster, on=['playerId'], how='left' )\n",
    "            train_last_roster = train_last_roster.fillna(20171231)\n",
    "            \n",
    "            train_features_dict['train_last_roster'] = train_last_roster\n",
    "            self.feature_cols1 += ['daysSinceLastRoster']\n",
    "            self.feature_cols2 += ['daysSinceLastRoster']\n",
    "            self.feature_cols3 += ['daysSinceLastRoster']\n",
    "            self.feature_cols4 += ['daysSinceLastRoster']\n",
    "\n",
    "\n",
    "        return train, train_features_dict\n",
    "\n",
    "    \n",
    "    def train_and_evaluate(self, train, isgamedayonly=False):\n",
    "        \n",
    "        if isgamedayonly:\n",
    "            train = train[train['gameday'] == 1].reset_index(drop=True)\n",
    "            \n",
    "        train_X = train\n",
    "        train_y = train[['target1', 'target2', 'target3', 'target4']]\n",
    "\n",
    "        oof = np.zeros(train_y.shape) - 1.0\n",
    "        y_valids = np.zeros(train_y.shape) - 1.0\n",
    "\n",
    "        tr_idx = (train['date'].astype(int) < 20210401)\n",
    "        val_idx = ~tr_idx\n",
    "\n",
    "        x_train = train_X.loc[tr_idx].reset_index(drop=True)\n",
    "        y_train = train_y.loc[tr_idx].reset_index(drop=True)\n",
    "        x_valid = train_X.loc[val_idx].reset_index(drop=True)\n",
    "        y_valid = train_y.loc[val_idx].reset_index(drop=True)\n",
    "\n",
    "        study1 = optuna.create_study(direction='maximize')\n",
    "        study1.optimize(fit_lgbm(x_train[self.feature_cols1], y_train['target1'], \n",
    "                                 x_valid[self.feature_cols1], y_valid['target1']), n_trials=100)\n",
    "        \n",
    "        study2 = optuna.create_study(direction='maximize')\n",
    "        study2.optimize(fit_lgbm(x_train[self.feature_cols2], y_train['target2'], \n",
    "                                 x_valid[self.feature_cols2], y_valid['target2']), n_trials=100)\n",
    "        \n",
    "        study3 = optuna.create_study(direction='maximize')\n",
    "        study3.optimize(fit_lgbm(x_train[self.feature_cols3], y_train['target3'], \n",
    "                                 x_valid[self.feature_cols3], y_valid['target3']), n_trials=100)\n",
    "        \n",
    "        study4 = optuna.create_study(direction='maximize')\n",
    "        study4.optimize(fit_lgbm(x_train[self.feature_cols4], y_train['target4'], \n",
    "                                 x_valid[self.feature_cols4], y_valid['target4']), n_trials=100)\n",
    "\n",
    "#         oof1, model1, score1 = fit_lgbm(\n",
    "#             x_train[self.feature_cols1], y_train['target1'],\n",
    "#             x_valid[self.feature_cols1], y_valid['target1'],\n",
    "# #             self.params1\n",
    "#         )\n",
    "#         oof2, model2, score2 = fit_lgbm(\n",
    "#             x_train[self.feature_cols2], y_train['target2'],\n",
    "#             x_valid[self.feature_cols2], y_valid['target2'],\n",
    "# #             self.params2\n",
    "#         )\n",
    "#         oof3, model3, score3 = fit_lgbm(\n",
    "#             x_train[self.feature_cols3], y_train['target3'],\n",
    "#             x_valid[self.feature_cols3], y_valid['target3'],\n",
    "# #             self.params3\n",
    "#         )\n",
    "#         oof4, model4, score4 = fit_lgbm(\n",
    "#             x_train[self.feature_cols4], y_train['target4'],\n",
    "#             x_valid[self.feature_cols4], y_valid['target4'],\n",
    "# #             self.params4\n",
    "#         )\n",
    "\n",
    "#         score = (score1+score2+score3+score4) / 4\n",
    "#         print(f'score: {score}')\n",
    "\n",
    "#         oof[val_idx, 0] = oof1\n",
    "#         oof[val_idx, 1] = oof2\n",
    "#         oof[val_idx, 2] = oof3\n",
    "#         oof[val_idx, 3] = oof4\n",
    "#         y_valids[val_idx, 0] = y_valid['target1'].values\n",
    "#         y_valids[val_idx, 1] = y_valid['target2'].values\n",
    "#         y_valids[val_idx, 2] = y_valid['target3'].values\n",
    "#         y_valids[val_idx, 3] = y_valid['target4'].values\n",
    "\n",
    "#         mae = mean_absolute_error(y_valids[val_idx, :], oof[val_idx, :])\n",
    "#         print(\"mae:\", mae)\n",
    "\n",
    "#         val_idx_num = val_idx[val_idx==True].index.to_list()\n",
    "\n",
    "#         oof_df = train[self.targets_cols]\n",
    "#         oof_df.iloc[val_idx_num, 1:5] = oof[val_idx_num, :]\n",
    "\n",
    "#         models = np.array([model1, model2, model3, model4])\n",
    "\n",
    "        return study1, study2, study3, study4\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6336fc22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calc target stat ... "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2061/2061 [00:45<00:00, 44.99it/s]\n",
      "100%|██████████| 30/30 [00:00<00:00, 42.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "preprocess ... done.\n",
      "creat feature ... done.\n"
     ]
    }
   ],
   "source": [
    "rt4kaido_train = Rt4kaidoTrain(usetimelinefeature=True)\n",
    "train, train_features_dict = rt4kaido_train.make_feature(train_elements_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497119c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:09:40,692]\u001b[0m A new study created in memory with name: no-name-a1024e13-2096-4686-b713-f11d18c9d26d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7951806324801636, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7951806324801636\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2897145656576592, subsample=0.8 will be ignored. Current value: bagging_fraction=0.2897145656576592\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.825425\tvalid_1's l1: 1.15231\n",
      "[200]\ttraining's l1: 0.814252\tvalid_1's l1: 1.15372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:09:55,461]\u001b[0m Trial 0 finished with value: -1.1505835553561288 and parameters: {'max_depth': 19, 'min_child_weight': 10, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_lambda': 1.8874891351227971, 'reg_alpha': 0.001548272148361639, 'feature_fraction': 0.7951806324801636, 'bagging_fraction': 0.2897145656576592, 'bagging_freq': 18, 'num_leaves': 877, 'min_child_samples': 59}. Best is trial 0 with value: -1.1505835553561288.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's l1: 0.821731\tvalid_1's l1: 1.15118\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8721169342296915, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.8721169342296915\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.36949839159289977, subsample=0.6 will be ignored. Current value: bagging_fraction=0.36949839159289977\n",
      "[LightGBM] [Warning] bagging_freq is set=19, subsample_freq=0 will be ignored. Current value: bagging_freq=19\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.887615\tvalid_1's l1: 1.2165\n",
      "[200]\ttraining's l1: 0.878817\tvalid_1's l1: 1.2003\n",
      "[300]\ttraining's l1: 0.874556\tvalid_1's l1: 1.19286\n",
      "[400]\ttraining's l1: 0.872271\tvalid_1's l1: 1.18837\n",
      "[500]\ttraining's l1: 0.867641\tvalid_1's l1: 1.17771\n",
      "[600]\ttraining's l1: 0.86616\tvalid_1's l1: 1.17434\n",
      "[700]\ttraining's l1: 0.863119\tvalid_1's l1: 1.16698\n",
      "[800]\ttraining's l1: 0.860379\tvalid_1's l1: 1.16223\n",
      "[900]\ttraining's l1: 0.859408\tvalid_1's l1: 1.16141\n",
      "[1000]\ttraining's l1: 0.854568\tvalid_1's l1: 1.15785\n",
      "[1100]\ttraining's l1: 0.85408\tvalid_1's l1: 1.15701\n",
      "[1200]\ttraining's l1: 0.853\tvalid_1's l1: 1.15467\n",
      "Early stopping, best iteration is:\n",
      "[1177]\ttraining's l1: 0.853097\tvalid_1's l1: 1.15459\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:10:12,375]\u001b[0m Trial 1 finished with value: -1.1543661363292903 and parameters: {'max_depth': 4, 'min_child_weight': 9, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_lambda': 0.15903845377103035, 'reg_alpha': 0.025094283490017345, 'feature_fraction': 0.8721169342296915, 'bagging_fraction': 0.36949839159289977, 'bagging_freq': 19, 'num_leaves': 497, 'min_child_samples': 72}. Best is trial 0 with value: -1.1505835553561288.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.4459233731561678, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.4459233731561678\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.893100540964213, subsample=0.7 will be ignored. Current value: bagging_fraction=0.893100540964213\n",
      "[LightGBM] [Warning] bagging_freq is set=18, subsample_freq=0 will be ignored. Current value: bagging_freq=18\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.927376\tvalid_1's l1: 1.27886\n",
      "[200]\ttraining's l1: 0.921094\tvalid_1's l1: 1.26575\n",
      "[300]\ttraining's l1: 0.916696\tvalid_1's l1: 1.25627\n",
      "[400]\ttraining's l1: 0.914103\tvalid_1's l1: 1.24998\n",
      "[500]\ttraining's l1: 0.913053\tvalid_1's l1: 1.24819\n",
      "[600]\ttraining's l1: 0.911723\tvalid_1's l1: 1.24508\n",
      "[700]\ttraining's l1: 0.911097\tvalid_1's l1: 1.24432\n",
      "[800]\ttraining's l1: 0.910384\tvalid_1's l1: 1.24248\n",
      "[900]\ttraining's l1: 0.909807\tvalid_1's l1: 1.24127\n",
      "[1000]\ttraining's l1: 0.909283\tvalid_1's l1: 1.23945\n",
      "[1100]\ttraining's l1: 0.908974\tvalid_1's l1: 1.23867\n",
      "[1200]\ttraining's l1: 0.908649\tvalid_1's l1: 1.23808\n",
      "[1300]\ttraining's l1: 0.908516\tvalid_1's l1: 1.23779\n",
      "[1400]\ttraining's l1: 0.90848\tvalid_1's l1: 1.23772\n",
      "[1500]\ttraining's l1: 0.908444\tvalid_1's l1: 1.2376\n",
      "[1600]\ttraining's l1: 0.908031\tvalid_1's l1: 1.23685\n",
      "[1700]\ttraining's l1: 0.908\tvalid_1's l1: 1.23676\n",
      "[1800]\ttraining's l1: 0.907811\tvalid_1's l1: 1.2362\n",
      "[1900]\ttraining's l1: 0.907715\tvalid_1's l1: 1.23586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:11:05,127]\u001b[0m Trial 2 finished with value: -1.2355452150079809 and parameters: {'max_depth': 2, 'min_child_weight': 6, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_lambda': 0.05863782923801954, 'reg_alpha': 1.9824643642165893, 'feature_fraction': 0.4459233731561678, 'bagging_fraction': 0.893100540964213, 'bagging_freq': 18, 'num_leaves': 883, 'min_child_samples': 32}. Best is trial 0 with value: -1.1505835553561288.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[1846]\ttraining's l1: 0.907733\tvalid_1's l1: 1.2358\n",
      "[LightGBM] [Warning] feature_fraction is set=0.3958903642599827, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.3958903642599827\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7667902930971371, subsample=0.7 will be ignored. Current value: bagging_fraction=0.7667902930971371\n",
      "[LightGBM] [Warning] bagging_freq is set=13, subsample_freq=0 will be ignored. Current value: bagging_freq=13\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.869987\tvalid_1's l1: 1.19314\n",
      "[200]\ttraining's l1: 0.864509\tvalid_1's l1: 1.18238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:11:13,123]\u001b[0m Trial 3 finished with value: -1.1822804385537233 and parameters: {'max_depth': 5, 'min_child_weight': 11, 'subsample': 0.7, 'colsample_bytree': 0.7, 'reg_lambda': 47.00233928559371, 'reg_alpha': 0.001269073446808143, 'feature_fraction': 0.3958903642599827, 'bagging_fraction': 0.7667902930971371, 'bagging_freq': 13, 'num_leaves': 571, 'min_child_samples': 69}. Best is trial 0 with value: -1.1505835553561288.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's l1: 0.864516\tvalid_1's l1: 1.18237\n",
      "[LightGBM] [Warning] feature_fraction is set=0.7109476893223634, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.7109476893223634\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.21714410924114447, subsample=0.6 will be ignored. Current value: bagging_fraction=0.21714410924114447\n",
      "[LightGBM] [Warning] bagging_freq is set=20, subsample_freq=0 will be ignored. Current value: bagging_freq=20\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.83891\tvalid_1's l1: 1.15465\n",
      "[200]\ttraining's l1: 0.833096\tvalid_1's l1: 1.15126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:11:22,692]\u001b[0m Trial 4 finished with value: -1.1498193937605796 and parameters: {'max_depth': 13, 'min_child_weight': 18, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_lambda': 0.0029576786367722036, 'reg_alpha': 0.057089458273734545, 'feature_fraction': 0.7109476893223634, 'bagging_fraction': 0.21714410924114447, 'bagging_freq': 20, 'num_leaves': 486, 'min_child_samples': 75}. Best is trial 4 with value: -1.1498193937605796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's l1: 0.83375\tvalid_1's l1: 1.15023\n",
      "[LightGBM] [Warning] feature_fraction is set=0.2559808457209526, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.2559808457209526\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2593694803528081, subsample=0.8 will be ignored. Current value: bagging_fraction=0.2593694803528081\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.867671\tvalid_1's l1: 1.17775\n",
      "[200]\ttraining's l1: 0.861514\tvalid_1's l1: 1.16938\n",
      "[300]\ttraining's l1: 0.860534\tvalid_1's l1: 1.16827\n",
      "[400]\ttraining's l1: 0.857902\tvalid_1's l1: 1.16493\n",
      "[500]\ttraining's l1: 0.856718\tvalid_1's l1: 1.16341\n",
      "[600]\ttraining's l1: 0.855808\tvalid_1's l1: 1.1615\n",
      "[700]\ttraining's l1: 0.854104\tvalid_1's l1: 1.15945\n",
      "[800]\ttraining's l1: 0.85271\tvalid_1's l1: 1.15645\n",
      "[900]\ttraining's l1: 0.850502\tvalid_1's l1: 1.15544\n",
      "[1000]\ttraining's l1: 0.849143\tvalid_1's l1: 1.15398\n",
      "Early stopping, best iteration is:\n",
      "[982]\ttraining's l1: 0.849397\tvalid_1's l1: 1.15378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:11:38,694]\u001b[0m Trial 5 finished with value: -1.1532465630600637 and parameters: {'max_depth': 7, 'min_child_weight': 12, 'subsample': 0.8, 'colsample_bytree': 0.8, 'reg_lambda': 991.2043715090208, 'reg_alpha': 0.08909882486824161, 'feature_fraction': 0.2559808457209526, 'bagging_fraction': 0.2593694803528081, 'bagging_freq': 9, 'num_leaves': 352, 'min_child_samples': 96}. Best is trial 4 with value: -1.1498193937605796.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.509186233880975, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.509186233880975\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3630745179550666, subsample=0.9 will be ignored. Current value: bagging_fraction=0.3630745179550666\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.84334\tvalid_1's l1: 1.15405\n",
      "[200]\ttraining's l1: 0.836923\tvalid_1's l1: 1.14542\n",
      "[300]\ttraining's l1: 0.835156\tvalid_1's l1: 1.1449\n",
      "[400]\ttraining's l1: 0.832288\tvalid_1's l1: 1.14443\n",
      "Early stopping, best iteration is:\n",
      "[349]\ttraining's l1: 0.834096\tvalid_1's l1: 1.14416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:11:53,316]\u001b[0m Trial 6 finished with value: -1.1439265845815219 and parameters: {'max_depth': 11, 'min_child_weight': 6, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_lambda': 0.4600778708947517, 'reg_alpha': 0.0011210935963340244, 'feature_fraction': 0.509186233880975, 'bagging_fraction': 0.3630745179550666, 'bagging_freq': 14, 'num_leaves': 269, 'min_child_samples': 78}. Best is trial 6 with value: -1.1439265845815219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6863044878412572, colsample_bytree=0.9 will be ignored. Current value: feature_fraction=0.6863044878412572\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.2557862047362869, subsample=0.5 will be ignored. Current value: bagging_fraction=0.2557862047362869\n",
      "[LightGBM] [Warning] bagging_freq is set=9, subsample_freq=0 will be ignored. Current value: bagging_freq=9\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.873579\tvalid_1's l1: 1.19113\n",
      "[200]\ttraining's l1: 0.866068\tvalid_1's l1: 1.1785\n",
      "[300]\ttraining's l1: 0.86574\tvalid_1's l1: 1.17725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:11:59,058]\u001b[0m Trial 7 finished with value: -1.1770813934561954 and parameters: {'max_depth': 6, 'min_child_weight': 9, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_lambda': 414.84955990215076, 'reg_alpha': 58.82023819272894, 'feature_fraction': 0.6863044878412572, 'bagging_fraction': 0.2557862047362869, 'bagging_freq': 9, 'num_leaves': 983, 'min_child_samples': 13}. Best is trial 6 with value: -1.1439265845815219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[256]\ttraining's l1: 0.865807\tvalid_1's l1: 1.17721\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4169767572519324, colsample_bytree=0.8 will be ignored. Current value: feature_fraction=0.4169767572519324\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6252827504812117, subsample=0.7 will be ignored. Current value: bagging_fraction=0.6252827504812117\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.868583\tvalid_1's l1: 1.19087\n",
      "[200]\ttraining's l1: 0.863188\tvalid_1's l1: 1.18268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:12:06,504]\u001b[0m Trial 8 finished with value: -1.1825763497258281 and parameters: {'max_depth': 5, 'min_child_weight': 19, 'subsample': 0.7, 'colsample_bytree': 0.8, 'reg_lambda': 3.462801997019065, 'reg_alpha': 1.137807342628682, 'feature_fraction': 0.4169767572519324, 'bagging_fraction': 0.6252827504812117, 'bagging_freq': 14, 'num_leaves': 739, 'min_child_samples': 67}. Best is trial 6 with value: -1.1439265845815219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[173]\ttraining's l1: 0.863192\tvalid_1's l1: 1.18267\n",
      "[LightGBM] [Warning] feature_fraction is set=0.21551060185797813, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.21551060185797813\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9408788237086556, subsample=0.5 will be ignored. Current value: bagging_fraction=0.9408788237086556\n",
      "[LightGBM] [Warning] bagging_freq is set=8, subsample_freq=0 will be ignored. Current value: bagging_freq=8\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.925692\tvalid_1's l1: 1.27546\n",
      "[200]\ttraining's l1: 0.919718\tvalid_1's l1: 1.26113\n",
      "[300]\ttraining's l1: 0.915541\tvalid_1's l1: 1.25246\n",
      "[400]\ttraining's l1: 0.91442\tvalid_1's l1: 1.24942\n",
      "[500]\ttraining's l1: 0.912879\tvalid_1's l1: 1.2467\n",
      "[600]\ttraining's l1: 0.91163\tvalid_1's l1: 1.24429\n",
      "[700]\ttraining's l1: 0.911166\tvalid_1's l1: 1.24292\n",
      "[800]\ttraining's l1: 0.910661\tvalid_1's l1: 1.24169\n",
      "[900]\ttraining's l1: 0.909998\tvalid_1's l1: 1.24021\n",
      "[1000]\ttraining's l1: 0.909814\tvalid_1's l1: 1.23959\n",
      "[1100]\ttraining's l1: 0.909625\tvalid_1's l1: 1.23918\n",
      "[1200]\ttraining's l1: 0.909083\tvalid_1's l1: 1.23807\n",
      "[1300]\ttraining's l1: 0.909025\tvalid_1's l1: 1.23808\n",
      "[1400]\ttraining's l1: 0.908835\tvalid_1's l1: 1.23734\n",
      "[1500]\ttraining's l1: 0.908236\tvalid_1's l1: 1.23652\n",
      "[1600]\ttraining's l1: 0.908209\tvalid_1's l1: 1.23651\n",
      "[1700]\ttraining's l1: 0.908091\tvalid_1's l1: 1.23594\n",
      "[1800]\ttraining's l1: 0.907997\tvalid_1's l1: 1.23552\n",
      "[1900]\ttraining's l1: 0.907972\tvalid_1's l1: 1.23549\n",
      "[2000]\ttraining's l1: 0.907925\tvalid_1's l1: 1.23548\n",
      "[2100]\ttraining's l1: 0.907875\tvalid_1's l1: 1.23537\n",
      "[2200]\ttraining's l1: 0.90764\tvalid_1's l1: 1.23477\n",
      "[2300]\ttraining's l1: 0.907562\tvalid_1's l1: 1.23465\n",
      "[2400]\ttraining's l1: 0.907428\tvalid_1's l1: 1.23429\n",
      "[2500]\ttraining's l1: 0.907381\tvalid_1's l1: 1.2341\n",
      "Early stopping, best iteration is:\n",
      "[2497]\ttraining's l1: 0.907385\tvalid_1's l1: 1.23407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:13:07,802]\u001b[0m Trial 9 finished with value: -1.2337770723004067 and parameters: {'max_depth': 2, 'min_child_weight': 19, 'subsample': 0.5, 'colsample_bytree': 0.6, 'reg_lambda': 1.9521029262036558, 'reg_alpha': 0.025944703700245285, 'feature_fraction': 0.21551060185797813, 'bagging_fraction': 0.9408788237086556, 'bagging_freq': 8, 'num_leaves': 646, 'min_child_samples': 85}. Best is trial 6 with value: -1.1439265845815219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5630728549251931, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.5630728549251931\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4815733143117289, subsample=0.9 will be ignored. Current value: bagging_fraction=0.4815733143117289\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.88185\tvalid_1's l1: 1.19938\n",
      "[200]\ttraining's l1: 0.878187\tvalid_1's l1: 1.19045\n",
      "[300]\ttraining's l1: 0.877573\tvalid_1's l1: 1.18885\n",
      "[400]\ttraining's l1: 0.876132\tvalid_1's l1: 1.18605\n",
      "[500]\ttraining's l1: 0.875414\tvalid_1's l1: 1.18469\n",
      "[600]\ttraining's l1: 0.874218\tvalid_1's l1: 1.1831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:13:33,858]\u001b[0m Trial 10 finished with value: -1.182716869556522 and parameters: {'max_depth': 14, 'min_child_weight': 2, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_lambda': 0.0027157331772427293, 'reg_alpha': 736.9538533331473, 'feature_fraction': 0.5630728549251931, 'bagging_fraction': 0.4815733143117289, 'bagging_freq': 1, 'num_leaves': 63, 'min_child_samples': 39}. Best is trial 6 with value: -1.1439265845815219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[539]\ttraining's l1: 0.874598\tvalid_1's l1: 1.18298\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6425412848510487, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.6425412848510487\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.43816635641833057, subsample=0.6 will be ignored. Current value: bagging_fraction=0.43816635641833057\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.843749\tvalid_1's l1: 1.15396\n",
      "[200]\ttraining's l1: 0.83905\tvalid_1's l1: 1.14822\n",
      "[300]\ttraining's l1: 0.837813\tvalid_1's l1: 1.14794\n",
      "[400]\ttraining's l1: 0.834606\tvalid_1's l1: 1.14516\n",
      "[500]\ttraining's l1: 0.827676\tvalid_1's l1: 1.14635\n",
      "Early stopping, best iteration is:\n",
      "[418]\ttraining's l1: 0.832685\tvalid_1's l1: 1.14465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:13:50,138]\u001b[0m Trial 11 finished with value: -1.1443673657476834 and parameters: {'max_depth': 12, 'min_child_weight': 15, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_lambda': 0.0012534222255077814, 'reg_alpha': 0.0010455597029411258, 'feature_fraction': 0.6425412848510487, 'bagging_fraction': 0.43816635641833057, 'bagging_freq': 15, 'num_leaves': 260, 'min_child_samples': 99}. Best is trial 6 with value: -1.1439265845815219.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.5522576490231054, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.5522576490231054\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4789093257810468, subsample=0.9 will be ignored. Current value: bagging_fraction=0.4789093257810468\n",
      "[LightGBM] [Warning] bagging_freq is set=14, subsample_freq=0 will be ignored. Current value: bagging_freq=14\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.852367\tvalid_1's l1: 1.15998\n",
      "[200]\ttraining's l1: 0.85097\tvalid_1's l1: 1.15882\n",
      "[300]\ttraining's l1: 0.848351\tvalid_1's l1: 1.15591\n",
      "[400]\ttraining's l1: 0.84447\tvalid_1's l1: 1.15077\n",
      "[500]\ttraining's l1: 0.841335\tvalid_1's l1: 1.14847\n",
      "[600]\ttraining's l1: 0.838435\tvalid_1's l1: 1.14767\n",
      "[700]\ttraining's l1: 0.835138\tvalid_1's l1: 1.14455\n",
      "[800]\ttraining's l1: 0.832225\tvalid_1's l1: 1.14399\n",
      "Early stopping, best iteration is:\n",
      "[742]\ttraining's l1: 0.834046\tvalid_1's l1: 1.14376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:14:16,615]\u001b[0m Trial 12 finished with value: -1.1433744915859865 and parameters: {'max_depth': 10, 'min_child_weight': 14, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_lambda': 0.042423179471462326, 'reg_alpha': 0.0013863211162166934, 'feature_fraction': 0.5522576490231054, 'bagging_fraction': 0.4789093257810468, 'bagging_freq': 14, 'num_leaves': 155, 'min_child_samples': 100}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.532346729340247, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.532346729340247\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.536663408744462, subsample=0.9 will be ignored. Current value: bagging_fraction=0.536663408744462\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.884295\tvalid_1's l1: 1.21122\n",
      "[200]\ttraining's l1: 0.884225\tvalid_1's l1: 1.21106\n",
      "[300]\ttraining's l1: 0.883784\tvalid_1's l1: 1.21047\n",
      "[400]\ttraining's l1: 0.881854\tvalid_1's l1: 1.20594\n",
      "[500]\ttraining's l1: 0.8787\tvalid_1's l1: 1.20074\n",
      "[600]\ttraining's l1: 0.87424\tvalid_1's l1: 1.19217\n",
      "[700]\ttraining's l1: 0.869014\tvalid_1's l1: 1.18196\n",
      "[800]\ttraining's l1: 0.86763\tvalid_1's l1: 1.17869\n",
      "[900]\ttraining's l1: 0.865044\tvalid_1's l1: 1.17494\n",
      "[1000]\ttraining's l1: 0.859098\tvalid_1's l1: 1.16447\n",
      "[1100]\ttraining's l1: 0.855923\tvalid_1's l1: 1.16078\n",
      "[1200]\ttraining's l1: 0.853748\tvalid_1's l1: 1.15759\n",
      "[1300]\ttraining's l1: 0.851335\tvalid_1's l1: 1.15336\n",
      "[1400]\ttraining's l1: 0.849904\tvalid_1's l1: 1.15257\n",
      "[1500]\ttraining's l1: 0.84854\tvalid_1's l1: 1.15154\n",
      "[1600]\ttraining's l1: 0.847306\tvalid_1's l1: 1.15046\n",
      "[1700]\ttraining's l1: 0.846312\tvalid_1's l1: 1.15038\n",
      "[1800]\ttraining's l1: 0.845156\tvalid_1's l1: 1.14923\n",
      "[1900]\ttraining's l1: 0.843829\tvalid_1's l1: 1.14765\n",
      "[2000]\ttraining's l1: 0.842987\tvalid_1's l1: 1.147\n",
      "[2100]\ttraining's l1: 0.84141\tvalid_1's l1: 1.14652\n",
      "[2200]\ttraining's l1: 0.840564\tvalid_1's l1: 1.1457\n",
      "[2300]\ttraining's l1: 0.839864\tvalid_1's l1: 1.14567\n",
      "Early stopping, best iteration is:\n",
      "[2240]\ttraining's l1: 0.8403\tvalid_1's l1: 1.14546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:15:15,068]\u001b[0m Trial 13 finished with value: -1.1450763197211513 and parameters: {'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_lambda': 0.040250894479830795, 'reg_alpha': 0.004728827234527957, 'feature_fraction': 0.532346729340247, 'bagging_fraction': 0.536663408744462, 'bagging_freq': 5, 'num_leaves': 33, 'min_child_samples': 88}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3018534903402847, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.3018534903402847\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.7074641164969618, subsample=0.9 will be ignored. Current value: bagging_fraction=0.7074641164969618\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.85347\tvalid_1's l1: 1.164\n",
      "[200]\ttraining's l1: 0.849545\tvalid_1's l1: 1.158\n",
      "[300]\ttraining's l1: 0.847468\tvalid_1's l1: 1.15549\n",
      "[400]\ttraining's l1: 0.844341\tvalid_1's l1: 1.15336\n",
      "[500]\ttraining's l1: 0.841187\tvalid_1's l1: 1.15055\n",
      "[600]\ttraining's l1: 0.838819\tvalid_1's l1: 1.14838\n",
      "[700]\ttraining's l1: 0.836539\tvalid_1's l1: 1.14786\n",
      "[800]\ttraining's l1: 0.833971\tvalid_1's l1: 1.14576\n",
      "[900]\ttraining's l1: 0.832289\tvalid_1's l1: 1.14695\n",
      "Early stopping, best iteration is:\n",
      "[803]\ttraining's l1: 0.833881\tvalid_1's l1: 1.14571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:15:45,453]\u001b[0m Trial 14 finished with value: -1.1453763793504657 and parameters: {'max_depth': 16, 'min_child_weight': 15, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_lambda': 0.195065570509387, 'reg_alpha': 12.803342323299766, 'feature_fraction': 0.3018534903402847, 'bagging_fraction': 0.7074641164969618, 'bagging_freq': 12, 'num_leaves': 193, 'min_child_samples': 100}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.513475308631619, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.513475308631619\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.3959407047017276, subsample=0.8 will be ignored. Current value: bagging_fraction=0.3959407047017276\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.850679\tvalid_1's l1: 1.15989\n",
      "[200]\ttraining's l1: 0.847974\tvalid_1's l1: 1.15516\n",
      "[300]\ttraining's l1: 0.843197\tvalid_1's l1: 1.15166\n",
      "[400]\ttraining's l1: 0.839548\tvalid_1's l1: 1.14836\n",
      "[500]\ttraining's l1: 0.834174\tvalid_1's l1: 1.14829\n",
      "Early stopping, best iteration is:\n",
      "[452]\ttraining's l1: 0.837265\tvalid_1's l1: 1.14731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:16:02,245]\u001b[0m Trial 15 finished with value: -1.1470461440125512 and parameters: {'max_depth': 11, 'min_child_weight': 5, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_lambda': 0.014333382647731428, 'reg_alpha': 0.007033560120611144, 'feature_fraction': 0.513475308631619, 'bagging_fraction': 0.3959407047017276, 'bagging_freq': 16, 'num_leaves': 192, 'min_child_samples': 85}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.9905152745242837, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.9905152745242837\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.5839275682973061, subsample=0.9 will be ignored. Current value: bagging_fraction=0.5839275682973061\n",
      "[LightGBM] [Warning] bagging_freq is set=12, subsample_freq=0 will be ignored. Current value: bagging_freq=12\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.840386\tvalid_1's l1: 1.16167\n",
      "[200]\ttraining's l1: 0.83345\tvalid_1's l1: 1.15577\n",
      "[300]\ttraining's l1: 0.830629\tvalid_1's l1: 1.15424\n",
      "[400]\ttraining's l1: 0.828633\tvalid_1's l1: 1.15253\n",
      "[500]\ttraining's l1: 0.82637\tvalid_1's l1: 1.15058\n",
      "[600]\ttraining's l1: 0.825244\tvalid_1's l1: 1.14988\n",
      "Early stopping, best iteration is:\n",
      "[562]\ttraining's l1: 0.825572\tvalid_1's l1: 1.14952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:16:27,551]\u001b[0m Trial 16 finished with value: -1.1492850665498098 and parameters: {'max_depth': 9, 'min_child_weight': 15, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_lambda': 22.795938818779796, 'reg_alpha': 0.21492353155726673, 'feature_fraction': 0.9905152745242837, 'bagging_fraction': 0.5839275682973061, 'bagging_freq': 12, 'num_leaves': 394, 'min_child_samples': 47}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.3536591507302146, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.3536591507302146\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.346086466959584, subsample=0.8 will be ignored. Current value: bagging_fraction=0.346086466959584\n",
      "[LightGBM] [Warning] bagging_freq is set=16, subsample_freq=0 will be ignored. Current value: bagging_freq=16\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.858412\tvalid_1's l1: 1.16959\n",
      "[200]\ttraining's l1: 0.8546\tvalid_1's l1: 1.16285\n",
      "[300]\ttraining's l1: 0.850696\tvalid_1's l1: 1.15764\n",
      "[400]\ttraining's l1: 0.845494\tvalid_1's l1: 1.1508\n",
      "[500]\ttraining's l1: 0.841777\tvalid_1's l1: 1.14939\n",
      "[600]\ttraining's l1: 0.838892\tvalid_1's l1: 1.14921\n",
      "[700]\ttraining's l1: 0.836701\tvalid_1's l1: 1.14811\n",
      "[800]\ttraining's l1: 0.834897\tvalid_1's l1: 1.14816\n",
      "Early stopping, best iteration is:\n",
      "[784]\ttraining's l1: 0.835353\tvalid_1's l1: 1.14767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:16:48,727]\u001b[0m Trial 17 finished with value: -1.1472589821683363 and parameters: {'max_depth': 15, 'min_child_weight': 6, 'subsample': 0.8, 'colsample_bytree': 0.6, 'reg_lambda': 0.3983626087173202, 'reg_alpha': 0.005914035251534058, 'feature_fraction': 0.3536591507302146, 'bagging_fraction': 0.346086466959584, 'bagging_freq': 16, 'num_leaves': 151, 'min_child_samples': 89}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.47568277828490246, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.47568277828490246\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4796659649650338, subsample=0.9 will be ignored. Current value: bagging_fraction=0.4796659649650338\n",
      "[LightGBM] [Warning] bagging_freq is set=11, subsample_freq=0 will be ignored. Current value: bagging_freq=11\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.844529\tvalid_1's l1: 1.15552\n",
      "[200]\ttraining's l1: 0.840148\tvalid_1's l1: 1.15207\n",
      "[300]\ttraining's l1: 0.837092\tvalid_1's l1: 1.15035\n",
      "[400]\ttraining's l1: 0.83128\tvalid_1's l1: 1.14815\n",
      "[500]\ttraining's l1: 0.827503\tvalid_1's l1: 1.14751\n",
      "[600]\ttraining's l1: 0.8237\tvalid_1's l1: 1.14606\n",
      "[700]\ttraining's l1: 0.820472\tvalid_1's l1: 1.14644\n",
      "Early stopping, best iteration is:\n",
      "[626]\ttraining's l1: 0.822614\tvalid_1's l1: 1.14587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:17:17,848]\u001b[0m Trial 18 finished with value: -1.145375135311367 and parameters: {'max_depth': 18, 'min_child_weight': 13, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_lambda': 0.016145214039615684, 'reg_alpha': 0.22273607137858872, 'feature_fraction': 0.47568277828490246, 'bagging_fraction': 0.4796659649650338, 'bagging_freq': 11, 'num_leaves': 316, 'min_child_samples': 56}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.6107398938534028, colsample_bytree=0.7 will be ignored. Current value: feature_fraction=0.6107398938534028\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6399057882501817, subsample=0.8 will be ignored. Current value: bagging_fraction=0.6399057882501817\n",
      "[LightGBM] [Warning] bagging_freq is set=7, subsample_freq=0 will be ignored. Current value: bagging_freq=7\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.864354\tvalid_1's l1: 1.18101\n",
      "[200]\ttraining's l1: 0.861452\tvalid_1's l1: 1.17419\n",
      "[300]\ttraining's l1: 0.859186\tvalid_1's l1: 1.17023\n",
      "[400]\ttraining's l1: 0.85582\tvalid_1's l1: 1.16305\n",
      "[500]\ttraining's l1: 0.851346\tvalid_1's l1: 1.15622\n",
      "[600]\ttraining's l1: 0.848952\tvalid_1's l1: 1.15511\n",
      "[700]\ttraining's l1: 0.845521\tvalid_1's l1: 1.15162\n",
      "[800]\ttraining's l1: 0.843293\tvalid_1's l1: 1.15023\n",
      "Early stopping, best iteration is:\n",
      "[771]\ttraining's l1: 0.843384\tvalid_1's l1: 1.15013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:17:48,078]\u001b[0m Trial 19 finished with value: -1.149983824194756 and parameters: {'max_depth': 9, 'min_child_weight': 8, 'subsample': 0.8, 'colsample_bytree': 0.7, 'reg_lambda': 16.821751816948378, 'reg_alpha': 0.001090473507521142, 'feature_fraction': 0.6107398938534028, 'bagging_fraction': 0.6399057882501817, 'bagging_freq': 7, 'num_leaves': 87, 'min_child_samples': 78}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] feature_fraction is set=0.7826431760322485, colsample_bytree=0.6 will be ignored. Current value: feature_fraction=0.7826431760322485\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.330223644118916, subsample=0.9 will be ignored. Current value: bagging_fraction=0.330223644118916\n",
      "[LightGBM] [Warning] bagging_freq is set=5, subsample_freq=0 will be ignored. Current value: bagging_freq=5\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.889938\tvalid_1's l1: 1.21116\n",
      "[200]\ttraining's l1: 0.888592\tvalid_1's l1: 1.20767\n",
      "[300]\ttraining's l1: 0.887581\tvalid_1's l1: 1.20617\n",
      "[400]\ttraining's l1: 0.886467\tvalid_1's l1: 1.20273\n",
      "[500]\ttraining's l1: 0.884503\tvalid_1's l1: 1.19764\n",
      "[600]\ttraining's l1: 0.88267\tvalid_1's l1: 1.19221\n",
      "[700]\ttraining's l1: 0.881783\tvalid_1's l1: 1.19107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2021-07-16 03:18:01,457]\u001b[0m Trial 20 finished with value: -1.1907437667359801 and parameters: {'max_depth': 17, 'min_child_weight': 1, 'subsample': 0.9, 'colsample_bytree': 0.6, 'reg_lambda': 0.5388595803099507, 'reg_alpha': 828.0802132324297, 'feature_fraction': 0.7826431760322485, 'bagging_fraction': 0.330223644118916, 'bagging_freq': 5, 'num_leaves': 428, 'min_child_samples': 99}. Best is trial 12 with value: -1.1433744915859865.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[699]\ttraining's l1: 0.881785\tvalid_1's l1: 1.19106\n",
      "[LightGBM] [Warning] feature_fraction is set=0.6133305243404783, colsample_bytree=0.5 will be ignored. Current value: feature_fraction=0.6133305243404783\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.4387268623730576, subsample=0.6 will be ignored. Current value: bagging_fraction=0.4387268623730576\n",
      "[LightGBM] [Warning] bagging_freq is set=15, subsample_freq=0 will be ignored. Current value: bagging_freq=15\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's l1: 0.842993\tvalid_1's l1: 1.15299\n",
      "[200]\ttraining's l1: 0.838695\tvalid_1's l1: 1.14982\n",
      "[300]\ttraining's l1: 0.836864\tvalid_1's l1: 1.14842\n",
      "[400]\ttraining's l1: 0.832529\tvalid_1's l1: 1.14586\n",
      "[500]\ttraining's l1: 0.828199\tvalid_1's l1: 1.14488\n",
      "[600]\ttraining's l1: 0.824036\tvalid_1's l1: 1.14531\n"
     ]
    }
   ],
   "source": [
    "study1, study2, study3, study4 = rt4kaido_train.train_and_evaluate(train, isgamedayonly=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "79ba349f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score = 1.1377244952432373\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 20,\n",
       " 'min_child_weight': 6,\n",
       " 'subsample': 0.6,\n",
       " 'colsample_bytree': 0.7,\n",
       " 'reg_lambda': 0.08135847923727514,\n",
       " 'reg_alpha': 1.49433391288005,\n",
       " 'feature_fraction': 0.5197130924180956,\n",
       " 'bagging_fraction': 0.7648977376363217,\n",
       " 'bagging_freq': 13,\n",
       " 'num_leaves': 181,\n",
       " 'min_child_samples': 17}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'best_score = {-study1.best_value}')\n",
    "study1.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1881c287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score = 2.1926348140676515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 16,\n",
       " 'min_child_weight': 3,\n",
       " 'subsample': 0.7,\n",
       " 'colsample_bytree': 0.5,\n",
       " 'reg_lambda': 0.004528826382334437,\n",
       " 'reg_alpha': 1.9645054145486578,\n",
       " 'feature_fraction': 0.9015395368511052,\n",
       " 'bagging_fraction': 0.9958830097531277,\n",
       " 'bagging_freq': 12,\n",
       " 'num_leaves': 761,\n",
       " 'min_child_samples': 96}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'best_score = {-study2.best_value}')\n",
    "study2.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23548304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score = 0.9225472847558365\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 5,\n",
       " 'min_child_weight': 18,\n",
       " 'subsample': 0.5,\n",
       " 'colsample_bytree': 0.5,\n",
       " 'reg_lambda': 0.02821111013127755,\n",
       " 'reg_alpha': 0.0046946396301503586,\n",
       " 'feature_fraction': 0.9780515566739537,\n",
       " 'bagging_fraction': 0.7202933086435114,\n",
       " 'bagging_freq': 11,\n",
       " 'num_leaves': 137,\n",
       " 'min_child_samples': 45}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'best_score = {-study3.best_value}')\n",
    "study3.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "085d8d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best_score = 1.5576931483677667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9,\n",
       " 'min_child_weight': 8,\n",
       " 'subsample': 0.6,\n",
       " 'colsample_bytree': 0.8,\n",
       " 'reg_lambda': 24.80468829330036,\n",
       " 'reg_alpha': 0.3674254895182708,\n",
       " 'feature_fraction': 0.8268416192212926,\n",
       " 'bagging_fraction': 0.36802486339139545,\n",
       " 'bagging_freq': 19,\n",
       " 'num_leaves': 909,\n",
       " 'min_child_samples': 62}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'best_score = {-study4.best_value}')\n",
    "study4.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ff5903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
