{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db00d124",
   "metadata": {
    "papermill": {
     "duration": 2.396783,
     "end_time": "2021-07-19T13:45:53.220925",
     "exception": false,
     "start_time": "2021-07-19T13:45:50.824142",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import math\n",
    "import random\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import copy\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "from functools import reduce\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# from pandarallel import pandarallel\n",
    "# pandarallel.initialize()\n",
    "warnings.simplefilter(\"ignore\")\n",
    "import ctypes as ct\n",
    "from datetime import timedelta\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# import mlb\n",
    "import statistics as st\n",
    "import lightgbm as lgbm\n",
    "from scipy.stats import norm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4119205a",
   "metadata": {
    "papermill": {
     "duration": 0.018969,
     "end_time": "2021-07-19T13:45:53.253211",
     "exception": false,
     "start_time": "2021-07-19T13:45:53.234242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# sys.path.append('../../')\n",
    "# import src.utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0dff279d",
   "metadata": {
    "papermill": {
     "duration": 0.019577,
     "end_time": "2021-07-19T13:45:53.285537",
     "exception": false,
     "start_time": "2021-07-19T13:45:53.265960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "OFFSET = 45\n",
    "MAX_LAG = 27\n",
    "LAGS = list(range(OFFSET, MAX_LAG + OFFSET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7fa5d1f3",
   "metadata": {
    "papermill": {
     "duration": 0.019734,
     "end_time": "2021-07-19T13:45:53.317585",
     "exception": false,
     "start_time": "2021-07-19T13:45:53.297851",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"/home/knikaido/work/MLB-Player-Digital-Engagement-Forecasting/data/\")\n",
    "MAIN_DATA_DIR = DATA_DIR / 'mlb-player-digital-engagement-forecasting'\n",
    "UPDATE_DATA_DIR = DATA_DIR / 'mlb-player-digital-engagement-forecasting-update'\n",
    "\n",
    "BASE_DIR = MAIN_DATA_DIR\n",
    "TRAIN_DIR = MAIN_DATA_DIR / 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5667afe",
   "metadata": {
    "papermill": {
     "duration": 4.51961,
     "end_time": "2021-07-19T13:45:57.849757",
     "exception": false,
     "start_time": "2021-07-19T13:45:53.330147",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "players = pd.read_csv(BASE_DIR / 'players.csv')\n",
    "\n",
    "rosters = pd.read_csv(TRAIN_DIR / 'rosters_train.csv')\n",
    "targets = pd.read_csv(TRAIN_DIR / 'nextDayPlayerEngagement_train.csv')\n",
    "scores = pd.read_csv(TRAIN_DIR / 'playerBoxScores_train.csv')\n",
    "scores = scores.groupby(['playerId', 'date']).sum().reset_index()\n",
    "standings = pd.read_csv(TRAIN_DIR / 'standings_train.csv')\n",
    "awards = pd.read_csv(TRAIN_DIR / 'awards_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "372a53f6",
   "metadata": {
    "papermill": {
     "duration": 0.033909,
     "end_time": "2021-07-19T13:45:57.896349",
     "exception": false,
     "start_time": "2021-07-19T13:45:57.862440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "players = pd.read_csv(BASE_DIR / 'players.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c977138c",
   "metadata": {
    "papermill": {
     "duration": 0.034139,
     "end_time": "2021-07-19T13:45:57.943154",
     "exception": false,
     "start_time": "2021-07-19T13:45:57.909015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten(df, col):\n",
    "    du = (df.pivot(index='playerId', columns='EvalDate', \n",
    "               values=col).add_prefix(f'{col}_').\n",
    "      rename_axis(None, axis=1).reset_index())\n",
    "    return du\n",
    "\n",
    "\n",
    "def reducer(left, right):\n",
    "    return left.merge(right, on='playerId')\n",
    "\n",
    "\n",
    "def make_train_lag(df, lags):\n",
    "    df['EvalDate'] = pd.to_datetime(df['date'], format=\"%Y%m%d\")\n",
    "    for lag in tqdm(lags):\n",
    "        dp = df[['playerId','EvalDate'] + ['target1', 'target2', 'target3', 'target4']].copy()\n",
    "        dp['EvalDate']  =dp['EvalDate'] + timedelta(days=lag) \n",
    "        df = df.merge(dp, on=['playerId', 'EvalDate'], suffixes=['',f'_{lag}'], how='left')\n",
    "        gc.collect()\n",
    "    df = df.sort_values(by=['playerId', 'EvalDate'])\n",
    "    df = df.dropna()\n",
    "    return df\n",
    "\n",
    "def make_test_lag(sub, last):\n",
    "    sub['playerId'] = sub['date_playerId'].apply(lambda s: int(  s.split('_')[1]  ) )\n",
    "    assert sub.date.nunique() == 1\n",
    "    dte = sub['date'].unique()[0]\n",
    "    \n",
    "    eval_dt = pd.to_datetime(dte, format='%Y%m%d')\n",
    "    dtes = [eval_dt + timedelta(days = -k) for k in LAGS]\n",
    "    mp_dtes = {eval_dt + timedelta(days = -k): k for k in LAGS}\n",
    "    \n",
    "    sl = last.loc[last['EvalDate'].between(dtes[-1], dtes[0]), ['EvalDate','playerId'] + ['target1', 'target2', 'target3', 'target4']].copy()\n",
    "    sl['EvalDate'] = sl['EvalDate'].map(mp_dtes)\n",
    "    du = [flatten(sl, col) for col in ['target1', 'target2', 'target3', 'target4']]\n",
    "    du = reduce(reducer, du)\n",
    "    return du, eval_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d76b81ed",
   "metadata": {
    "papermill": {
     "duration": 0.068618,
     "end_time": "2021-07-19T13:45:58.024323",
     "exception": false,
     "start_time": "2021-07-19T13:45:57.955705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Rt4kaidoTest:\n",
    "    def __init__(self, train_features_dict, models_notgameday, models_gameday, usetimelinefeature=False):\n",
    "        \n",
    "        self.usetimelinefeature = usetimelinefeature\n",
    "        self.train_features_dict = train_features_dict\n",
    "        self.feature_cols1 = train_features_dict['feature_cols1']\n",
    "        self.feature_cols2 = train_features_dict['feature_cols2']\n",
    "        self.feature_cols3 = train_features_dict['feature_cols3']\n",
    "        self.feature_cols4 = train_features_dict['feature_cols4']\n",
    "        self.models_notgameday = models_notgameday\n",
    "        self.models_gameday = models_gameday\n",
    "\n",
    "\n",
    "        self.test_players_cols = ['playerId', 'primaryPositionName', 'birthCity', 'DOY', 'mlbDebutYear', 'DebutAge', 'heightInches', 'weight']\n",
    "        self.test_rosters_cols = ['playerId', 'teamId', 'status']\n",
    "        self.test_standings_cols = ['teamId', 'wildCardRank', 'sportGamesBack']\n",
    "        self.test_scores_cols = ['playerId', 'battingOrder', 'gamesPlayedBatting', 'flyOuts',\n",
    "               'groundOuts', 'runsScored', 'doubles', 'triples', 'homeRuns',\n",
    "               'strikeOuts', 'baseOnBalls', 'intentionalWalks', 'hits', 'hitByPitch',\n",
    "               'atBats', 'caughtStealing', 'stolenBases', 'groundIntoDoublePlay',\n",
    "               'groundIntoTriplePlay', 'plateAppearances', 'totalBases', 'rbi',\n",
    "               'leftOnBase', 'sacBunts', 'sacFlies', 'catchersInterference',\n",
    "               'pickoffs', 'gamesPlayedPitching', 'gamesStartedPitching',\n",
    "               'completeGamesPitching', 'shutoutsPitching', 'winsPitching',\n",
    "               'lossesPitching', 'flyOutsPitching', 'airOutsPitching',\n",
    "               'groundOutsPitching', 'runsPitching', 'doublesPitching',\n",
    "               'triplesPitching', 'homeRunsPitching', 'strikeOutsPitching',\n",
    "               'baseOnBallsPitching', 'intentionalWalksPitching', 'hitsPitching',\n",
    "               'hitByPitchPitching', 'atBatsPitching', 'caughtStealingPitching',\n",
    "               'stolenBasesPitching', 'inningsPitched', 'saveOpportunities',\n",
    "               'earnedRuns', 'battersFaced', 'outsPitching', 'pitchesThrown', 'balls',\n",
    "               'strikes', 'hitBatsmen', 'balks', 'wildPitches', 'pickoffsPitching',\n",
    "               'rbiPitching', 'gamesFinishedPitching', 'inheritedRunners',\n",
    "               'inheritedRunnersScored', 'catchersInterferencePitching',\n",
    "               'sacBuntsPitching', 'sacFliesPitching', 'saves', 'holds', 'blownSaves',\n",
    "               'assists', 'putOuts', 'errors', 'chances']\n",
    "        \n",
    "\n",
    "    def test_oneline(self, test_df, sample_prediction_df):\n",
    "        \n",
    "        null = np.nan\n",
    "        true = True\n",
    "        false = False\n",
    "        \n",
    "        sample_prediction_df = sample_prediction_df.reset_index(drop=True)\n",
    "\n",
    "        # creat dataset\n",
    "        sample_prediction_df['playerId'] = sample_prediction_df['date_playerId']\\\n",
    "                                            .map(lambda x: int(x.split('_')[1]))\n",
    "        # Dealing with missing values\n",
    "        if test_df['rosters'].iloc[0] == test_df['rosters'].iloc[0]:\n",
    "            test_rosters = pd.DataFrame(eval(test_df['rosters'].iloc[0]))\n",
    "        else:\n",
    "            test_rosters = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "            for col in rosters.columns:\n",
    "                if col == 'playerId': continue\n",
    "                test_rosters[col] = np.nan\n",
    "\n",
    "        if test_df['playerBoxScores'].iloc[0] == test_df['playerBoxScores'].iloc[0]:\n",
    "            test_scores = pd.DataFrame(eval(test_df['playerBoxScores'].iloc[0]))\n",
    "        else:\n",
    "            test_scores = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "            for col in scores.columns:\n",
    "                if col == 'playerId': continue\n",
    "                test_scores[col] = np.nan\n",
    "\n",
    "        if test_df['standings'].iloc[0] == test_df['standings'].iloc[0]:\n",
    "            test_standings = pd.DataFrame(eval(test_df['standings'].iloc[0]))\n",
    "        else:\n",
    "            test_standings = pd.DataFrame({'playerId': sample_prediction_df['playerId']})\n",
    "            for col in standings.columns:\n",
    "                if col == 'playerId': continue\n",
    "                test_standings[col] = np.nan\n",
    "\n",
    "        test_scores = test_scores.groupby('playerId').sum().reset_index()\n",
    "        test = sample_prediction_df[['playerId']].copy()\n",
    "        test = test.merge(self.train_features_dict['players'][self.test_players_cols], on='playerId', how='left')\n",
    "        test = test.merge(test_rosters[self.test_rosters_cols], on='playerId', how='left')\n",
    "        test = test.merge(test_scores[self.test_scores_cols], on='playerId', how='left')\n",
    "        test = test.merge(self.train_features_dict['player_target_stats'], how='left', left_on=[\"playerId\"],right_on=[\"playerId\"])\n",
    "        test = test.merge(test_standings[self.test_standings_cols], on='teamId', how='left')\n",
    "        test = test.merge(self.train_features_dict['team_target_stats'], how='left', left_on=[\"teamId\"],right_on=[\"playerId\"], suffixes=('', 'team_'))\n",
    "        test['wildCardRank'] = test['wildCardRank'].astype(float)\n",
    "\n",
    "\n",
    "        test['label_playerId'] = test['playerId'].map(self.train_features_dict['player2num'])\n",
    "        test['label_primaryPositionName'] = test['primaryPositionName'].map(self.train_features_dict['position2num'])\n",
    "        test['label_teamId'] = test['teamId'].map(self.train_features_dict['teamid2num'])\n",
    "        test['label_status'] = test['status'].map(self.train_features_dict['status2num'])\n",
    "        test['label_birthCity'] = test['birthCity'].map(self.train_features_dict['birthCityn2num'])\n",
    "\n",
    "        date_ = pd.to_datetime(test_df.index[0], format=\"%Y%m%d\")\n",
    "        test['annual_day'] = (date_ - pd.to_datetime(date_.year, format=\"%Y\")) /  timedelta(days=1)\n",
    "        test['week_day'] = date_.weekday()\n",
    "        test['month'] = date_.month\n",
    "        test['season_info'] = 2\n",
    "        \n",
    "        if self.usetimelinefeature:\n",
    "            test['date'] = test_df.index[0]\n",
    "            \n",
    "            test['gameday'] = ~test['battingOrder'].isna()*1\n",
    "            test = pd.merge(test, self.train_features_dict['train_last_game'], on=['playerId'], how='left')\n",
    "            test['daysSinceLastGame'] = (pd.to_datetime(test['date'], format=\"%Y%m%d\") - pd.to_datetime(test['lastdate'], format=\"%Y%m%d\")).dt.days\n",
    "            test.loc[test['gameday']==1,'daysSinceLastGame']=0\n",
    "            \n",
    "            self.train_features_dict['train_last_game'] = pd.merge(self.train_features_dict['train_last_game'], test[test['gameday']==1][['playerId','date']], on=['playerId'], how='left')\n",
    "            self.train_features_dict['train_last_game']['lastdate'].update(self.train_features_dict['train_last_game']['date'])\n",
    "            self.train_features_dict['train_last_game'] = self.train_features_dict['train_last_game'][['playerId', 'lastdate']]\n",
    "                        \n",
    "            test['rosterday'] = ~test['status'].isna()*1\n",
    "            test = pd.merge(test, self.train_features_dict['train_last_roster'], on=['playerId'], how='left')\n",
    "            test['daysSinceLastRoster'] = (pd.to_datetime(test['date'], format=\"%Y%m%d\") - pd.to_datetime(test['lastroster'], format=\"%Y%m%d\")).dt.days\n",
    "            test.loc[test['rosterday']==1,'daysSinceLastRoster']=0\n",
    "            \n",
    "            self.train_features_dict['train_last_roster'] = pd.merge(self.train_features_dict['train_last_roster'], test[test['rosterday']==1][['playerId','date']], on=['playerId'], how='left')\n",
    "            self.train_features_dict['train_last_roster']['lastroster'].update(self.train_features_dict['train_last_roster']['date'])\n",
    "            self.train_features_dict['train_last_roster'] = self.train_features_dict['train_last_roster'][['playerId', 'lastroster']]\n",
    "\n",
    "        test_gameday = test[test['gameday']==1]\n",
    "\n",
    "        if len(test_gameday) != 0:\n",
    "            gameday_index = list(test_gameday.index)\n",
    "\n",
    "            test_X = test.iloc[gameday_index]\n",
    "\n",
    "            pred1 = self.models_gameday[0][4].predict(test_X[self.feature_cols1])\n",
    "            pred2 = self.models_gameday[1][4].predict(test_X[self.feature_cols2])\n",
    "            pred3 = self.models_gameday[2][4].predict(test_X[self.feature_cols3])\n",
    "            pred4 = self.models_gameday[3][4].predict(test_X[self.feature_cols4])\n",
    "\n",
    "            # merge submission\n",
    "            sample_prediction_df['target1'].iloc[gameday_index] = np.clip(pred1, 0, 100)\n",
    "            sample_prediction_df['target2'].iloc[gameday_index] = np.clip(pred2, 0, 100)\n",
    "            sample_prediction_df['target3'].iloc[gameday_index] = np.clip(pred3, 0, 100)\n",
    "            sample_prediction_df['target4'].iloc[gameday_index] = np.clip(pred4, 0, 100)\n",
    "\n",
    "        # ------------------------------------------------------------\n",
    "\n",
    "        test_notgameday = test[test['gameday']==0]\n",
    "        if len(test_notgameday) != 0:\n",
    "            notgameday_index = list(test_notgameday.index)\n",
    "\n",
    "            test_X = test.iloc[notgameday_index]\n",
    "\n",
    "            pred1 = self.models_notgameday[0][4].predict(test_X[self.feature_cols1])\n",
    "            pred2 = self.models_notgameday[1][4].predict(test_X[self.feature_cols2])\n",
    "            pred3 = self.models_notgameday[2][4].predict(test_X[self.feature_cols3])\n",
    "            pred4 = self.models_notgameday[3][4].predict(test_X[self.feature_cols4])\n",
    "\n",
    "            # merge submission\n",
    "            sample_prediction_df['target1'].iloc[notgameday_index] = np.clip(pred1, 0, 100)\n",
    "            sample_prediction_df['target2'].iloc[notgameday_index] = np.clip(pred2, 0, 100)\n",
    "            sample_prediction_df['target3'].iloc[notgameday_index] = np.clip(pred3, 0, 100)\n",
    "            sample_prediction_df['target4'].iloc[notgameday_index] = np.clip(pred4, 0, 100)\n",
    "\n",
    "        sample_prediction_df = sample_prediction_df.fillna(0.)\n",
    "\n",
    "        del sample_prediction_df['playerId']\n",
    "        \n",
    "        return sample_prediction_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db79fac5",
   "metadata": {
    "papermill": {
     "duration": 0.011281,
     "end_time": "2021-07-19T13:46:00.105632",
     "exception": false,
     "start_time": "2021-07-19T13:46:00.094351",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e89b3710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 新しいtrain_update, players, nextDayPlayerEngagementの展開されたものを読み込める必要あり\n",
    "\n",
    "class LocalTest:\n",
    "    def __init__(self, start_day, end_day):\n",
    "        self.start_day = start_day\n",
    "        self.end_day = end_day\n",
    "        \n",
    "    def make_env(self):\n",
    "    \n",
    "        self.original_data = pd.read_csv(UPDATE_DATA_DIR / \"train_updated.csv\")\n",
    "        self.original_data = self.original_data[(self.original_data['date'] >= self.start_day) & (self.original_data['date'] <= self.end_day)].reset_index(drop=True)\n",
    "        \n",
    "        test_players = pd.read_csv(UPDATE_DATA_DIR / 'players.csv')\n",
    "        self.players_test = test_players[test_players['playerForTestSetAndFuturePreds']==True]['playerId'].unique()\n",
    "        \n",
    "        self.test_targets = pd.read_csv(UPDATE_DATA_DIR / 'train/nextDayPlayerEngagement_train.csv')\n",
    "        self.test_targets = self.test_targets[(self.test_targets['date'] >= self.start_day) & (self.test_targets['date'] <= self.end_day) & (self.test_targets['playerId'].isin(self.players_test))].reset_index(drop=True)\n",
    "        \n",
    "        self.scores = []\n",
    "        return self\n",
    "        \n",
    "    def iter_test(self):\n",
    "        self.num = len(self.original_data['date'].unique())\n",
    "        self.current = 0\n",
    "        self.predict_flag = True\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        assert self.predict_flag == True, 'You must call `predict()` successfully before you can continue with `iter_test()`'\n",
    "     \n",
    "        if self.current == self.num:\n",
    "            print(np.mean(self.scores))\n",
    "            raise StopIteration()\n",
    "\n",
    "        test_df = self.original_data.iloc[self.current:self.current+1].set_index('date')\n",
    "\n",
    "        sample_prediction_df = pd.DataFrame()\n",
    "        sample_prediction_df['date'] = [test_df.index[0]] * len(self.players_test)\n",
    "        next_day = (pd.to_datetime(sample_prediction_df['date'], format=\"%Y%m%d\") + timedelta(days=1)).astype(str).str.replace('-', '')\n",
    "        # next_day.str.cat(players_test.astype(str))\n",
    "        sample_prediction_df['date_playerId'] = [next_day[0] + '_' + str(p_) for p_ in self.players_test]\n",
    "        sample_prediction_df['target1'] = 0\n",
    "        sample_prediction_df['target2'] = 0\n",
    "        sample_prediction_df['target3'] = 0\n",
    "        sample_prediction_df['target4'] = 0\n",
    "\n",
    "        sample_prediction_df = sample_prediction_df.set_index('date')\n",
    "\n",
    "        self.current += 1\n",
    "        self.predict_flag = False\n",
    "        return test_df, sample_prediction_df\n",
    "    \n",
    "    def predict(self, sample_prediction_df):\n",
    "        \n",
    "        self.predict_flag = True\n",
    "    \n",
    "        sample_prediction_df = sample_prediction_df.reset_index()\n",
    "        date_playerId = sample_prediction_df['date_playerId'].str.split('_', expand=True)\n",
    "        sample_prediction_df['date'] = (pd.to_datetime(date_playerId[0], format=\"%Y%m%d\") + timedelta(days=-1)).astype(str).str.replace('-', '').values.astype(int)\n",
    "        sample_prediction_df['playerId'] = date_playerId[1].values.astype(int)\n",
    "        target_oneday = pd.merge(sample_prediction_df, self.test_targets, how='left', on=['date', 'playerId'], suffixes=('', '_true'))\n",
    "        score = mean_absolute_error(target_oneday.loc[:, 'target1':'target4'], target_oneday.loc[:, 'target1_true':'target4_true'])\n",
    "        \n",
    "        self.scores.append(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "572b8fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../74/output/train_features_dict74.pickle\", mode=\"rb\") as f:\n",
    "    train_features_dict = pickle.load(f)\n",
    "    \n",
    "with open('../74/output/models74.pickle', mode=\"rb\") as f:\n",
    "    models = pickle.load(f)\n",
    "    \n",
    "# with open('../78/output/models78_gameday.pickle', mode=\"rb\") as f:\n",
    "#     models_gameday = pickle.load(f)\n",
    "    \n",
    "## self.train_features_dict['train_last_roster']が更新されちゃうから，これは絶対呼ぶ\n",
    "rt4kaido_test = Rt4kaidoTest(train_features_dict, models, models, usetimelinefeature=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ef76e064",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = LocalTest(20210501, 20210531)\n",
    "env = mlb.make_env() # initialize the environment\n",
    "iter_test = env.iter_test() # iterator which loops over each date in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a7d31efd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.3145874903503743\n"
     ]
    }
   ],
   "source": [
    "scores = []\n",
    "for (test_df, sample_prediction_df) in iter_test: # make predictions here\n",
    "    \n",
    "    sample_prediction_df = rt4kaido_test.test_oneline(test_df, sample_prediction_df)\n",
    "    \n",
    "    env.predict(sample_prediction_df)\n",
    "#     continue\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a8bab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218be83d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 22.662561,
   "end_time": "2021-07-19T13:46:04.680324",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-07-19T13:45:42.017763",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
