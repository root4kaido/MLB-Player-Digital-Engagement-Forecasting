{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### CREDITS\n* [baseline average 1.47](https://www.kaggle.com/mlconsult/baseline-average-1-47)\n* [BaseLine Model: Player Mean or Median ?](https://www.kaggle.com/ulrich07/baseline-model-player-mean-or-median)\n* [Fork - MLB baseline avergage 1.47](https://www.kaggle.com/junichih/mlb-baseline-median-1-45) \n\n### UPDATES\n* **V1**: Lags up to 3, 10 Epochs \n* **V2**: Lags up to 3, 20 Epochs\n* **V5**: Lags up to 20, 10 Epochs\n* **V6**: Lags up to 20, 10 Epochs with Stratified KFold\n* **V7**: Lags up to 20, 50 Epochs with Stratified KFold\n* **V8**: Lags up to 30, 10 Epochs with Stratified KFold\n\n### Please **Upvote** if you find this helpful ðŸ‘½","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-06-16T15:46:24.94492Z","iopub.execute_input":"2021-06-16T15:46:24.945502Z","iopub.status.idle":"2021-06-16T15:46:25.761799Z","shell.execute_reply.started":"2021-06-16T15:46:24.945463Z","shell.execute_reply":"2021-06-16T15:46:25.760806Z"}}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom datetime import timedelta\nfrom tqdm import tqdm\nimport gc\nfrom functools import reduce\nfrom sklearn.model_selection import StratifiedKFold\nimport lightgbm as lgbm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_df(df, col, bool_in=False):\n    tp = df.loc[ ~df[col].isnull() ,[col]].copy()\n    df.drop(col, axis=1, inplace=True)\n    \n    tp[col] = tp[col].str.replace(\"null\",'\"\"')\n    if bool_in:\n        tp[col] = tp[col].str.replace(\"false\",'\"False\"')\n        tp[col] = tp[col].str.replace(\"true\",'\"True\"')\n    tp[col] = tp[col].apply(lambda x: eval(x) )\n    a = tp[col].sum()\n    gc.collect()\n    return pd.DataFrame(a)\n#===============","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ROOT_DIR = \"../input/mlb-player-digital-engagement-forecasting\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## UTILITY FUNCTIONS","metadata":{}},{"cell_type":"code","source":"#=======================#\ndef flatten(df, col):\n    du = (df.pivot(index=\"playerId\", columns=\"EvalDate\", \n               values=col).add_prefix(f\"{col}_\").\n      rename_axis(None, axis=1).reset_index())\n    return du\n#============================#\ndef reducer(left, right):\n    return left.merge(right, on=\"playerId\")\n#========================","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TGTCOLS = [\"target1\",\"target2\",\"target3\",\"target4\"]\ndef train_lag(df, lag=1):\n    dp = df[[\"playerId\",\"EvalDate\"]+TGTCOLS].copy()\n    dp[\"EvalDate\"]  =dp[\"EvalDate\"] + timedelta(days=lag) \n    df = df.merge(dp, on=[\"playerId\", \"EvalDate\"], suffixes=[\"\",f\"_{lag}\"], how=\"left\")\n    return df\n#=================================\ndef test_lag(sub):\n    sub[\"playerId\"] = sub[\"date_playerId\"].apply(lambda s: int(  s.split(\"_\")[1]  ) )\n    assert sub.date.nunique() == 1\n    dte = sub[\"date\"].unique()[0]\n    \n    eval_dt = pd.to_datetime(dte, format=\"%Y%m%d\")\n    dtes = [eval_dt + timedelta(days=-k) for k in LAGS]\n    mp_dtes = {eval_dt + timedelta(days=-k):k for k in LAGS}\n    \n    sl = LAST.loc[LAST.EvalDate.between(dtes[-1], dtes[0]), [\"EvalDate\",\"playerId\"]+TGTCOLS].copy()\n    sl[\"EvalDate\"] = sl[\"EvalDate\"].map(mp_dtes)\n    du = [flatten(sl, col) for col in TGTCOLS]\n    du = reduce(reducer, du)\n    return du, eval_dt\n    #\n#===============","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\n#tr = pd.read_csv(f\"{ROOT_DIR}/train.csv\")\ntr = pd.read_csv(\"../input/mlb-data/target.csv\")\nprint(tr.shape)\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr[\"EvalDate\"] = pd.to_datetime(tr[\"EvalDate\"])\ntr[\"EvalDate\"] = tr[\"EvalDate\"] + timedelta(days=-1)\ntr[\"EvalYear\"] = tr[\"EvalDate\"].dt.year","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MED_DF = tr.groupby([\"playerId\",\"EvalYear\"])[TGTCOLS].median().reset_index()\nMEDCOLS = [\"tgt1_med\",\"tgt2_med\", \"tgt3_med\", \"tgt4_med\"]\nMED_DF.columns = [\"playerId\",\"EvalYear\"] + MEDCOLS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MED_DF.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAGS = list(range(1,31))\nFECOLS = [f\"{col}_{lag}\" for lag in reversed(LAGS) for col in TGTCOLS]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAGS","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nfor lag in tqdm(LAGS):\n    tr = train_lag(tr, lag=lag)\n    gc.collect()\n#===========\ntr = tr.sort_values(by=[\"playerId\", \"EvalDate\"])\nprint(tr.shape)\ntr = tr.dropna()\nprint(tr.shape)\ntr = tr.merge(MED_DF, on=[\"playerId\",\"EvalYear\"])\ngc.collect()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = tr[FECOLS+MEDCOLS].values\ny = tr[TGTCOLS].values\ncl = tr[\"playerId\"].values","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"NFOLDS = 5\nskf = StratifiedKFold(n_splits=NFOLDS)\nfolds = skf.split(X, cl)\nfolds = list(folds)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def fit_lgbm(x_train, y_train, x_valid, y_valid, params: dict=None, verbose=100):\n    oof_pred = np.zeros(len(y_valid), dtype=np.float32)\n    model = lgbm.LGBMRegressor(**params)\n    model.fit(x_train, y_train, \n        eval_set=[(x_valid, y_valid)],  \n        early_stopping_rounds=verbose, \n        verbose=verbose)\n    oof_pred = model.predict(x_valid)\n    oof_pred = np.clip(oof_pred, 0, 100)\n    score = mean_absolute_error(oof_pred, y_valid)\n    print('mae:', score)\n    return oof_pred, model, score","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for idx in range(NFOLDS):\n    \n    # training lightgbm\n    params = {\n     'objective':'mae',\n     'reg_alpha': 0.1,\n     'reg_lambda': 0.1, \n     'n_estimators': 100000,\n     'learning_rate': 0.1,\n     'random_state': 42,\n    }\n    tr_idx, val_idx = folds[idx]\n    x_train = X[tr_idx]\n    x_valid = X[val_idx]\n    y_train = y[tr_idx]\n    y_valid = y[val_idx]\n\n    oof1, model1, score1 = fit_lgbm(\n        x_train, y_train[:, 0],\n        x_valid, y_valid[:, 0],\n        params\n    )\n    oof2, model2, score2 = fit_lgbm(\n        x_train, y_train[:, 1],\n        x_valid, y_valid[:, 1],\n        params\n    )\n    oof3, model3, score3 = fit_lgbm(\n        x_train, y_train[:, 2],\n        x_valid, y_valid[:, 2],\n        params\n    )\n    oof4, model4, score4 = fit_lgbm(\n        x_train, y_train[:, 3],\n        x_valid, y_valid[:, 3],\n        params\n    )\n\n    score = (score1+score2+score3+score4) / 4\n    print(f'score: {score}')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Neural Net Training","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow.keras.layers as L\nimport tensorflow.keras.models as M\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_model(n_in):\n    inp = L.Input(name=\"inputs\", shape=(n_in,))\n    x = L.Dense(50, activation=\"relu\", name=\"d1\")(inp)\n    x = L.Dense(50, activation=\"relu\", name=\"d2\")(x)\n    preds = L.Dense(4, activation=\"linear\", name=\"preds\")(x)\n    \n    model = M.Model(inp, preds, name=\"ANN\")\n    model.compile(loss=\"mean_absolute_error\", optimizer=\"adam\")\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"net = make_model(X.shape[1])\nprint(net.summary())","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof = np.zeros(y.shape)\nnets = []\nEPOCHS  = 10\nfor idx in range(NFOLDS):\n    print(\"FOLD:\", idx)\n    tr_idx, val_idx = folds[idx]\n    ckpt = ModelCheckpoint(f\"w{idx}.h5\", monitor='val_loss', verbose=1, save_best_only=True,mode='min')\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2,patience=3, min_lr=0.0005)\n    es = EarlyStopping(monitor='val_loss', patience=6)\n    reg = make_model(X.shape[1])\n    reg.fit(X[tr_idx], y[tr_idx], epochs=EPOCHS, batch_size=30_000, \n            validation_data=(X[val_idx], y[val_idx]),\n            verbose=1, callbacks=[ckpt, reduce_lr, es])\n    reg.load_weights(f\"w{idx}.h5\")\n    oof[val_idx] = reg.predict(X[val_idx], batch_size=50_000, verbose=1)\n    nets.append(reg)\n    gc.collect()\n    #\n#","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#reg.fit(X, y, epochs=10, batch_size=30_000, validation_split=0.3)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"mae = mean_absolute_error(y, oof)\nmse = mean_squared_error(y, oof, squared=False)\nprint(\"mae:\", mae)\nprint(\"mse:\", mse)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Historical information to use in prediction time\nbound_dt = pd.to_datetime(\"2021-01-01\")\nLAST = tr.loc[tr.EvalDate>bound_dt].copy()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAST","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAST_MED_DF = MED_DF.loc[MED_DF.EvalYear==2021].copy()\nLAST_MED_DF.drop(\"EvalYear\", axis=1, inplace=True)\ndel tr","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAST.shape, LAST_MED_DF.shape, MED_DF.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#nets[0].summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\"\"\"\nimport mlb\nFE = []; SUB = [];\n# env = mlb.make_env() # initialize the environment\n# iter_test = env.iter_test() # iterator which loops over each date in test set\n# \nfor (test_df, sub) in iter_test:\n    # Features computation at Evaluation Date\n    sub = sub.reset_index()\n    sub_fe, eval_dt = test_lag(sub)\n    sub_fe = sub_fe.merge(LAST_MED_DF, on=\"playerId\", how=\"left\")\n    sub_fe = sub_fe.fillna(0.)\n    \n#     _preds = 0.\n#     for reg in nets:\n#         _preds += reg.predict(sub_fe[FECOLS + MEDCOLS]) / NFOLDS\n#     sub_fe[TGTCOLS] = np.clip(_preds, 0, 100)\n#     sub.drop([\"date\"]+TGTCOLS, axis=1, inplace=True)\n#     sub = sub.merge(sub_fe[[\"playerId\"]+TGTCOLS], on=\"playerId\", how=\"left\")\n#     sub.drop(\"playerId\", axis=1, inplace=True)\n#     sub = sub.fillna(0.)\n#     # Submit\n#     env.predict(sub)\n#     # Update Available information\n#     sub_fe[\"EvalDate\"] = eval_dt\n#     #sub_fe.drop(MEDCOLS, axis=1, inplace=True)\n#     LAST = LAST.append(sub_fe)\n#     LAST = LAST.drop_duplicates(subset=[\"EvalDate\",\"playerId\"], keep=\"last\")\n#\"\"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sub_fe.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"LAST.shape, sub_fe.shape","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#df_tr[\"dte\"] = pd.to_datetime(df_tr[\"date\"], format='%Y%m%d')","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}